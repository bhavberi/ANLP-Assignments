Using cuda
Number of sentences:  35415
Number of words:  941819
Number of unique words:  26128
Most common words:  [('the', 56795), ('to', 26839), ('of', 25600), ('and', 24759), ('a', 18892)]
26129
Ignored 2517 sentences due to length
Number of samples: 539401
Ignored 751 sentences due to length
Number of samples: 157155
Ignored 376 sentences due to length
Number of samples: 74696
Epoch: 1, Batch: 250, Loss: 10.07093951034546
Epoch: 1, Batch: 500, Loss: 8.517641260147094
Epoch: 1, Batch: 750, Loss: 7.311821784973144
Epoch: 1, Batch: 1000, Loss: 7.077541282653809
Epoch: 1, Batch: 1250, Loss: 6.989204820632935
Epoch: 1, Batch: 1500, Loss: 6.939243360519409
Epoch: 1, Batch: 1750, Loss: 6.898212816238403
Epoch: 1, Batch: 2000, Loss: 6.843180528640747
Epoch: 1, Batch: 2250, Loss: 6.852924964904785
Epoch: 1, Batch: 2500, Loss: 6.769979330062866
Epoch: 1, Batch: 2750, Loss: 6.76484840965271
Epoch: 1, Batch: 3000, Loss: 6.734214742660522
Epoch: 1, Batch: 3250, Loss: 6.722292629241943
Epoch: 1, Batch: 3500, Loss: 6.722292274475097
Epoch: 1, Batch: 3750, Loss: 6.6663082962036135
Epoch: 1, Batch: 4000, Loss: 6.6712835578918455
Epoch: 1, Batch: 4250, Loss: 6.615101354598999
Epoch: 1, Batch: 4500, Loss: 6.625353130340576
Epoch: 1, Batch: 4750, Loss: 6.621165201187134
Epoch: 1, Batch: 5000, Loss: 6.592595321655273
Epoch: 1, Batch: 5250, Loss: 6.588640396118164
Epoch: 1, Batch: 5500, Loss: 6.523178367614746
Epoch: 1, Batch: 5750, Loss: 6.527080533981323
Epoch: 1, Batch: 6000, Loss: 6.5058083267211915
Epoch: 1, Batch: 6250, Loss: 6.490486345291138
Epoch: 1, Batch: 6500, Loss: 6.467707416534424
Epoch: 1, Batch: 6750, Loss: 6.48915898513794
Epoch: 1, Batch: 7000, Loss: 6.4555791549682615
Epoch: 1, Batch: 7250, Loss: 6.441256219863892
Epoch: 1, Batch: 7500, Loss: 6.509939804077148
Epoch: 1, Batch: 7750, Loss: 6.453364723205566
Epoch: 1, Batch: 8000, Loss: 6.4496103820800785
Epoch: 1, Batch: 8250, Loss: 6.403300458908081
Epoch: 1, Val loss: 6.37431115902208 Perplexity: 586.5812305543119
Model saved at Epoch:  1
Epoch: 2, Batch: 250, Loss: 6.317041770935059
Epoch: 2, Batch: 500, Loss: 6.3702810192108155
Epoch: 2, Batch: 750, Loss: 6.388596910476685
Epoch: 2, Batch: 1000, Loss: 6.366692506790161
Epoch: 2, Batch: 1250, Loss: 6.349903823852539
Epoch: 2, Batch: 1500, Loss: 6.317771999359131
Epoch: 2, Batch: 1750, Loss: 6.28802818107605
Epoch: 2, Batch: 2000, Loss: 6.295938089370727
Epoch: 2, Batch: 2250, Loss: 6.284691165924072
Epoch: 2, Batch: 2500, Loss: 6.247084402084351
Epoch: 2, Batch: 2750, Loss: 6.297583108901978
Epoch: 2, Batch: 3000, Loss: 6.249252511978149
Epoch: 2, Batch: 3250, Loss: 6.231255256652832
Epoch: 2, Batch: 3500, Loss: 6.21453470993042
Epoch: 2, Batch: 3750, Loss: 6.270469736099243
Epoch: 2, Batch: 4000, Loss: 6.209179447174073
Epoch: 2, Batch: 4250, Loss: 6.209504421234131
Epoch: 2, Batch: 4500, Loss: 6.197693424224854
Epoch: 2, Batch: 4750, Loss: 6.190351022720337
Epoch: 2, Batch: 5000, Loss: 6.206992902755737
Epoch: 2, Batch: 5250, Loss: 6.169958683013916
Epoch: 2, Batch: 5500, Loss: 6.195923749923706
Epoch: 2, Batch: 5750, Loss: 6.178349290847779
Epoch: 2, Batch: 6000, Loss: 6.1322112655639645
Epoch: 2, Batch: 6250, Loss: 6.186147087097168
Epoch: 2, Batch: 6500, Loss: 6.133524326324463
Epoch: 2, Batch: 6750, Loss: 6.1064041805267335
Epoch: 2, Batch: 7000, Loss: 6.092228429794312
Epoch: 2, Batch: 7250, Loss: 6.15464422416687
Epoch: 2, Batch: 7500, Loss: 6.157339298248291
Epoch: 2, Batch: 7750, Loss: 6.08316921043396
Epoch: 2, Batch: 8000, Loss: 6.068662448883057
Epoch: 2, Batch: 8250, Loss: 6.110549619674683
Epoch: 2, Val loss: 6.06816465672142 Perplexity: 431.88729228733473
Model saved at Epoch:  2
Epoch: 3, Batch: 250, Loss: 6.080967542648316
Epoch: 3, Batch: 500, Loss: 6.0585032653808595
Epoch: 3, Batch: 750, Loss: 6.052414527893067
Epoch: 3, Batch: 1000, Loss: 6.047427240371704
Epoch: 3, Batch: 1250, Loss: 6.047350307464599
Epoch: 3, Batch: 1500, Loss: 6.000057859420776
Epoch: 3, Batch: 1750, Loss: 6.036643253326416
Epoch: 3, Batch: 2000, Loss: 6.046699989318848
Epoch: 3, Batch: 2250, Loss: 6.01442052268982
Epoch: 3, Batch: 2500, Loss: 6.046304000854493
Epoch: 3, Batch: 2750, Loss: 5.999539604187012
Epoch: 3, Batch: 3000, Loss: 5.993370939254761
Epoch: 3, Batch: 3250, Loss: 5.996906883239746
Epoch: 3, Batch: 3500, Loss: 5.9978285522460935
Epoch: 3, Batch: 3750, Loss: 5.999868108749389
Epoch: 3, Batch: 4000, Loss: 5.9777857818603515
Epoch: 3, Batch: 4250, Loss: 6.000793994903565
Epoch: 3, Batch: 4500, Loss: 5.996904623031616
Epoch: 3, Batch: 4750, Loss: 5.974012420654297
Epoch: 3, Batch: 5000, Loss: 5.955123363494873
Epoch: 3, Batch: 5250, Loss: 5.975044176101685
Epoch: 3, Batch: 5500, Loss: 5.978344146728515
Epoch: 3, Batch: 5750, Loss: 5.954799432754516
Epoch: 3, Batch: 6000, Loss: 5.976145956039429
Epoch: 3, Batch: 6250, Loss: 5.964171422958374
Epoch: 3, Batch: 6500, Loss: 5.911496305465699
Epoch: 3, Batch: 6750, Loss: 5.977892883300782
Epoch: 3, Batch: 7000, Loss: 5.960390769958496
Epoch: 3, Batch: 7250, Loss: 5.865078742980957
Epoch: 3, Batch: 7500, Loss: 5.927697420120239
Epoch: 3, Batch: 7750, Loss: 5.960775239944458
Epoch: 3, Batch: 8000, Loss: 5.946016944885254
Epoch: 3, Batch: 8250, Loss: 5.90923203086853
Epoch: 3, Val loss: 5.902914162955765 Perplexity: 366.10279805059986
Model saved at Epoch:  3
Epoch: 4, Batch: 250, Loss: 5.886041265487671
Epoch: 4, Batch: 500, Loss: 5.9079918308258055
Epoch: 4, Batch: 750, Loss: 5.870124166488647
Epoch: 4, Batch: 1000, Loss: 5.853902446746826
Epoch: 4, Batch: 1250, Loss: 5.89738942527771
Epoch: 4, Batch: 1500, Loss: 5.875282020568847
Epoch: 4, Batch: 1750, Loss: 5.865466884613037
Epoch: 4, Batch: 2000, Loss: 5.867055152893067
Epoch: 4, Batch: 2250, Loss: 5.864396497726441
Epoch: 4, Batch: 2500, Loss: 5.867496105194092
Epoch: 4, Batch: 2750, Loss: 5.882293373107911
Epoch: 4, Batch: 3000, Loss: 5.849676149368286
Epoch: 4, Batch: 3250, Loss: 5.873073965072632
Epoch: 4, Batch: 3500, Loss: 5.8888783950805665
Epoch: 4, Batch: 3750, Loss: 5.822229093551636
Epoch: 4, Batch: 4000, Loss: 5.87408962059021
Epoch: 4, Batch: 4250, Loss: 5.889838314056396
Epoch: 4, Batch: 4500, Loss: 5.851562911987305
Epoch: 4, Batch: 4750, Loss: 5.822064510345459
Epoch: 4, Batch: 5000, Loss: 5.83913779258728
Epoch: 4, Batch: 5250, Loss: 5.8690143508911135
Epoch: 4, Batch: 5500, Loss: 5.825207136154175
Epoch: 4, Batch: 5750, Loss: 5.832627546310425
Epoch: 4, Batch: 6000, Loss: 5.801757804870605
Epoch: 4, Batch: 6250, Loss: 5.8329076519012455
Epoch: 4, Batch: 6500, Loss: 5.865618324279785
Epoch: 4, Batch: 6750, Loss: 5.799875755310058
Epoch: 4, Batch: 7000, Loss: 5.853110681533813
Epoch: 4, Batch: 7250, Loss: 5.848887844085693
Epoch: 4, Batch: 7500, Loss: 5.882616111755371
Epoch: 4, Batch: 7750, Loss: 5.785199754714966
Epoch: 4, Batch: 8000, Loss: 5.813401807785034
Epoch: 4, Batch: 8250, Loss: 5.791039213180542
Epoch: 4, Val loss: 5.801269829467376 Perplexity: 330.7192504351868
Model saved at Epoch:  4
Epoch: 5, Batch: 250, Loss: 5.799414541244507
Epoch: 5, Batch: 500, Loss: 5.773577049255371
Epoch: 5, Batch: 750, Loss: 5.780223411560058
Epoch: 5, Batch: 1000, Loss: 5.780062395095825
Epoch: 5, Batch: 1250, Loss: 5.773551073074341
Epoch: 5, Batch: 1500, Loss: 5.743904850006103
Epoch: 5, Batch: 1750, Loss: 5.73550862121582
Epoch: 5, Batch: 2000, Loss: 5.81309693145752
Epoch: 5, Batch: 2250, Loss: 5.791985614776611
Epoch: 5, Batch: 2500, Loss: 5.735191335678101
Epoch: 5, Batch: 2750, Loss: 5.766253057479858
Epoch: 5, Batch: 3000, Loss: 5.759566282272339
Epoch: 5, Batch: 3250, Loss: 5.799625692367553
Epoch: 5, Batch: 3500, Loss: 5.77695073890686
Epoch: 5, Batch: 3750, Loss: 5.752246616363525
Epoch: 5, Batch: 4000, Loss: 5.745511421203613
Epoch: 5, Batch: 4250, Loss: 5.7866104755401615
Epoch: 5, Batch: 4500, Loss: 5.78499617767334
Epoch: 5, Batch: 4750, Loss: 5.7869660148620605
Epoch: 5, Batch: 5000, Loss: 5.753626941680908
Epoch: 5, Batch: 5250, Loss: 5.742113479614257
Epoch: 5, Batch: 5500, Loss: 5.757159776687622
Epoch: 5, Batch: 5750, Loss: 5.760946619033813
Epoch: 5, Batch: 6000, Loss: 5.750351312637329
Epoch: 5, Batch: 6250, Loss: 5.76598685836792
Epoch: 5, Batch: 6500, Loss: 5.785231864929199
Epoch: 5, Batch: 6750, Loss: 5.767733509063721
Epoch: 5, Batch: 7000, Loss: 5.7422336559295655
Epoch: 5, Batch: 7250, Loss: 5.743728437423706
Epoch: 5, Batch: 7500, Loss: 5.728586883544922
Epoch: 5, Batch: 7750, Loss: 5.716455545425415
Epoch: 5, Batch: 8000, Loss: 5.7124304084777835
Epoch: 5, Batch: 8250, Loss: 5.716262643814087
Epoch: 5, Val loss: 5.730094275179438 Perplexity: 307.9983036040776
Model saved at Epoch:  5
Epoch: 6, Batch: 250, Loss: 5.770512815475464
Epoch: 6, Batch: 500, Loss: 5.687306356430054
Epoch: 6, Batch: 750, Loss: 5.768904186248779
Epoch: 6, Batch: 1000, Loss: 5.709681299209595
Epoch: 6, Batch: 1250, Loss: 5.678444190979004
Epoch: 6, Batch: 1500, Loss: 5.729554681777954
Epoch: 6, Batch: 1750, Loss: 5.742820285797119
Epoch: 6, Batch: 2000, Loss: 5.654879688262939
Epoch: 6, Batch: 2250, Loss: 5.678622018814087
Epoch: 6, Batch: 2500, Loss: 5.713229488372803
Epoch: 6, Batch: 2750, Loss: 5.675666332244873
Epoch: 6, Batch: 3000, Loss: 5.6956937065124515
Epoch: 6, Batch: 3250, Loss: 5.689819067001343
Epoch: 6, Batch: 3500, Loss: 5.67765888595581
Epoch: 6, Batch: 3750, Loss: 5.694802219390869
Epoch: 6, Batch: 4000, Loss: 5.717124380111694
Epoch: 6, Batch: 4250, Loss: 5.707186950683594
Epoch: 6, Batch: 4500, Loss: 5.657398069381714
Epoch: 6, Batch: 4750, Loss: 5.717056243896485
Epoch: 6, Batch: 5000, Loss: 5.661650579452514
Epoch: 6, Batch: 5250, Loss: 5.685720426559448
Epoch: 6, Batch: 5500, Loss: 5.655549877166748
Epoch: 6, Batch: 5750, Loss: 5.701202056884766
Epoch: 6, Batch: 6000, Loss: 5.671242618560791
Epoch: 6, Batch: 6250, Loss: 5.693171497344971
Epoch: 6, Batch: 6500, Loss: 5.65159801864624
Epoch: 6, Batch: 6750, Loss: 5.6876745090484615
Epoch: 6, Batch: 7000, Loss: 5.671962728500366
Epoch: 6, Batch: 7250, Loss: 5.622719093322754
Epoch: 6, Batch: 7500, Loss: 5.675439832687378
Epoch: 6, Batch: 7750, Loss: 5.7101516494750975
Epoch: 6, Batch: 8000, Loss: 5.686215087890625
Epoch: 6, Batch: 8250, Loss: 5.6822644786834715
Epoch: 6, Val loss: 5.67989249415817 Perplexity: 292.9179378402948
Model saved at Epoch:  6
Epoch: 7, Batch: 250, Loss: 5.643502998352051
Epoch: 7, Batch: 500, Loss: 5.645799457550049
Epoch: 7, Batch: 750, Loss: 5.6421601123809815
Epoch: 7, Batch: 1000, Loss: 5.649449113845825
Epoch: 7, Batch: 1250, Loss: 5.659076589584351
Epoch: 7, Batch: 1500, Loss: 5.6645664176940915
Epoch: 7, Batch: 1750, Loss: 5.719385002136231
Epoch: 7, Batch: 2000, Loss: 5.651698890686035
Epoch: 7, Batch: 2250, Loss: 5.6079919090271
Epoch: 7, Batch: 2500, Loss: 5.654255702972412
Epoch: 7, Batch: 2750, Loss: 5.592984958648682
Epoch: 7, Batch: 3000, Loss: 5.628650791168213
Epoch: 7, Batch: 3250, Loss: 5.6245882625579835
Epoch: 7, Batch: 3500, Loss: 5.632321491241455
Epoch: 7, Batch: 3750, Loss: 5.636910921096802
Epoch: 7, Batch: 4000, Loss: 5.619481395721436
Epoch: 7, Batch: 4250, Loss: 5.669054584503174
Epoch: 7, Batch: 4500, Loss: 5.624005325317383
Epoch: 7, Batch: 4750, Loss: 5.642864339828491
Epoch: 7, Batch: 5000, Loss: 5.616968608856201
Epoch: 7, Batch: 5250, Loss: 5.5877548160552974
Epoch: 7, Batch: 5500, Loss: 5.6125959854125975
Epoch: 7, Batch: 5750, Loss: 5.619608207702637
Epoch: 7, Batch: 6000, Loss: 5.63453164100647
Epoch: 7, Batch: 6250, Loss: 5.622503540039062
Epoch: 7, Batch: 6500, Loss: 5.6357456378936766
Epoch: 7, Batch: 6750, Loss: 5.637056581497192
Epoch: 7, Batch: 7000, Loss: 5.629166107177735
Epoch: 7, Batch: 7250, Loss: 5.642085977554322
Epoch: 7, Batch: 7500, Loss: 5.622065872192382
Epoch: 7, Batch: 7750, Loss: 5.62975004196167
Epoch: 7, Batch: 8000, Loss: 5.606570142745972
Epoch: 7, Batch: 8250, Loss: 5.636858476638794
Epoch: 7, Val loss: 5.638268366698722 Perplexity: 280.9757500059926
Model saved at Epoch:  7
Epoch: 8, Batch: 250, Loss: 5.548167051315308
Epoch: 8, Batch: 500, Loss: 5.566224718093872
Epoch: 8, Batch: 750, Loss: 5.609528070449829
Epoch: 8, Batch: 1000, Loss: 5.56357911491394
Epoch: 8, Batch: 1250, Loss: 5.6271782455444335
Epoch: 8, Batch: 1500, Loss: 5.5932239112854
Epoch: 8, Batch: 1750, Loss: 5.613269081115723
Epoch: 8, Batch: 2000, Loss: 5.591240617752075
Epoch: 8, Batch: 2250, Loss: 5.614088640213013
Epoch: 8, Batch: 2500, Loss: 5.538280632019043
Epoch: 8, Batch: 2750, Loss: 5.581314453125
Epoch: 8, Batch: 3000, Loss: 5.602042644500733
Epoch: 8, Batch: 3250, Loss: 5.589054136276245
Epoch: 8, Batch: 3500, Loss: 5.610375301361084
Epoch: 8, Batch: 3750, Loss: 5.58763970375061
Epoch: 8, Batch: 4000, Loss: 5.604552316665649
Epoch: 8, Batch: 4250, Loss: 5.546460580825806
Epoch: 8, Batch: 4500, Loss: 5.5667869529724125
Epoch: 8, Batch: 4750, Loss: 5.563144157409668
Epoch: 8, Batch: 5000, Loss: 5.589698535919189
Epoch: 8, Batch: 5250, Loss: 5.574854513168335
Epoch: 8, Batch: 5500, Loss: 5.575517610549927
Epoch: 8, Batch: 5750, Loss: 5.614808864593506
Epoch: 8, Batch: 6000, Loss: 5.615332893371582
Epoch: 8, Batch: 6250, Loss: 5.58237197303772
Epoch: 8, Batch: 6500, Loss: 5.574928094863892
Epoch: 8, Batch: 6750, Loss: 5.591878582000732
Epoch: 8, Batch: 7000, Loss: 5.58712659072876
Epoch: 8, Batch: 7250, Loss: 5.634165529251098
Epoch: 8, Batch: 7500, Loss: 5.5971111335754395
Epoch: 8, Batch: 7750, Loss: 5.565613283157349
Epoch: 8, Batch: 8000, Loss: 5.546853422164917
Epoch: 8, Batch: 8250, Loss: 5.529484252929688
Epoch: 8, Val loss: 5.597658888136525 Perplexity: 269.794049454724
Model saved at Epoch:  8
Epoch: 9, Batch: 250, Loss: 5.530340394973755
Epoch: 9, Batch: 500, Loss: 5.528062072753906
Epoch: 9, Batch: 750, Loss: 5.562823986053467
Epoch: 9, Batch: 1000, Loss: 5.535155796051026
Epoch: 9, Batch: 1250, Loss: 5.507292442321777
Epoch: 9, Batch: 1500, Loss: 5.559759244918824
Epoch: 9, Batch: 1750, Loss: 5.544733907699585
Epoch: 9, Batch: 2000, Loss: 5.539671579360962
Epoch: 9, Batch: 2250, Loss: 5.536750663757324
Epoch: 9, Batch: 2500, Loss: 5.526894693374634
Epoch: 9, Batch: 2750, Loss: 5.574326080322265
Epoch: 9, Batch: 3000, Loss: 5.559649291992187
Epoch: 9, Batch: 3250, Loss: 5.54047618484497
Epoch: 9, Batch: 3500, Loss: 5.52783387184143
Epoch: 9, Batch: 3750, Loss: 5.560199893951416
Epoch: 9, Batch: 4000, Loss: 5.570417854309082
Epoch: 9, Batch: 4250, Loss: 5.516485986709594
Epoch: 9, Batch: 4500, Loss: 5.546080717086792
Epoch: 9, Batch: 4750, Loss: 5.586053098678589
Epoch: 9, Batch: 5000, Loss: 5.535080280303955
Epoch: 9, Batch: 5250, Loss: 5.5447934684753415
Epoch: 9, Batch: 5500, Loss: 5.532628713607788
Epoch: 9, Batch: 5750, Loss: 5.512017570495606
Epoch: 9, Batch: 6000, Loss: 5.563922994613647
Epoch: 9, Batch: 6250, Loss: 5.5025218486785885
Epoch: 9, Batch: 6500, Loss: 5.555438718795776
Epoch: 9, Batch: 6750, Loss: 5.542965572357177
Epoch: 9, Batch: 7000, Loss: 5.537671169281006
Epoch: 9, Batch: 7250, Loss: 5.552519733428955
Epoch: 9, Batch: 7500, Loss: 5.538489183425903
Epoch: 9, Batch: 7750, Loss: 5.589385028839112
Epoch: 9, Batch: 8000, Loss: 5.530229499816895
Epoch: 9, Batch: 8250, Loss: 5.464295270919799
Epoch: 9, Val loss: 5.559924139844478 Perplexity: 259.8031268697697
Model saved at Epoch:  9
Epoch: 10, Batch: 250, Loss: 5.519577438354492
Epoch: 10, Batch: 500, Loss: 5.49064044380188
Epoch: 10, Batch: 750, Loss: 5.534175249099731
Epoch: 10, Batch: 1000, Loss: 5.449172183990479
Epoch: 10, Batch: 1250, Loss: 5.514745151519775
Epoch: 10, Batch: 1500, Loss: 5.485677251815796
Epoch: 10, Batch: 1750, Loss: 5.5212504730224605
Epoch: 10, Batch: 2000, Loss: 5.485708780288697
Epoch: 10, Batch: 2250, Loss: 5.534140626907349
Epoch: 10, Batch: 2500, Loss: 5.513302696228028
Epoch: 10, Batch: 2750, Loss: 5.480049438476563
Epoch: 10, Batch: 3000, Loss: 5.49987603187561
Epoch: 10, Batch: 3250, Loss: 5.528172361373901
Epoch: 10, Batch: 3500, Loss: 5.444231721878052
Epoch: 10, Batch: 3750, Loss: 5.4762390480041505
Epoch: 10, Batch: 4000, Loss: 5.521893342971802
Epoch: 10, Batch: 4250, Loss: 5.527744369506836
Epoch: 10, Batch: 4500, Loss: 5.510567281723023
Epoch: 10, Batch: 4750, Loss: 5.512536394119262
Epoch: 10, Batch: 5000, Loss: 5.540193864822387
Epoch: 10, Batch: 5250, Loss: 5.507510620117188
Epoch: 10, Batch: 5500, Loss: 5.504500064849854
Epoch: 10, Batch: 5750, Loss: 5.511177116394043
Epoch: 10, Batch: 6000, Loss: 5.503903238296509
Epoch: 10, Batch: 6250, Loss: 5.472097410202027
Epoch: 10, Batch: 6500, Loss: 5.526042783737183
Epoch: 10, Batch: 6750, Loss: 5.513633596420288
Epoch: 10, Batch: 7000, Loss: 5.491407627105713
Epoch: 10, Batch: 7250, Loss: 5.478711248397827
Epoch: 10, Batch: 7500, Loss: 5.52184146308899
Epoch: 10, Batch: 7750, Loss: 5.471218910217285
Epoch: 10, Batch: 8000, Loss: 5.460368448257446
Epoch: 10, Batch: 8250, Loss: 5.504427051544189
Epoch: 10, Val loss: 5.535573937411417 Perplexity: 253.5532695915331
Model saved at Epoch:  10
Epoch: 11, Batch: 250, Loss: 5.444891548156738
Epoch: 11, Batch: 500, Loss: 5.470777460098267
Epoch: 11, Batch: 750, Loss: 5.451481287002563
Epoch: 11, Batch: 1000, Loss: 5.496465400695801
Epoch: 11, Batch: 1250, Loss: 5.465852176666259
Epoch: 11, Batch: 1500, Loss: 5.4591288528442385
Epoch: 11, Batch: 1750, Loss: 5.471814683914184
Epoch: 11, Batch: 2000, Loss: 5.483463026046753
Epoch: 11, Batch: 2250, Loss: 5.475556493759155
Epoch: 11, Batch: 2500, Loss: 5.468847171783447
Epoch: 11, Batch: 2750, Loss: 5.463548141479492
Epoch: 11, Batch: 3000, Loss: 5.465749319076538
Epoch: 11, Batch: 3250, Loss: 5.46386137008667
Epoch: 11, Batch: 3500, Loss: 5.499597892761231
Epoch: 11, Batch: 3750, Loss: 5.481206428527832
Epoch: 11, Batch: 4000, Loss: 5.461561883926391
Epoch: 11, Batch: 4250, Loss: 5.441166151046753
Epoch: 11, Batch: 4500, Loss: 5.497484739303589
Epoch: 11, Batch: 4750, Loss: 5.414235095977784
Epoch: 11, Batch: 5000, Loss: 5.458417854309082
Epoch: 11, Batch: 5250, Loss: 5.473518730163574
Epoch: 11, Batch: 5500, Loss: 5.507589933395386
Epoch: 11, Batch: 5750, Loss: 5.492457220077514
Epoch: 11, Batch: 6000, Loss: 5.485288673400879
Epoch: 11, Batch: 6250, Loss: 5.461081827163697
Epoch: 11, Batch: 6500, Loss: 5.486517868041992
Epoch: 11, Batch: 6750, Loss: 5.450249717712403
Epoch: 11, Batch: 7000, Loss: 5.442518556594849
Epoch: 11, Batch: 7250, Loss: 5.4785326366424565
Epoch: 11, Batch: 7500, Loss: 5.487138380050659
Epoch: 11, Batch: 7750, Loss: 5.413941019058227
Epoch: 11, Batch: 8000, Loss: 5.4661114826202395
Epoch: 11, Batch: 8250, Loss: 5.448696544647217
Epoch: 11, Val loss: 5.510320755674319 Perplexity: 247.23041490937774
Model saved at Epoch:  11
Epoch: 12, Batch: 250, Loss: 5.406829986572266
Epoch: 12, Batch: 500, Loss: 5.399107227325439
Epoch: 12, Batch: 750, Loss: 5.440878162384033
Epoch: 12, Batch: 1000, Loss: 5.432866779327393
Epoch: 12, Batch: 1250, Loss: 5.43880518913269
Epoch: 12, Batch: 1500, Loss: 5.427037158966065
Epoch: 12, Batch: 1750, Loss: 5.437857452392578
Epoch: 12, Batch: 2000, Loss: 5.427028560638428
Epoch: 12, Batch: 2250, Loss: 5.450936382293701
Epoch: 12, Batch: 2500, Loss: 5.393601358413696
Epoch: 12, Batch: 2750, Loss: 5.467575361251831
Epoch: 12, Batch: 3000, Loss: 5.415940599441528
Epoch: 12, Batch: 3250, Loss: 5.5001458644866945
Epoch: 12, Batch: 3500, Loss: 5.39962393951416
Epoch: 12, Batch: 3750, Loss: 5.4386567058563235
Epoch: 12, Batch: 4000, Loss: 5.418969841003418
Epoch: 12, Batch: 4250, Loss: 5.425934368133545
Epoch: 12, Batch: 4500, Loss: 5.413406282424927
Epoch: 12, Batch: 4750, Loss: 5.42619331741333
Epoch: 12, Batch: 5000, Loss: 5.451908433914185
Epoch: 12, Batch: 5250, Loss: 5.471988712310791
Epoch: 12, Batch: 5500, Loss: 5.436498146057129
Epoch: 12, Batch: 5750, Loss: 5.432914922714233
Epoch: 12, Batch: 6000, Loss: 5.446184740066529
Epoch: 12, Batch: 6250, Loss: 5.4698077449798586
Epoch: 12, Batch: 6500, Loss: 5.382093608856201
Epoch: 12, Batch: 6750, Loss: 5.45756206703186
Epoch: 12, Batch: 7000, Loss: 5.452422607421875
Epoch: 12, Batch: 7250, Loss: 5.431471441268921
Epoch: 12, Batch: 7500, Loss: 5.385900789260864
Epoch: 12, Batch: 7750, Loss: 5.451851556777954
Epoch: 12, Batch: 8000, Loss: 5.465872575759888
Epoch: 12, Batch: 8250, Loss: 5.467348693847656
Epoch: 12, Val loss: 5.492824026544242 Perplexity: 242.94231456651391
Model saved at Epoch:  12
Epoch: 13, Batch: 250, Loss: 5.4381802349090576
Epoch: 13, Batch: 500, Loss: 5.429709135055542
Epoch: 13, Batch: 750, Loss: 5.403344703674317
Epoch: 13, Batch: 1000, Loss: 5.388372753143311
Epoch: 13, Batch: 1250, Loss: 5.382533967971802
Epoch: 13, Batch: 1500, Loss: 5.3955166625976565
Epoch: 13, Batch: 1750, Loss: 5.407265794754029
Epoch: 13, Batch: 2000, Loss: 5.381057783126831
Epoch: 13, Batch: 2250, Loss: 5.426720006942749
Epoch: 13, Batch: 2500, Loss: 5.438241472244263
Epoch: 13, Batch: 2750, Loss: 5.432194623947144
Epoch: 13, Batch: 3000, Loss: 5.393269767761231
Epoch: 13, Batch: 3250, Loss: 5.361262113571167
Epoch: 13, Batch: 3500, Loss: 5.379694574356079
Epoch: 13, Batch: 3750, Loss: 5.440490615844727
Epoch: 13, Batch: 4000, Loss: 5.420459272384644
Epoch: 13, Batch: 4250, Loss: 5.405605001449585
Epoch: 13, Batch: 4500, Loss: 5.393206907272339
Epoch: 13, Batch: 4750, Loss: 5.437350957870484
Epoch: 13, Batch: 5000, Loss: 5.4023007373809815
Epoch: 13, Batch: 5250, Loss: 5.439564628601074
Epoch: 13, Batch: 5500, Loss: 5.341420358657837
Epoch: 13, Batch: 5750, Loss: 5.429075527191162
Epoch: 13, Batch: 6000, Loss: 5.405669450759888
Epoch: 13, Batch: 6250, Loss: 5.395411203384399
Epoch: 13, Batch: 6500, Loss: 5.389461057662964
Epoch: 13, Batch: 6750, Loss: 5.385894874572754
Epoch: 13, Batch: 7000, Loss: 5.422650049209595
Epoch: 13, Batch: 7250, Loss: 5.4254821739196775
Epoch: 13, Batch: 7500, Loss: 5.384632658004761
Epoch: 13, Batch: 7750, Loss: 5.391453065872192
Epoch: 13, Batch: 8000, Loss: 5.405541730880738
Epoch: 13, Batch: 8250, Loss: 5.422379463195801
Epoch: 13, Val loss: 5.46623637466555 Perplexity: 236.56816125291851
Model saved at Epoch:  13
Epoch: 14, Batch: 250, Loss: 5.394269929885864
Epoch: 14, Batch: 500, Loss: 5.385482137680054
Epoch: 14, Batch: 750, Loss: 5.379289758682251
Epoch: 14, Batch: 1000, Loss: 5.381536388397217
Epoch: 14, Batch: 1250, Loss: 5.389534954071045
Epoch: 14, Batch: 1500, Loss: 5.384753643035888
Epoch: 14, Batch: 1750, Loss: 5.411261526107788
Epoch: 14, Batch: 2000, Loss: 5.390512813568115
Epoch: 14, Batch: 2250, Loss: 5.3231785869598385
Epoch: 14, Batch: 2500, Loss: 5.376136270523071
Epoch: 14, Batch: 2750, Loss: 5.381073211669922
Epoch: 14, Batch: 3000, Loss: 5.406584869384766
Epoch: 14, Batch: 3250, Loss: 5.393978937149048
Epoch: 14, Batch: 3500, Loss: 5.402029014587402
Epoch: 14, Batch: 3750, Loss: 5.379263080596924
Epoch: 14, Batch: 4000, Loss: 5.34825564956665
Epoch: 14, Batch: 4250, Loss: 5.31708249092102
Epoch: 14, Batch: 4500, Loss: 5.410230662345886
Epoch: 14, Batch: 4750, Loss: 5.390803884506226
Epoch: 14, Batch: 5000, Loss: 5.3775328960418705
Epoch: 14, Batch: 5250, Loss: 5.372966651916504
Epoch: 14, Batch: 5500, Loss: 5.3679038963317875
Epoch: 14, Batch: 5750, Loss: 5.3867276039123535
Epoch: 14, Batch: 6000, Loss: 5.382012804031372
Epoch: 14, Batch: 6250, Loss: 5.386376905441284
Epoch: 14, Batch: 6500, Loss: 5.375203969955444
Epoch: 14, Batch: 6750, Loss: 5.3253257427215575
Epoch: 14, Batch: 7000, Loss: 5.392258253097534
Epoch: 14, Batch: 7250, Loss: 5.362270797729492
Epoch: 14, Batch: 7500, Loss: 5.33777121925354
Epoch: 14, Batch: 7750, Loss: 5.35250016784668
Epoch: 14, Batch: 8000, Loss: 5.368531209945679
Epoch: 14, Batch: 8250, Loss: 5.3725792541503905
Epoch: 14, Val loss: 5.4530877069075645 Perplexity: 233.47796559768787
Model saved at Epoch:  14
Epoch: 15, Batch: 250, Loss: 5.3402561378479
Epoch: 15, Batch: 500, Loss: 5.350950902938843
Epoch: 15, Batch: 750, Loss: 5.334013589859008
Epoch: 15, Batch: 1000, Loss: 5.351654914855957
Epoch: 15, Batch: 1250, Loss: 5.335844078063965
Epoch: 15, Batch: 1500, Loss: 5.342991451263428
Epoch: 15, Batch: 1750, Loss: 5.33199540901184
Epoch: 15, Batch: 2000, Loss: 5.297236173629761
Epoch: 15, Batch: 2250, Loss: 5.372129344940186
Epoch: 15, Batch: 2500, Loss: 5.4101220169067386
Epoch: 15, Batch: 2750, Loss: 5.379785680770874
Epoch: 15, Batch: 3000, Loss: 5.373620220184327
Epoch: 15, Batch: 3250, Loss: 5.296106435775757
Epoch: 15, Batch: 3500, Loss: 5.355415662765503
Epoch: 15, Batch: 3750, Loss: 5.348542940139771
Epoch: 15, Batch: 4000, Loss: 5.336930505752563
Epoch: 15, Batch: 4250, Loss: 5.356137092590332
Epoch: 15, Batch: 4500, Loss: 5.310609008789062
Epoch: 15, Batch: 4750, Loss: 5.362306743621827
Epoch: 15, Batch: 5000, Loss: 5.362751066207886
Epoch: 15, Batch: 5250, Loss: 5.349703008651733
Epoch: 15, Batch: 5500, Loss: 5.3794691696167
Epoch: 15, Batch: 5750, Loss: 5.349260190963745
Epoch: 15, Batch: 6000, Loss: 5.365667036056519
Epoch: 15, Batch: 6250, Loss: 5.339194169998169
Epoch: 15, Batch: 6500, Loss: 5.3799922676086425
Epoch: 15, Batch: 6750, Loss: 5.369443435668945
Epoch: 15, Batch: 7000, Loss: 5.382749435424805
Epoch: 15, Batch: 7250, Loss: 5.302865510940552
Epoch: 15, Batch: 7500, Loss: 5.3528384017944335
Epoch: 15, Batch: 7750, Loss: 5.345678098678589
Epoch: 15, Batch: 8000, Loss: 5.312740767478943
Epoch: 15, Batch: 8250, Loss: 5.355139768600464
Epoch: 15, Val loss: 5.437605746600061 Perplexity: 229.89110645165508
Model saved at Epoch:  15
Epoch: 16, Batch: 250, Loss: 5.314864320755005
Epoch: 16, Batch: 500, Loss: 5.325635364532471
Epoch: 16, Batch: 750, Loss: 5.321962007522583
Epoch: 16, Batch: 1000, Loss: 5.28131855392456
Epoch: 16, Batch: 1250, Loss: 5.342554298400879
Epoch: 16, Batch: 1500, Loss: 5.274675802230835
Epoch: 16, Batch: 1750, Loss: 5.343338430404663
Epoch: 16, Batch: 2000, Loss: 5.29520862197876
Epoch: 16, Batch: 2250, Loss: 5.360177171707154
Epoch: 16, Batch: 2500, Loss: 5.331999879837036
Epoch: 16, Batch: 2750, Loss: 5.305347972869873
Epoch: 16, Batch: 3000, Loss: 5.332895639419555
Epoch: 16, Batch: 3250, Loss: 5.296086345672608
Epoch: 16, Batch: 3500, Loss: 5.336508260726928
Epoch: 16, Batch: 3750, Loss: 5.3738447265625
Epoch: 16, Batch: 4000, Loss: 5.3325151996612545
Epoch: 16, Batch: 4250, Loss: 5.3848254661560055
Epoch: 16, Batch: 4500, Loss: 5.316304792404175
Epoch: 16, Batch: 4750, Loss: 5.315864868164063
Epoch: 16, Batch: 5000, Loss: 5.338741550445556
Epoch: 16, Batch: 5250, Loss: 5.3229040431976316
Epoch: 16, Batch: 5500, Loss: 5.274708055496216
Epoch: 16, Batch: 5750, Loss: 5.277437791824341
Epoch: 16, Batch: 6000, Loss: 5.373739410400391
Epoch: 16, Batch: 6250, Loss: 5.326322931289673
Epoch: 16, Batch: 6500, Loss: 5.324287477493286
Epoch: 16, Batch: 6750, Loss: 5.3173616771698
Epoch: 16, Batch: 7000, Loss: 5.35003085899353
Epoch: 16, Batch: 7250, Loss: 5.302585935592651
Epoch: 16, Batch: 7500, Loss: 5.338861621856689
Epoch: 16, Batch: 7750, Loss: 5.344910831451416
Epoch: 16, Batch: 8000, Loss: 5.322650831222534
Epoch: 16, Batch: 8250, Loss: 5.373141471862793
Epoch: 16, Val loss: 5.420645807193234 Perplexity: 226.0250439776443
Model saved at Epoch:  16
Epoch: 17, Batch: 250, Loss: 5.31270366859436
Epoch: 17, Batch: 500, Loss: 5.280124382019043
Epoch: 17, Batch: 750, Loss: 5.256553070068359
Epoch: 17, Batch: 1000, Loss: 5.281121047973633
Epoch: 17, Batch: 1250, Loss: 5.286882472991944
Epoch: 17, Batch: 1500, Loss: 5.280583938598633
Epoch: 17, Batch: 1750, Loss: 5.290808498382568
Epoch: 17, Batch: 2000, Loss: 5.286213983535767
Epoch: 17, Batch: 2250, Loss: 5.295758234024047
Epoch: 17, Batch: 2500, Loss: 5.3025657081604
Epoch: 17, Batch: 2750, Loss: 5.285045694351196
Epoch: 17, Batch: 3000, Loss: 5.342573297500611
Epoch: 17, Batch: 3250, Loss: 5.306643013000488
Epoch: 17, Batch: 3500, Loss: 5.28089260673523
Epoch: 17, Batch: 3750, Loss: 5.319390895843505
Epoch: 17, Batch: 4000, Loss: 5.315425281524658
Epoch: 17, Batch: 4250, Loss: 5.299499504089355
Epoch: 17, Batch: 4500, Loss: 5.3287783679962155
Epoch: 17, Batch: 4750, Loss: 5.315386318206787
Epoch: 17, Batch: 5000, Loss: 5.3118291797637935
Epoch: 17, Batch: 5250, Loss: 5.333550674438476
Epoch: 17, Batch: 5500, Loss: 5.334240335464478
Epoch: 17, Batch: 5750, Loss: 5.322689121246338
Epoch: 17, Batch: 6000, Loss: 5.317287172317505
Epoch: 17, Batch: 6250, Loss: 5.304110021591186
Epoch: 17, Batch: 6500, Loss: 5.3079796962738035
Epoch: 17, Batch: 6750, Loss: 5.273222507476807
Epoch: 17, Batch: 7000, Loss: 5.308039716720581
Epoch: 17, Batch: 7250, Loss: 5.290168529510498
Epoch: 17, Batch: 7500, Loss: 5.291120101928711
Epoch: 17, Batch: 7750, Loss: 5.312452033996582
Epoch: 17, Batch: 8000, Loss: 5.295409248352051
Epoch: 17, Batch: 8250, Loss: 5.315953290939331
Epoch: 17, Val loss: 5.4087736119276535 Perplexity: 223.35749667413856
Model saved at Epoch:  17
Epoch: 18, Batch: 250, Loss: 5.254744348526001
Epoch: 18, Batch: 500, Loss: 5.233076524734497
Epoch: 18, Batch: 750, Loss: 5.243250686645508
Epoch: 18, Batch: 1000, Loss: 5.269636240005493
Epoch: 18, Batch: 1250, Loss: 5.275171743392944
Epoch: 18, Batch: 1500, Loss: 5.207150276184082
Epoch: 18, Batch: 1750, Loss: 5.278471006393433
Epoch: 18, Batch: 2000, Loss: 5.326304698944091
Epoch: 18, Batch: 2250, Loss: 5.27125824546814
Epoch: 18, Batch: 2500, Loss: 5.2795267505645755
Epoch: 18, Batch: 2750, Loss: 5.237938505172729
Epoch: 18, Batch: 3000, Loss: 5.316303316116333
Epoch: 18, Batch: 3250, Loss: 5.297977630615234
Epoch: 18, Batch: 3500, Loss: 5.2838316326141355
Epoch: 18, Batch: 3750, Loss: 5.275807901382446
Epoch: 18, Batch: 4000, Loss: 5.291575811386108
Epoch: 18, Batch: 4250, Loss: 5.28558755683899
Epoch: 18, Batch: 4500, Loss: 5.274015796661377
Epoch: 18, Batch: 4750, Loss: 5.296738309860229
Epoch: 18, Batch: 5000, Loss: 5.2790377330780025
Epoch: 18, Batch: 5250, Loss: 5.2544467086791995
Epoch: 18, Batch: 5500, Loss: 5.28422317314148
Epoch: 18, Batch: 5750, Loss: 5.299749210357666
Epoch: 18, Batch: 6000, Loss: 5.2571934280395505
Epoch: 18, Batch: 6250, Loss: 5.305137985229492
Epoch: 18, Batch: 6500, Loss: 5.310477815628052
Epoch: 18, Batch: 6750, Loss: 5.281573053359986
Epoch: 18, Batch: 7000, Loss: 5.321566953659057
Epoch: 18, Batch: 7250, Loss: 5.2832599601745605
Epoch: 18, Batch: 7500, Loss: 5.28565270614624
Epoch: 18, Batch: 7750, Loss: 5.264510688781738
Epoch: 18, Batch: 8000, Loss: 5.303590726852417
Epoch: 18, Batch: 8250, Loss: 5.279325662612915
Epoch: 18, Val loss: 5.395464367509277 Perplexity: 220.40447201217495
Model saved at Epoch:  18
Epoch: 19, Batch: 250, Loss: 5.252767601013184
Epoch: 19, Batch: 500, Loss: 5.265190841674805
Epoch: 19, Batch: 750, Loss: 5.249564704895019
Epoch: 19, Batch: 1000, Loss: 5.214402946472168
Epoch: 19, Batch: 1250, Loss: 5.293644227981567
Epoch: 19, Batch: 1500, Loss: 5.2607004737854
Epoch: 19, Batch: 1750, Loss: 5.235432195663452
Epoch: 19, Batch: 2000, Loss: 5.246648611068726
Epoch: 19, Batch: 2250, Loss: 5.261586973190307
Epoch: 19, Batch: 2500, Loss: 5.263015268325805
Epoch: 19, Batch: 2750, Loss: 5.263172063827515
Epoch: 19, Batch: 3000, Loss: 5.280583641052246
Epoch: 19, Batch: 3250, Loss: 5.222357845306396
Epoch: 19, Batch: 3500, Loss: 5.300849521636963
Epoch: 19, Batch: 3750, Loss: 5.248125095367431
Epoch: 19, Batch: 4000, Loss: 5.299864374160767
Epoch: 19, Batch: 4250, Loss: 5.259299379348755
Epoch: 19, Batch: 4500, Loss: 5.260702224731445
Epoch: 19, Batch: 4750, Loss: 5.213882478713989
Epoch: 19, Batch: 5000, Loss: 5.2555813865661625
Epoch: 19, Batch: 5250, Loss: 5.24558491897583
Epoch: 19, Batch: 5500, Loss: 5.2587230052948
Epoch: 19, Batch: 5750, Loss: 5.262952875137329
Epoch: 19, Batch: 6000, Loss: 5.292167276382446
Epoch: 19, Batch: 6250, Loss: 5.265335399627686
Epoch: 19, Batch: 6500, Loss: 5.235842191696167
Epoch: 19, Batch: 6750, Loss: 5.258827827453613
Epoch: 19, Batch: 7000, Loss: 5.215920621871948
Epoch: 19, Batch: 7250, Loss: 5.2512392272949215
Epoch: 19, Batch: 7500, Loss: 5.23149365234375
Epoch: 19, Batch: 7750, Loss: 5.263638343811035
Epoch: 19, Batch: 8000, Loss: 5.295067018508911
Epoch: 19, Batch: 8250, Loss: 5.251425901412964
Epoch: 19, Val loss: 5.38486540181629 Perplexity: 218.08074885923392
Model saved at Epoch:  19
Epoch: 20, Batch: 250, Loss: 5.2595670166015625
Epoch: 20, Batch: 500, Loss: 5.204395938873291
Epoch: 20, Batch: 750, Loss: 5.234681166648865
Epoch: 20, Batch: 1000, Loss: 5.212404508590698
Epoch: 20, Batch: 1250, Loss: 5.242853240966797
Epoch: 20, Batch: 1500, Loss: 5.229291738510132
Epoch: 20, Batch: 1750, Loss: 5.232060939788818
Epoch: 20, Batch: 2000, Loss: 5.248928894042969
Epoch: 20, Batch: 2250, Loss: 5.2469024696350095
Epoch: 20, Batch: 2500, Loss: 5.223186647415161
Epoch: 20, Batch: 2750, Loss: 5.232130182266236
Epoch: 20, Batch: 3000, Loss: 5.215759073257447
Epoch: 20, Batch: 3250, Loss: 5.227197834014893
Epoch: 20, Batch: 3500, Loss: 5.275728525161743
Epoch: 20, Batch: 3750, Loss: 5.194961492538452
Epoch: 20, Batch: 4000, Loss: 5.211354314804077
Epoch: 20, Batch: 4250, Loss: 5.216772336959838
Epoch: 20, Batch: 4500, Loss: 5.234352146148682
Epoch: 20, Batch: 4750, Loss: 5.211168584823608
Epoch: 20, Batch: 5000, Loss: 5.257091718673706
Epoch: 20, Batch: 5250, Loss: 5.248059568405151
Epoch: 20, Batch: 5500, Loss: 5.226130483627319
Epoch: 20, Batch: 5750, Loss: 5.251525735855102
Epoch: 20, Batch: 6000, Loss: 5.257803260803223
Epoch: 20, Batch: 6250, Loss: 5.236506616592407
Epoch: 20, Batch: 6500, Loss: 5.23389347076416
Epoch: 20, Batch: 6750, Loss: 5.2296709575653075
Epoch: 20, Batch: 7000, Loss: 5.263615087509155
Epoch: 20, Batch: 7250, Loss: 5.251788896560669
Epoch: 20, Batch: 7500, Loss: 5.257560400009155
Epoch: 20, Batch: 7750, Loss: 5.216505113601684
Epoch: 20, Batch: 8000, Loss: 5.230820266723633
Epoch: 20, Batch: 8250, Loss: 5.2654320373535155
Epoch: 20, Val loss: 5.364055423181298 Perplexity: 213.58938778157747
Model saved at Epoch:  20
Epoch: 21, Batch: 250, Loss: 5.16523928642273
Epoch: 21, Batch: 500, Loss: 5.191615652084351
Epoch: 21, Batch: 750, Loss: 5.198957006454468
Epoch: 21, Batch: 1000, Loss: 5.191656536102295
Epoch: 21, Batch: 1250, Loss: 5.185189733505249
Epoch: 21, Batch: 1500, Loss: 5.20835391998291
Epoch: 21, Batch: 1750, Loss: 5.230506950378418
Epoch: 21, Batch: 2000, Loss: 5.225702684402465
Epoch: 21, Batch: 2250, Loss: 5.241144457817078
Epoch: 21, Batch: 2500, Loss: 5.208704532623291
Epoch: 21, Batch: 2750, Loss: 5.208497928619384
Epoch: 21, Batch: 3000, Loss: 5.1901042289733885
Epoch: 21, Batch: 3250, Loss: 5.200919351577759
Epoch: 21, Batch: 3500, Loss: 5.205314849853516
Epoch: 21, Batch: 3750, Loss: 5.2539654655456545
Epoch: 21, Batch: 4000, Loss: 5.225732725143432
Epoch: 21, Batch: 4250, Loss: 5.262598836898804
Epoch: 21, Batch: 4500, Loss: 5.259120014190674
Epoch: 21, Batch: 4750, Loss: 5.2144904174804685
Epoch: 21, Batch: 5000, Loss: 5.2052924499511715
Epoch: 21, Batch: 5250, Loss: 5.20820133972168
Epoch: 21, Batch: 5500, Loss: 5.261067985534668
Epoch: 21, Batch: 5750, Loss: 5.217865478515625
Epoch: 21, Batch: 6000, Loss: 5.227118713378906
Epoch: 21, Batch: 6250, Loss: 5.188794082641602
Epoch: 21, Batch: 6500, Loss: 5.227400718688965
Epoch: 21, Batch: 6750, Loss: 5.203840562820434
Epoch: 21, Batch: 7000, Loss: 5.195037578582764
Epoch: 21, Batch: 7250, Loss: 5.229005052566528
Epoch: 21, Batch: 7500, Loss: 5.172434698104858
Epoch: 21, Batch: 7750, Loss: 5.2497149848937985
Epoch: 21, Batch: 8000, Loss: 5.188581337928772
Epoch: 21, Batch: 8250, Loss: 5.241473751068115
Epoch: 21, Val loss: 5.357857188883356 Perplexity: 212.26960509899138
Model saved at Epoch:  21
Epoch: 22, Batch: 250, Loss: 5.154763809204102
Epoch: 22, Batch: 500, Loss: 5.218883773803711
Epoch: 22, Batch: 750, Loss: 5.170004495620727
Epoch: 22, Batch: 1000, Loss: 5.196420276641846
Epoch: 22, Batch: 1250, Loss: 5.215319324493408
Epoch: 22, Batch: 1500, Loss: 5.202920846939087
Epoch: 22, Batch: 1750, Loss: 5.201201509475708
Epoch: 22, Batch: 2000, Loss: 5.144017915725708
Epoch: 22, Batch: 2250, Loss: 5.193849744796753
Epoch: 22, Batch: 2500, Loss: 5.169067903518677
Epoch: 22, Batch: 2750, Loss: 5.168191904067993
Epoch: 22, Batch: 3000, Loss: 5.229178722381592
Epoch: 22, Batch: 3250, Loss: 5.19459831237793
Epoch: 22, Batch: 3500, Loss: 5.168747200012207
Epoch: 22, Batch: 3750, Loss: 5.18924294090271
Epoch: 22, Batch: 4000, Loss: 5.202775945663452
Epoch: 22, Batch: 4250, Loss: 5.179987522125244
Epoch: 22, Batch: 4500, Loss: 5.182209142684936
Epoch: 22, Batch: 4750, Loss: 5.2001742763519285
Epoch: 22, Batch: 5000, Loss: 5.23234161567688
Epoch: 22, Batch: 5250, Loss: 5.191024880409241
Epoch: 22, Batch: 5500, Loss: 5.184108207702637
Epoch: 22, Batch: 5750, Loss: 5.2331910381317135
Epoch: 22, Batch: 6000, Loss: 5.213928091049194
Epoch: 22, Batch: 6250, Loss: 5.22095677947998
Epoch: 22, Batch: 6500, Loss: 5.238860607147217
Epoch: 22, Batch: 6750, Loss: 5.220690099716187
Epoch: 22, Batch: 7000, Loss: 5.202712985992432
Epoch: 22, Batch: 7250, Loss: 5.220999034881592
Epoch: 22, Batch: 7500, Loss: 5.187688869476318
Epoch: 22, Batch: 7750, Loss: 5.210947479248047
Epoch: 22, Batch: 8000, Loss: 5.161080965042114
Epoch: 22, Batch: 8250, Loss: 5.195256042480469
Epoch: 22, Val loss: 5.353791757010482 Perplexity: 211.40838927407358
Model saved at Epoch:  22
Epoch: 23, Batch: 250, Loss: 5.191173440933228
Epoch: 23, Batch: 500, Loss: 5.151105104446411
Epoch: 23, Batch: 750, Loss: 5.137632402420044
Epoch: 23, Batch: 1000, Loss: 5.177132440567017
Epoch: 23, Batch: 1250, Loss: 5.165406986236572
Epoch: 23, Batch: 1500, Loss: 5.165396001815796
Epoch: 23, Batch: 1750, Loss: 5.14654495048523
Epoch: 23, Batch: 2000, Loss: 5.209038537979126
Epoch: 23, Batch: 2250, Loss: 5.164875770568847
Epoch: 23, Batch: 2500, Loss: 5.173853658676148
Epoch: 23, Batch: 2750, Loss: 5.16591247177124
Epoch: 23, Batch: 3000, Loss: 5.204138729095459
Epoch: 23, Batch: 3250, Loss: 5.189674411773682
Epoch: 23, Batch: 3500, Loss: 5.165456867218017
Epoch: 23, Batch: 3750, Loss: 5.1973003463745115
Epoch: 23, Batch: 4000, Loss: 5.20840075302124
Epoch: 23, Batch: 4250, Loss: 5.186775644302368
Epoch: 23, Batch: 4500, Loss: 5.149516618728637
Epoch: 23, Batch: 4750, Loss: 5.185077096939087
Epoch: 23, Batch: 5000, Loss: 5.155715791702271
Epoch: 23, Batch: 5250, Loss: 5.179693561553955
Epoch: 23, Batch: 5500, Loss: 5.152892448425293
Epoch: 23, Batch: 5750, Loss: 5.190275638580323
Epoch: 23, Batch: 6000, Loss: 5.194176218032837
Epoch: 23, Batch: 6250, Loss: 5.198132574081421
Epoch: 23, Batch: 6500, Loss: 5.1599124240875245
Epoch: 23, Batch: 6750, Loss: 5.207719066619873
Epoch: 23, Batch: 7000, Loss: 5.178199684143066
Epoch: 23, Batch: 7250, Loss: 5.185410482406616
Epoch: 23, Batch: 7500, Loss: 5.168556262969971
Epoch: 23, Batch: 7750, Loss: 5.176181165695191
Epoch: 23, Batch: 8000, Loss: 5.18010711479187
Epoch: 23, Batch: 8250, Loss: 5.187111763000488
Epoch: 23, Val loss: 5.340424089750172 Perplexity: 208.60115714568758
Model saved at Epoch:  23
Epoch: 24, Batch: 250, Loss: 5.163171318054199
Epoch: 24, Batch: 500, Loss: 5.12107168006897
Epoch: 24, Batch: 750, Loss: 5.1621310386657715
Epoch: 24, Batch: 1000, Loss: 5.149475484848023
Epoch: 24, Batch: 1250, Loss: 5.159959844589233
Epoch: 24, Batch: 1500, Loss: 5.1444289493560795
Epoch: 24, Batch: 1750, Loss: 5.150938756942749
Epoch: 24, Batch: 2000, Loss: 5.117201732635498
Epoch: 24, Batch: 2250, Loss: 5.167439205169678
Epoch: 24, Batch: 2500, Loss: 5.169925804138184
Epoch: 24, Batch: 2750, Loss: 5.140244136810303
Epoch: 24, Batch: 3000, Loss: 5.162657661437988
Epoch: 24, Batch: 3250, Loss: 5.142162826538086
Epoch: 24, Batch: 3500, Loss: 5.129534358024597
Epoch: 24, Batch: 3750, Loss: 5.156541694641113
Epoch: 24, Batch: 4000, Loss: 5.171281147003174
Epoch: 24, Batch: 4250, Loss: 5.152106317520142
Epoch: 24, Batch: 4500, Loss: 5.165502305984497
Epoch: 24, Batch: 4750, Loss: 5.110875930786133
Epoch: 24, Batch: 5000, Loss: 5.164012107849121
Epoch: 24, Batch: 5250, Loss: 5.156435657501221
Epoch: 24, Batch: 5500, Loss: 5.199275960922241
Epoch: 24, Batch: 5750, Loss: 5.164673749923706
Epoch: 24, Batch: 6000, Loss: 5.1517919788360595
Epoch: 24, Batch: 6250, Loss: 5.162790342330933
Epoch: 24, Batch: 6500, Loss: 5.1580336380004885
Epoch: 24, Batch: 6750, Loss: 5.185755911827087
Epoch: 24, Batch: 7000, Loss: 5.197382062911987
Epoch: 24, Batch: 7250, Loss: 5.150003059387207
Epoch: 24, Batch: 7500, Loss: 5.164844026565552
Epoch: 24, Batch: 7750, Loss: 5.1521141242980955
Epoch: 24, Batch: 8000, Loss: 5.174116920471191
Epoch: 24, Batch: 8250, Loss: 5.177812307357788
Epoch: 24, Val loss: 5.339934458367599 Perplexity: 208.4990444735325
Model saved at Epoch:  24
Epoch: 25, Batch: 250, Loss: 5.124931051254272
Epoch: 25, Batch: 500, Loss: 5.108441694259644
Epoch: 25, Batch: 750, Loss: 5.134545799255371
Epoch: 25, Batch: 1000, Loss: 5.124870641708374
Epoch: 25, Batch: 1250, Loss: 5.118787746429444
Epoch: 25, Batch: 1500, Loss: 5.120410123825073
Epoch: 25, Batch: 1750, Loss: 5.117572843551636
Epoch: 25, Batch: 2000, Loss: 5.114947685241699
Epoch: 25, Batch: 2250, Loss: 5.1483056640625
Epoch: 25, Batch: 2500, Loss: 5.162204183578491
Epoch: 25, Batch: 2750, Loss: 5.182675708770752
Epoch: 25, Batch: 3000, Loss: 5.136582876205444
Epoch: 25, Batch: 3250, Loss: 5.153468118667602
Epoch: 25, Batch: 3500, Loss: 5.149645971298217
Epoch: 25, Batch: 3750, Loss: 5.152937295913696
Epoch: 25, Batch: 4000, Loss: 5.1200378723144535
Epoch: 25, Batch: 4250, Loss: 5.144632055282592
Epoch: 25, Batch: 4500, Loss: 5.080039040565491
Epoch: 25, Batch: 4750, Loss: 5.1567097091674805
Epoch: 25, Batch: 5000, Loss: 5.114421728134155
Epoch: 25, Batch: 5250, Loss: 5.140185210227966
Epoch: 25, Batch: 5500, Loss: 5.151017780303955
Epoch: 25, Batch: 5750, Loss: 5.1410243072509765
Epoch: 25, Batch: 6000, Loss: 5.161761068344116
Epoch: 25, Batch: 6250, Loss: 5.149929523468018
Epoch: 25, Batch: 6500, Loss: 5.153747514724731
Epoch: 25, Batch: 6750, Loss: 5.14406385421753
Epoch: 25, Batch: 7000, Loss: 5.141226455688477
Epoch: 25, Batch: 7250, Loss: 5.1655501346588135
Epoch: 25, Batch: 7500, Loss: 5.1591022567749025
Epoch: 25, Batch: 7750, Loss: 5.174874032974243
Epoch: 25, Batch: 8000, Loss: 5.153970335006714
Epoch: 25, Batch: 8250, Loss: 5.148329549789429
Epoch: 25, Val loss: 5.324503138418694 Perplexity: 205.30632629251838
Model saved at Epoch:  25
Epoch: 26, Batch: 250, Loss: 5.112589612960815
Epoch: 26, Batch: 500, Loss: 5.1076697254180905
Epoch: 26, Batch: 750, Loss: 5.094820963859558
Epoch: 26, Batch: 1000, Loss: 5.090349817276001
Epoch: 26, Batch: 1250, Loss: 5.06693939781189
Epoch: 26, Batch: 1500, Loss: 5.118674600601197
Epoch: 26, Batch: 1750, Loss: 5.113521633148193
Epoch: 26, Batch: 2000, Loss: 5.129599668502808
Epoch: 26, Batch: 2250, Loss: 5.1335944728851315
Epoch: 26, Batch: 2500, Loss: 5.1546629009246825
Epoch: 26, Batch: 2750, Loss: 5.152930196762085
Epoch: 26, Batch: 3000, Loss: 5.110517488479614
Epoch: 26, Batch: 3250, Loss: 5.133442039489746
Epoch: 26, Batch: 3500, Loss: 5.093686122894287
Epoch: 26, Batch: 3750, Loss: 5.0857794589996335
Epoch: 26, Batch: 4000, Loss: 5.139802537918091
Epoch: 26, Batch: 4250, Loss: 5.146951219558716
Epoch: 26, Batch: 4500, Loss: 5.149516191482544
Epoch: 26, Batch: 4750, Loss: 5.139808856964112
Epoch: 26, Batch: 5000, Loss: 5.1413189373016355
Epoch: 26, Batch: 5250, Loss: 5.159310041427612
Epoch: 26, Batch: 5500, Loss: 5.1137968463897705
Epoch: 26, Batch: 5750, Loss: 5.124700695037842
Epoch: 26, Batch: 6000, Loss: 5.124442436218262
Epoch: 26, Batch: 6250, Loss: 5.110528993606567
Epoch: 26, Batch: 6500, Loss: 5.119248542785645
Epoch: 26, Batch: 6750, Loss: 5.137561326980591
Epoch: 26, Batch: 7000, Loss: 5.119649211883545
Epoch: 26, Batch: 7250, Loss: 5.147064226150513
Epoch: 26, Batch: 7500, Loss: 5.171049240112304
Epoch: 26, Batch: 7750, Loss: 5.122778831481933
Epoch: 26, Batch: 8000, Loss: 5.103703821182251
Epoch: 26, Batch: 8250, Loss: 5.136844114303589
Epoch: 26, Val loss: 5.318453659646286 Perplexity: 204.0680791808378
Model saved at Epoch:  26
Epoch: 27, Batch: 250, Loss: 5.123050731658935
Epoch: 27, Batch: 500, Loss: 5.038712812423706
Epoch: 27, Batch: 750, Loss: 5.060482294082641
Epoch: 27, Batch: 1000, Loss: 5.114172022819519
Epoch: 27, Batch: 1250, Loss: 5.096233169555664
Epoch: 27, Batch: 1500, Loss: 5.087396034240722
Epoch: 27, Batch: 1750, Loss: 5.086754243850708
Epoch: 27, Batch: 2000, Loss: 5.102653200149536
Epoch: 27, Batch: 2250, Loss: 5.092033151626587
Epoch: 27, Batch: 2500, Loss: 5.094302579879761
Epoch: 27, Batch: 2750, Loss: 5.1160767517089845
Epoch: 27, Batch: 3000, Loss: 5.123718635559082
Epoch: 27, Batch: 3250, Loss: 5.0997753372192385
Epoch: 27, Batch: 3500, Loss: 5.127129402160644
Epoch: 27, Batch: 3750, Loss: 5.073820331573486
Epoch: 27, Batch: 4000, Loss: 5.077638959884643
Epoch: 27, Batch: 4250, Loss: 5.131463722229004
Epoch: 27, Batch: 4500, Loss: 5.16299916267395
Epoch: 27, Batch: 4750, Loss: 5.084093961715698
Epoch: 27, Batch: 5000, Loss: 5.077575412750244
Epoch: 27, Batch: 5250, Loss: 5.096823810577392
Epoch: 27, Batch: 5500, Loss: 5.160665584564209
Epoch: 27, Batch: 5750, Loss: 5.139221263885498
Epoch: 27, Batch: 6000, Loss: 5.120969541549683
Epoch: 27, Batch: 6250, Loss: 5.1029180240631105
Epoch: 27, Batch: 6500, Loss: 5.1349130096435545
Epoch: 27, Batch: 6750, Loss: 5.0972550621032715
Epoch: 27, Batch: 7000, Loss: 5.097991649627685
Epoch: 27, Batch: 7250, Loss: 5.105914867401123
Epoch: 27, Batch: 7500, Loss: 5.101692127227783
Epoch: 27, Batch: 7750, Loss: 5.147072260856628
Epoch: 27, Batch: 8000, Loss: 5.113296719551086
Epoch: 27, Batch: 8250, Loss: 5.134252044677734
Epoch: 27, Val loss: 5.319182737157089 Perplexity: 204.21691487782817
Epoch: 28, Batch: 250, Loss: 5.085925945281982
Epoch: 28, Batch: 500, Loss: 5.058713532447815
Epoch: 28, Batch: 750, Loss: 5.085592311859131
Epoch: 28, Batch: 1000, Loss: 5.081781837463379
Epoch: 28, Batch: 1250, Loss: 5.0807893772125245
Epoch: 28, Batch: 1500, Loss: 5.0881660957336425
Epoch: 28, Batch: 1750, Loss: 5.092885313034057
Epoch: 28, Batch: 2000, Loss: 5.073516649246216
Epoch: 28, Batch: 2250, Loss: 5.065765112876892
Epoch: 28, Batch: 2500, Loss: 5.088697465896606
Epoch: 28, Batch: 2750, Loss: 5.105528358459472
Epoch: 28, Batch: 3000, Loss: 5.07284052658081
Epoch: 28, Batch: 3250, Loss: 5.105688314437867
Epoch: 28, Batch: 3500, Loss: 5.099735826492309
Epoch: 28, Batch: 3750, Loss: 5.098798974990845
Epoch: 28, Batch: 4000, Loss: 5.089905019760132
Epoch: 28, Batch: 4250, Loss: 5.117356311798096
Epoch: 28, Batch: 4500, Loss: 5.103292340278625
Epoch: 28, Batch: 4750, Loss: 5.0887890672683715
Epoch: 28, Batch: 5000, Loss: 5.10554701423645
Epoch: 28, Batch: 5250, Loss: 5.095693941116333
Epoch: 28, Batch: 5500, Loss: 5.075055660247803
Epoch: 28, Batch: 5750, Loss: 5.108396778106689
Epoch: 28, Batch: 6000, Loss: 5.083364810943603
Epoch: 28, Batch: 6250, Loss: 5.079397230148316
Epoch: 28, Batch: 6500, Loss: 5.066310018539428
Epoch: 28, Batch: 6750, Loss: 5.115389768600464
Epoch: 28, Batch: 7000, Loss: 5.084643377304078
Epoch: 28, Batch: 7250, Loss: 5.086989833831787
Epoch: 28, Batch: 7500, Loss: 5.115005784034729
Epoch: 28, Batch: 7750, Loss: 5.091939771652222
Epoch: 28, Batch: 8000, Loss: 5.129860010147095
Epoch: 28, Batch: 8250, Loss: 5.069773475646973
Epoch: 28, Val loss: 5.306843694724167 Perplexity: 201.71255616820415
Model saved at Epoch:  28
Epoch: 29, Batch: 250, Loss: 5.049146892547608
Epoch: 29, Batch: 500, Loss: 5.0610956249237065
Epoch: 29, Batch: 750, Loss: 5.049652063369751
Epoch: 29, Batch: 1000, Loss: 5.105890232086182
Epoch: 29, Batch: 1250, Loss: 5.0634650669097905
Epoch: 29, Batch: 1500, Loss: 5.057437826156616
Epoch: 29, Batch: 1750, Loss: 5.042905150413513
Epoch: 29, Batch: 2000, Loss: 5.075621522903442
Epoch: 29, Batch: 2250, Loss: 5.086693325042725
Epoch: 29, Batch: 2500, Loss: 5.1102152462005614
Epoch: 29, Batch: 2750, Loss: 5.100346273422241
Epoch: 29, Batch: 3000, Loss: 5.098808352470398
Epoch: 29, Batch: 3250, Loss: 5.061468452453613
Epoch: 29, Batch: 3500, Loss: 5.086994318008423
Epoch: 29, Batch: 3750, Loss: 5.087186996459961
Epoch: 29, Batch: 4000, Loss: 5.069881235122681
Epoch: 29, Batch: 4250, Loss: 5.025536361694336
Epoch: 29, Batch: 4500, Loss: 5.060416589736938
Epoch: 29, Batch: 4750, Loss: 5.1054237213134765
Epoch: 29, Batch: 5000, Loss: 5.1087100830078125
Epoch: 29, Batch: 5250, Loss: 5.096369297027588
Epoch: 29, Batch: 5500, Loss: 5.069357307434082
Epoch: 29, Batch: 5750, Loss: 5.025800519943237
Epoch: 29, Batch: 6000, Loss: 5.127138710021972
Epoch: 29, Batch: 6250, Loss: 5.07538946723938
Epoch: 29, Batch: 6500, Loss: 5.058450593948364
Epoch: 29, Batch: 6750, Loss: 5.109460975646972
Epoch: 29, Batch: 7000, Loss: 5.041569177627563
Epoch: 29, Batch: 7250, Loss: 5.0601783618927
Epoch: 29, Batch: 7500, Loss: 5.090326681137085
Epoch: 29, Batch: 7750, Loss: 5.062530021667481
Epoch: 29, Batch: 8000, Loss: 5.093316259384156
Epoch: 29, Batch: 8250, Loss: 5.051375767707825
Epoch: 29, Val loss: 5.298995725106727 Perplexity: 200.13571773917863
Model saved at Epoch:  29
Epoch: 30, Batch: 250, Loss: 5.0152459239959715
Epoch: 30, Batch: 500, Loss: 5.0195647220611574
Epoch: 30, Batch: 750, Loss: 5.089131036758423
Epoch: 30, Batch: 1000, Loss: 5.035922910690307
Epoch: 30, Batch: 1250, Loss: 5.041831546783447
Epoch: 30, Batch: 1500, Loss: 5.099540658950806
Epoch: 30, Batch: 1750, Loss: 5.016931266784668
Epoch: 30, Batch: 2000, Loss: 5.060548791885376
Epoch: 30, Batch: 2250, Loss: 5.069532117843628
Epoch: 30, Batch: 2500, Loss: 5.047637469291687
Epoch: 30, Batch: 2750, Loss: 5.0649191226959225
Epoch: 30, Batch: 3000, Loss: 5.008196779251099
Epoch: 30, Batch: 3250, Loss: 5.070331186294555
Epoch: 30, Batch: 3500, Loss: 5.10380297088623
Epoch: 30, Batch: 3750, Loss: 5.084139364242554
Epoch: 30, Batch: 4000, Loss: 5.069144153594971
Epoch: 30, Batch: 4250, Loss: 5.081553659439087
Epoch: 30, Batch: 4500, Loss: 5.051663326263427
Epoch: 30, Batch: 4750, Loss: 5.065268339157105
Epoch: 30, Batch: 5000, Loss: 5.0192741184234615
Epoch: 30, Batch: 5250, Loss: 5.070517362594605
Epoch: 30, Batch: 5500, Loss: 5.060190670013427
Epoch: 30, Batch: 5750, Loss: 5.066787546157837
Epoch: 30, Batch: 6000, Loss: 5.053136493682861
Epoch: 30, Batch: 6250, Loss: 5.057153940200806
Epoch: 30, Batch: 6500, Loss: 5.063264081954956
Epoch: 30, Batch: 6750, Loss: 5.046867771148682
Epoch: 30, Batch: 7000, Loss: 5.076539596557617
Epoch: 30, Batch: 7250, Loss: 5.067885484695434
Epoch: 30, Batch: 7500, Loss: 5.071569801330567
Epoch: 30, Batch: 7750, Loss: 5.044973157882691
Epoch: 30, Batch: 8000, Loss: 5.091171920776367
Epoch: 30, Batch: 8250, Loss: 5.040039081573486
Epoch: 30, Val loss: 5.304423224654182 Perplexity: 201.22490737099938
Test loss: 5.3157648333947956
Test Perplexity: 203.52011259605428
Ignored 2517 sentences due to length
Overall Perplexity: 143.02995201102905
Ignored 751 sentences due to length
Overall Perplexity: 211.7381600513458
Ignored 376 sentences due to length
Overall Perplexity: 211.42966722100843
