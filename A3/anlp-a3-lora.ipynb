{"cells":[{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.255449Z","iopub.status.busy":"2024-10-29T12:14:06.255019Z","iopub.status.idle":"2024-10-29T12:14:06.267368Z","shell.execute_reply":"2024-10-29T12:14:06.266466Z","shell.execute_reply.started":"2024-10-29T12:14:06.255398Z"},"trusted":true},"outputs":[],"source":["import os\n","import re\n","import csv\n","import time\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","from itertools import islice\n","from torchinfo import summary as modelinfo\n","# import matplotlib.pyplot as plt\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","\n","import torch\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n","\n","\n","try: \n","    from rouge_score import rouge_scorer\n","except:\n","    %pip install rouge-score==0.1.2\n","    from rouge_score import rouge_scorer\n","    \n","try:\n","    from peft import get_peft_model, LoraConfig, TaskType\n","except:\n","    %pip install peft==0.13.2\n","    from peft import get_peft_model, LoraConfig, TaskType"]},{"cell_type":"markdown","metadata":{},"source":["## Config"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.269551Z","iopub.status.busy":"2024-10-29T12:14:06.269211Z","iopub.status.idle":"2024-10-29T12:14:06.279278Z","shell.execute_reply":"2024-10-29T12:14:06.278463Z","shell.execute_reply.started":"2024-10-29T12:14:06.269518Z"},"trusted":true},"outputs":[],"source":["train_filepath = \"/kaggle/input/cnn_dailymail/train.csv\"\n","val_filepath = \"/kaggle/input/cnn_dailymail/validation.csv\"\n","test_filepath = \"/kaggle/input/cnn_dailymail/test.csv\"\n","\n","# train_filepath = \"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\"\n","# val_filepath = \"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\"\n","# test_filepath = \"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\"\n","\n","max_train_samples = 5000\n","max_val_samples = 1000\n","max_test_samples = 1000"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.281014Z","iopub.status.busy":"2024-10-29T12:14:06.280645Z","iopub.status.idle":"2024-10-29T12:14:06.291606Z","shell.execute_reply":"2024-10-29T12:14:06.290470Z","shell.execute_reply.started":"2024-10-29T12:14:06.280973Z"},"trusted":true},"outputs":[],"source":["to_train = True\n","model_name = \"EleutherAI/gpt-neo-125m\"\n","tuning_type = \"lora\"\n","\n","lr = 6e-5\n","epochs = 5\n","mini_batch_size = 32\n","\n","# For LORA\n","r = 16\n","alpha = 32"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.292880Z","iopub.status.busy":"2024-10-29T12:14:06.292595Z","iopub.status.idle":"2024-10-29T12:14:06.302299Z","shell.execute_reply":"2024-10-29T12:14:06.301476Z","shell.execute_reply.started":"2024-10-29T12:14:06.292850Z"},"trusted":true},"outputs":[],"source":["assert tuning_type in [\"none\", \"last\", \"lora\"], \"Invalid tuning type\"\n","if tuning_type == \"none\": to_train=False\n","os.makedirs(\"models\", exist_ok=True)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.305974Z","iopub.status.busy":"2024-10-29T12:14:06.305227Z","iopub.status.idle":"2024-10-29T12:14:06.316096Z","shell.execute_reply":"2024-10-29T12:14:06.315250Z","shell.execute_reply.started":"2024-10-29T12:14:06.305941Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Random Seed: 42\n"]}],"source":["random_seed = 42\n","\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","print(\"Using Random Seed:\", random_seed)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.317534Z","iopub.status.busy":"2024-10-29T12:14:06.317151Z","iopub.status.idle":"2024-10-29T12:14:06.327152Z","shell.execute_reply":"2024-10-29T12:14:06.326216Z","shell.execute_reply.started":"2024-10-29T12:14:06.317489Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Utils"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.328362Z","iopub.status.busy":"2024-10-29T12:14:06.328107Z","iopub.status.idle":"2024-10-29T12:14:06.338608Z","shell.execute_reply":"2024-10-29T12:14:06.337804Z","shell.execute_reply.started":"2024-10-29T12:14:06.328332Z"},"trusted":true},"outputs":[],"source":["dm_single_close_quote = \"\\u2019\"  # unicode\n","dm_double_close_quote = \"\\u201d\"\n","\n","# acceptable ways to end a sentence\n","END_TOKENS = [\n","    \".\",\n","    \"!\",\n","    \"?\",\n","    \"'\",\n","    \"`\",\n","    '\"',\n","    dm_single_close_quote,\n","    dm_double_close_quote,\n","    \")\",\n","]"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.339903Z","iopub.status.busy":"2024-10-29T12:14:06.339619Z","iopub.status.idle":"2024-10-29T12:14:06.350089Z","shell.execute_reply":"2024-10-29T12:14:06.349180Z","shell.execute_reply.started":"2024-10-29T12:14:06.339873Z"},"trusted":true},"outputs":[],"source":["def remove_period(line):\n","    if line[-1] in END_TOKENS:\n","        return line[:-1]\n","    return line\n","\n","\n","def remove_punctuations(line):\n","    return re.sub(r\"[^\\w\\s]\", \" \", line)\n","\n","\n","def clean_data(data):\n","    for i in range(len(data)):\n","        data[i][\"article\"] = remove_punctuations(data[i][\"article\"])\n","        data[i][\"highlights\"] = remove_punctuations(data[i][\"highlights\"])\n","\n","        data[i][\"article\"] = re.sub(r\"\\s+\", \" \", data[i][\"article\"]).strip()\n","        data[i][\"highlights\"] = re.sub(r\"\\s+\", \" \", data[i][\"highlights\"]).strip()\n","\n","    return data"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.351486Z","iopub.status.busy":"2024-10-29T12:14:06.351174Z","iopub.status.idle":"2024-10-29T12:14:06.360388Z","shell.execute_reply":"2024-10-29T12:14:06.359655Z","shell.execute_reply.started":"2024-10-29T12:14:06.351455Z"},"trusted":true},"outputs":[],"source":["def read_data(filepath, max_length=None):\n","    with open(filepath, \"r\") as f:\n","        reader = csv.DictReader(f)\n","        if max_length is not None:\n","            rows = islice(reader, max_length)\n","        else:\n","            rows = reader\n","        data = list(rows)\n","    \n","    return clean_data(data)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.361607Z","iopub.status.busy":"2024-10-29T12:14:06.361304Z","iopub.status.idle":"2024-10-29T12:14:06.371931Z","shell.execute_reply":"2024-10-29T12:14:06.371141Z","shell.execute_reply.started":"2024-10-29T12:14:06.361575Z"},"trusted":true},"outputs":[],"source":["def freeze_last_layer(model):\n","    assert tuning_type == \"last\", \"Only last layer fine-tuning is supported\"\n","\n","    for param in model.parameters():\n","        param.requires_grad = False\n","    \n","    for param in model.lm_head.parameters():\n","        param.requires_grad = True\n","\n","def lora(model):\n","    assert tuning_type == \"lora\"\n","\n","    config = LoraConfig(\n","        task_type=TaskType.CAUSAL_LM,\n","        inference_mode=False,\n","        r=r,\n","        lora_alpha=alpha,\n","        bias=\"none\"\n","    )\n","\n","    model = get_peft_model(model, config)\n","\n","    return model"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.373332Z","iopub.status.busy":"2024-10-29T12:14:06.372962Z","iopub.status.idle":"2024-10-29T12:14:06.383711Z","shell.execute_reply":"2024-10-29T12:14:06.382890Z","shell.execute_reply.started":"2024-10-29T12:14:06.373284Z"},"trusted":true},"outputs":[],"source":["def make_tokenizer(model_name):\n","    \"\"\"Returns GPT2 tokenizer after adding separator and padding tokens\"\"\"\n","    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","    special_tokens = {\"pad_token\": \"<pad>\", \"sep_token\": \"<sep>\"}\n","    tokenizer.add_special_tokens(special_tokens)\n","    return tokenizer\n","\n","\n","def make_model(model_name, len_tokenizer, tuning_type=\"last\"):\n","    model = GPTNeoForCausalLM.from_pretrained(model_name)\n","    model.resize_token_embeddings(len_tokenizer)\n","\n","    if tuning_type == \"last\":\n","        freeze_last_layer(model)\n","    elif tuning_type == \"lora\":\n","        model = lora(model)\n","\n","    model.to(device)\n","    return model"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.385442Z","iopub.status.busy":"2024-10-29T12:14:06.384792Z","iopub.status.idle":"2024-10-29T12:14:06.401845Z","shell.execute_reply":"2024-10-29T12:14:06.401017Z","shell.execute_reply.started":"2024-10-29T12:14:06.385380Z"},"trusted":true},"outputs":[],"source":["class SummarizationDataset(Dataset):\n","    def __init__(self, data, tokenizer, article_max_length=512, summary_max_length=128, type=\"train\"):\n","        assert type in [\"train\", \"val\", \"test\"], \"Invalid dataset type\"\n","\n","        self.type = type\n","        if type == \"test\":\n","            summary_max_length = 0\n","\n","        self.tokenizer = tokenizer\n","        self.article_max_length = article_max_length\n","        self.summary_max_length = summary_max_length\n","        self.instruction_tokens = self.tokenizer.encode(\"summarize: \")\n","        self.sep_token = self.tokenizer.encode(\" \" + self.tokenizer.sep_token + \" \")\n","        self.max_length = article_max_length + summary_max_length + len(self.instruction_tokens) + len(self.sep_token)\n","        \n","        self.processed_data = self._process_all_data(data, 4)\n","\n","    def _attention_mask(self, padding_length):\n","        return [1] * (self.max_length - padding_length) + [0] * padding_length\n","\n","    def _process_data(self, data):\n","        article_ids = self.tokenizer.encode(\n","            data[\"article\"], truncation=True, max_length=self.article_max_length\n","        )\n","        if self.type != \"test\":\n","            abstract_ids = self.tokenizer.encode(\n","                data[\"highlights\"], truncation=True, max_length=self.summary_max_length\n","            )\n","        else:\n","            abstract_ids = []\n","\n","        # Combine all components\n","        content = self.instruction_tokens + article_ids + self.sep_token + abstract_ids\n","\n","        if self.type != \"test\":\n","            padding_length = self.max_length - len(content)\n","            padded_content = content + [self.tokenizer.pad_token_id] * padding_length\n","        else:\n","            padding_length = self.max_length - len(content)\n","            padded_content = [self.tokenizer.pad_token_id] * padding_length + content\n","\n","        return {\n","            \"text\": padded_content,\n","            \"sep_idx\": len(article_ids),\n","            \"article_len\": len(article_ids),\n","            \"summary_len\": len(abstract_ids),\n","            \"attention_mask\": self._attention_mask(padding_length),\n","            \"highlights\": data[\"highlights\"],\n","        }\n","    \n","    def _process_all_data(self, data, num_workers):\n","        processed_data = []\n","\n","        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n","            # Submit tasks to the thread pool\n","            futures = [executor.submit(self._process_data, item) for item in data]\n","            \n","            # Use tqdm to track the progress\n","            for future in tqdm(as_completed(futures), total=len(data), desc=\"Processing Data\"):\n","                processed_data.append(future.result())\n","\n","        return processed_data\n","\n","    def __len__(self):\n","        return len(self.processed_data)\n","\n","    def __getitem__(self, idx):\n","        processed_item = self.processed_data[idx]\n","        return {\n","            \"article\": torch.tensor(processed_item[\"text\"]),\n","            \"sep_idx\": processed_item[\"sep_idx\"],\n","            \"article_len\": processed_item[\"article_len\"],\n","            \"summary_len\": processed_item[\"summary_len\"],\n","            \"attention_mask\": torch.tensor(processed_item[\"attention_mask\"]),\n","            \"highlights\": processed_item[\"highlights\"],\n","        }"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.403109Z","iopub.status.busy":"2024-10-29T12:14:06.402856Z","iopub.status.idle":"2024-10-29T12:14:06.418126Z","shell.execute_reply":"2024-10-29T12:14:06.417391Z","shell.execute_reply.started":"2024-10-29T12:14:06.403081Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, val_loader, loss_fn, summary_max_length=128):\n","    \"\"\"\n","    Evaluate the model on validation/test data\n","\n","    Args:\n","        model: The model to evaluate\n","        val_loader: DataLoader for validation data\n","        loss_fn: Loss function (typically CrossEntropyLoss with ignore_index set to pad_token_id)\n","\n","    Returns:\n","        float: Average loss per batch\n","    \"\"\"\n","    model.eval()\n","    total_loss = 0.0\n","    num_batches = 0\n","\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n","            inputs = batch[\"article\"].to(device)\n","            sep_idx = batch[\"sep_idx\"].squeeze()\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","\n","            outputs = model(inputs, attention_mask=attention_mask, labels=inputs)\n","            loss = outputs.loss\n","            # decoded_output = tokenizer.decode(outputs.logits[0].argmax(dim=-1))\n","            # decoded_input = tokenizer.decode(inputs[0])\n","            # print(decoded_input, decoded_output, sep=\"\\n\\n\")\n","\n","            # Get logits and labels for summary portion only\n","            shift_logits = outputs.logits[..., sep_idx:-1, :].contiguous()\n","            shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n","            shift_labels = inputs[..., sep_idx + 1 :].contiguous()\n","            shift_labels = shift_labels.view(-1)\n","\n","            shift_logits = shift_logits[:summary_max_length]\n","            shift_labels = shift_labels[:summary_max_length]\n","            \n","            # print()\n","            # print(tokenizer.decode(shift_logits.argmax(dim=-1)))\n","            # print(shift_labels)\n","\n","            loss = loss_fn(shift_logits, shift_labels)\n","            total_loss += loss.item()\n","            num_batches += 1\n","\n","    return total_loss / (num_batches if num_batches > 0 else 1)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.435015Z","iopub.status.busy":"2024-10-29T12:14:06.434642Z","iopub.status.idle":"2024-10-29T12:14:06.449793Z","shell.execute_reply":"2024-10-29T12:14:06.448925Z","shell.execute_reply.started":"2024-10-29T12:14:06.434984Z"},"trusted":true},"outputs":[],"source":["def train(\n","    model,\n","    optimiser,\n","    loss_fn,\n","    train_loader,\n","    val_loader,\n","    num_epochs,\n","    max_grad_norm=1.0,\n","    mini_batch_size=4,\n","    summary_max_length=128,\n","    save_path=\"models/model.pt\",\n","    print_every=5,\n","):\n","    global_step = 0\n","    best_val_loss = float(\"inf\")\n","    tr_loss = 0.0\n","    last_tr_loss, logging_loss = 0.0, 0.0\n","\n","    model.zero_grad()\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        epoch_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n","\n","        for step, batch in enumerate(epoch_iterator):\n","            inputs = batch[\"article\"].to(device)\n","            sep_idx = batch[\"sep_idx\"].squeeze()\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","\n","            outputs = model(inputs, labels=inputs, attention_mask=attention_mask)\n","\n","            shift_logits = outputs.logits[..., sep_idx:-1, :].contiguous()\n","            shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n","            shift_labels = inputs[..., sep_idx + 1 :].contiguous()\n","            shift_labels = shift_labels.view(-1)\n","\n","            shift_logits = shift_logits[:summary_max_length]\n","            shift_labels = shift_labels[:summary_max_length]\n","\n","            loss = loss_fn(shift_logits, shift_labels)\n","            loss /= mini_batch_size\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","\n","            tr_loss += loss.item()\n","\n","            if (step + 1) % mini_batch_size == 0:\n","                optimiser.step()\n","                model.zero_grad()\n","                global_step += 1\n","\n","                if global_step % print_every == 0:\n","                    log_loss = (tr_loss - logging_loss) / mini_batch_size\n","                    logging_loss = tr_loss\n","\n","                    print(f\"Step: {global_step}, Mini-Batch Loss: {log_loss:.4f}\")\n","\n","        print(\n","            f\"Epoch: {epoch+1}, Avg Training Loss: {(tr_loss - last_tr_loss) / len(train_loader):.4f}/sample\",\n","            end=\", \",\n","        )\n","        last_tr_loss = tr_loss\n","\n","        val_loss = evaluate(model, val_loader, loss_fn)\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), save_path)\n","\n","        print(f\"Validation Loss: {val_loss:.4f}\")"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.451235Z","iopub.status.busy":"2024-10-29T12:14:06.450961Z","iopub.status.idle":"2024-10-29T12:14:06.463782Z","shell.execute_reply":"2024-10-29T12:14:06.462966Z","shell.execute_reply.started":"2024-10-29T12:14:06.451205Z"},"trusted":true},"outputs":[],"source":["def predict(\n","    model,\n","    tokenizer,\n","    text,\n","    article_max_length=512,\n","    max_length=128,\n","    preprocess=True,\n","    sep_idx=None,\n","):\n","    model.eval()\n","    if preprocess:\n","        text_ids = (\n","            tokenizer.encode(\"summarize: \")\n","            + tokenizer.encode(text)[:article_max_length]\n","            + tokenizer.encode(tokenizer.sep_token)\n","        )\n","        sep_idx = len(text_ids) - 1\n","        inputs = torch.tensor(text_ids).unsqueeze(0).to(device)\n","    else:\n","        assert sep_idx is not None, \"sep_idx must be provided if preprocess is False\"\n","        assert isinstance(sep_idx, torch.Tensor), \"sep_idx must be a list\"\n","        inputs = text.to(device)\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            inputs,\n","            max_new_tokens=max_length,\n","            pad_token_id=tokenizer.pad_token_id,\n","            eos_token_id=tokenizer.eos_token_id,\n","            do_sample=True,\n","            top_k=50,\n","            top_p=0.95,\n","            temperature=0.7,\n","            num_return_sequences=1,\n","            no_repeat_ngram_size=3,\n","        )\n","\n","    if preprocess:\n","        generated_summary = tokenizer.decode(\n","            outputs[0][sep_idx + 1 :], skip_special_tokens=True\n","        )\n","        return generated_summary\n","    else:\n","        generated_summaries = []\n","        for i in range(len(sep_idx)):\n","            sep_idx_i = sep_idx[i].item()\n","            generated_summary = tokenizer.decode(outputs[i][sep_idx_i + 1 :], skip_special_tokens=True)\n","            generated_summaries.append(generated_summary)\n","\n","        return generated_summaries"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.465094Z","iopub.status.busy":"2024-10-29T12:14:06.464799Z","iopub.status.idle":"2024-10-29T12:14:06.477429Z","shell.execute_reply":"2024-10-29T12:14:06.476709Z","shell.execute_reply.started":"2024-10-29T12:14:06.465063Z"},"trusted":true},"outputs":[],"source":["def test_score(model, tokenizer, test_loader, article_max_length=512, max_length=128, print_every=False):\n","    rouge_scorer_obj = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"])\n","    rouge_scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n","\n","    for i in tqdm(test_loader):\n","        text = i[\"article\"]\n","        summary = i[\"highlights\"]\n","\n","        generated_summary = predict(\n","            model,\n","            tokenizer,\n","            text,\n","            article_max_length,\n","            max_length,\n","            preprocess=False,\n","            sep_idx=i[\"sep_idx\"],\n","        )\n","\n","        for j in range(len(summary)):\n","            scores = rouge_scorer_obj.score(summary[j], generated_summary[j])\n","            for key in rouge_scores:\n","                rouge_scores[key].append(scores[key].fmeasure)\n","            \n","            if print_every:\n","                print(scores)\n","\n","    for key in rouge_scores:\n","        rouge_scores[key] = np.mean(rouge_scores[key])\n","\n","    return rouge_scores"]},{"cell_type":"markdown","metadata":{},"source":["## Main"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:06.491160Z","iopub.status.busy":"2024-10-29T12:14:06.490877Z","iopub.status.idle":"2024-10-29T12:14:10.234505Z","shell.execute_reply":"2024-10-29T12:14:10.233656Z","shell.execute_reply.started":"2024-10-29T12:14:06.491129Z"},"trusted":true},"outputs":[],"source":["train_data = read_data(train_filepath, max_train_samples)\n","val_data = read_data(val_filepath, max_val_samples)\n","test_data = read_data(test_filepath, max_test_samples)"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:10.236037Z","iopub.status.busy":"2024-10-29T12:14:10.235750Z","iopub.status.idle":"2024-10-29T12:14:12.525242Z","shell.execute_reply":"2024-10-29T12:14:12.524437Z","shell.execute_reply.started":"2024-10-29T12:14:10.236007Z"},"trusted":true},"outputs":[],"source":["tokenizer = make_tokenizer(model_name)\n","len_tokenizer = len(tokenizer)\n","\n","model = make_model(model_name, len_tokenizer, tuning_type)"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:12.526650Z","iopub.status.busy":"2024-10-29T12:14:12.526309Z","iopub.status.idle":"2024-10-29T12:14:12.798652Z","shell.execute_reply":"2024-10-29T12:14:12.797742Z","shell.execute_reply.started":"2024-10-29T12:14:12.526615Z"},"trusted":true},"outputs":[{"data":{"text/plain":["===============================================================================================\n","Layer (type:depth-idx)                                                 Param #\n","===============================================================================================\n","PeftModelForCausalLM                                                   --\n","├─LoraModel: 1-1                                                       --\n","│    └─GPTNeoForCausalLM: 2-1                                          --\n","│    │    └─GPTNeoModel: 3-1                                           125,789,952\n","│    │    └─Linear: 3-2                                                (38,598,912)\n","===============================================================================================\n","Total params: 164,388,864\n","Trainable params: 589,824\n","Non-trainable params: 163,799,040\n","==============================================================================================="]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["modelinfo(model)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:14:12.799985Z","iopub.status.busy":"2024-10-29T12:14:12.799692Z","iopub.status.idle":"2024-10-29T12:16:17.946755Z","shell.execute_reply":"2024-10-29T12:16:17.945638Z","shell.execute_reply.started":"2024-10-29T12:14:12.799954Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing Data: 100%|██████████| 5000/5000 [01:30<00:00, 55.12it/s]\n","Processing Data: 100%|██████████| 1000/1000 [00:18<00:00, 55.23it/s]\n","Processing Data: 100%|██████████| 1000/1000 [00:15<00:00, 63.14it/s]\n"]}],"source":["if to_train:\n","    train_dataset = SummarizationDataset(train_data, tokenizer, type=\"train\")\n","    val_dataset = SummarizationDataset(val_data, tokenizer, type=\"val\")\n","test_dataset = SummarizationDataset(test_data, tokenizer, type=\"test\")\n","\n","if to_train:\n","    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:16:17.948485Z","iopub.status.busy":"2024-10-29T12:16:17.948068Z","iopub.status.idle":"2024-10-29T12:16:17.955793Z","shell.execute_reply":"2024-10-29T12:16:17.954812Z","shell.execute_reply.started":"2024-10-29T12:16:17.948439Z"},"trusted":true},"outputs":[],"source":["optimiser = optim.AdamW(model.parameters(), lr=lr)\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:16:17.957231Z","iopub.status.busy":"2024-10-29T12:16:17.956931Z","iopub.status.idle":"2024-10-29T12:59:25.180012Z","shell.execute_reply":"2024-10-29T12:59:25.178962Z","shell.execute_reply.started":"2024-10-29T12:16:17.957200Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1:  26%|██▌       | 1281/5000 [02:00<05:50, 10.60it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 40, Mini-Batch Loss: 24.4306\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1:  51%|█████     | 2561/5000 [04:00<03:50, 10.60it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 80, Mini-Batch Loss: 24.1842\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1:  77%|███████▋  | 3841/5000 [06:00<01:49, 10.63it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 120, Mini-Batch Loss: 23.8087\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1: 100%|██████████| 5000/5000 [07:49<00:00, 10.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1, Avg Training Loss: 0.6017/sample, "]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 1000/1000 [00:45<00:00, 22.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 19.2922\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2:   3%|▎         | 130/5000 [00:12<07:39, 10.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 160, Mini-Batch Loss: 24.0139\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2:  28%|██▊       | 1410/5000 [02:12<05:39, 10.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 200, Mini-Batch Loss: 23.3410\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2:  54%|█████▍    | 2690/5000 [04:12<03:36, 10.67it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 240, Mini-Batch Loss: 22.5977\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2:  79%|███████▉  | 3970/5000 [06:12<01:37, 10.61it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 280, Mini-Batch Loss: 21.8251\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2: 100%|██████████| 5000/5000 [07:49<00:00, 10.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2, Avg Training Loss: 0.5584/sample, "]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 1000/1000 [00:45<00:00, 22.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 16.8264\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3:   5%|▌         | 258/5000 [00:24<07:25, 10.63it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 320, Mini-Batch Loss: 21.2982\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3:  31%|███       | 1538/5000 [02:24<05:26, 10.60it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 360, Mini-Batch Loss: 20.4520\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3:  56%|█████▋    | 2818/5000 [04:25<03:27, 10.54it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 400, Mini-Batch Loss: 19.5263\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3:  82%|████████▏ | 4098/5000 [06:26<01:25, 10.54it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 440, Mini-Batch Loss: 18.8391\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3: 100%|██████████| 5000/5000 [07:51<00:00, 10.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3, Avg Training Loss: 0.4867/sample, "]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 1000/1000 [00:45<00:00, 21.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 14.7158\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4:   8%|▊         | 386/5000 [00:36<07:14, 10.61it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 480, Mini-Batch Loss: 18.4120\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4:  33%|███▎      | 1666/5000 [02:37<05:15, 10.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 520, Mini-Batch Loss: 18.0245\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4:  59%|█████▉    | 2946/5000 [04:38<03:14, 10.54it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 560, Mini-Batch Loss: 17.6748\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4:  85%|████████▍ | 4226/5000 [06:38<01:13, 10.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 600, Mini-Batch Loss: 17.2708\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4: 100%|██████████| 5000/5000 [07:51<00:00, 10.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4, Avg Training Loss: 0.4391/sample, "]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 1000/1000 [00:45<00:00, 21.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 13.4501\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5:  10%|█         | 514/5000 [00:48<07:05, 10.55it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 640, Mini-Batch Loss: 16.8770\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5:  36%|███▌      | 1794/5000 [02:49<05:02, 10.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 680, Mini-Batch Loss: 16.5276\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5:  61%|██████▏   | 3074/5000 [04:49<03:02, 10.56it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 720, Mini-Batch Loss: 16.0112\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5:  87%|████████▋ | 4354/5000 [06:50<01:01, 10.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 760, Mini-Batch Loss: 15.9350\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5: 100%|██████████| 5000/5000 [07:51<00:00, 10.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5, Avg Training Loss: 0.4036/sample, "]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 1000/1000 [00:45<00:00, 21.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 13.0669\n","Total Training Time: 43.11 minutes\n","\n","Model loaded successfully\n"]}],"source":["if to_train:\n","    start_time = time.time()\n","    train(\n","        model,\n","        optimiser,\n","        loss_fn,\n","        train_loader,\n","        val_loader,\n","        num_epochs=epochs,\n","        mini_batch_size=mini_batch_size,\n","        save_path=f\"models/model_{tuning_type}.pt\",\n","        print_every=40,\n","    )\n","    end_time = time.time()\n","    total_training_time = end_time - start_time\n","    print(f\"Total Training Time: {total_training_time / 60:.2f} minutes\\n\")\n","\n","if os.path.exists(f\"models/model_{tuning_type}.pt\"):\n","    model.load_state_dict(torch.load(f\"models/model_{tuning_type}.pt\", map_location=device, weights_only=True))\n","    print(\"Model loaded successfully\")\n","else:\n","    print(\"No model checkpoint found\")"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:59:25.182722Z","iopub.status.busy":"2024-10-29T12:59:25.181821Z","iopub.status.idle":"2024-10-29T12:59:25.187077Z","shell.execute_reply":"2024-10-29T12:59:25.186307Z","shell.execute_reply.started":"2024-10-29T12:59:25.182672Z"},"trusted":true},"outputs":[],"source":["# # Predict first 5 examples from test data\n","\n","# for i in range(5):\n","#     text = test_data[i][\"article\"]\n","#     summary = test_data[i][\"highlights\"]\n","#     generated_summary = predict(model, tokenizer, text)\n","\n","#     print(f\"Example {i+1}\")\n","#     print(\"Text:\", text)\n","#     print(\"Actual Summary:\", summary)\n","#     print(\"Generated Summary:\", generated_summary)\n","#     print(\"\\n\")"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:59:25.188624Z","iopub.status.busy":"2024-10-29T12:59:25.188211Z","iopub.status.idle":"2024-10-29T13:06:22.470536Z","shell.execute_reply":"2024-10-29T13:06:22.469594Z","shell.execute_reply.started":"2024-10-29T12:59:25.188565Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [06:57<00:00,  6.62s/it]"]},{"name":"stdout","output_type":"stream","text":["Test Scores: {'rouge1': 0.18475428115523927, 'rouge2': 0.10113436339126156, 'rougeL': 0.13792411686014674}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["print(\"Test Scores:\", test_score(model, tokenizer, test_loader, print_every=False))"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T13:06:22.472155Z","iopub.status.busy":"2024-10-29T13:06:22.471824Z","iopub.status.idle":"2024-10-29T13:06:22.478683Z","shell.execute_reply":"2024-10-29T13:06:22.477633Z","shell.execute_reply.started":"2024-10-29T13:06:22.472121Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Allocated Memory: 1.2033 GB\n","Max Allocated Memory: 4.9300 GB\n","Reserved Memory: 6.4004 GB\n","Max Reserved Memory: 6.4004 GB\n"]}],"source":["print(f\"Allocated Memory: {torch.cuda.memory_allocated() / (1024 ** 3):.4f} GB\")\n","print(f\"Max Allocated Memory: {torch.cuda.max_memory_allocated() / (1024 ** 3):.4f} GB\")\n","print(f\"Reserved Memory: {torch.cuda.memory_reserved() / (1024 ** 3):.4f} GB\")\n","print(f\"Max Reserved Memory: {torch.cuda.max_memory_reserved() / (1024 ** 3):.4f} GB\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1654566,"sourceId":2734496,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
