{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:15:26.291530Z","iopub.status.busy":"2024-10-29T11:15:26.291209Z","iopub.status.idle":"2024-10-29T11:16:00.092682Z","shell.execute_reply":"2024-10-29T11:16:00.091702Z","shell.execute_reply.started":"2024-10-29T11:15:26.291497Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rouge-score==0.1.2\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score==0.1.2) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score==0.1.2) (3.2.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score==0.1.2) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score==0.1.2) (1.16.0)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=62ef6af4800dd945b91767316c147b01fbb6bf34f901a841aa838e80fac5b53c\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting peft==0.13.2\n","  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (6.0.2)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (2.4.0)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (4.45.1)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (4.66.4)\n","Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (0.34.2)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (0.4.5)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.13.2) (0.25.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.13.2) (3.15.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.13.2) (2024.6.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.13.2) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.13.2) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.13.2) (3.1.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.13.2) (3.1.4)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.13.2) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.13.2) (0.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.13.2) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.13.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.13.2) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.13.2) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.13.2) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.13.2) (1.3.0)\n","Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: peft\n","Successfully installed peft-0.13.2\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["import os\n","import re\n","import csv\n","import time\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","from itertools import islice\n","from torchinfo import summary as modelinfo\n","# import matplotlib.pyplot as plt\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","\n","import torch\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n","\n","\n","try: \n","    from rouge_score import rouge_scorer\n","except:\n","    %pip install rouge-score==0.1.2\n","    from rouge_score import rouge_scorer\n","    \n","try:\n","    from peft import get_peft_model, LoraConfig, TaskType\n","except:\n","    %pip install peft==0.13.2\n","    from peft import get_peft_model, LoraConfig, TaskType"]},{"cell_type":"markdown","metadata":{},"source":["## Config"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.095140Z","iopub.status.busy":"2024-10-29T11:16:00.094538Z","iopub.status.idle":"2024-10-29T11:16:00.100381Z","shell.execute_reply":"2024-10-29T11:16:00.099456Z","shell.execute_reply.started":"2024-10-29T11:16:00.095103Z"},"trusted":true},"outputs":[],"source":["train_filepath = \"/kaggle/input/cnn_dailymail/train.csv\"\n","val_filepath = \"/kaggle/input/cnn_dailymail/validation.csv\"\n","test_filepath = \"/kaggle/input/cnn_dailymail/test.csv\"\n","\n","# train_filepath = \"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\"\n","# val_filepath = \"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\"\n","# test_filepath = \"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\"\n","\n","max_train_samples = 5000\n","max_val_samples = 1000\n","max_test_samples = 1000"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.102056Z","iopub.status.busy":"2024-10-29T11:16:00.101677Z","iopub.status.idle":"2024-10-29T11:16:00.111672Z","shell.execute_reply":"2024-10-29T11:16:00.110817Z","shell.execute_reply.started":"2024-10-29T11:16:00.102011Z"},"trusted":true},"outputs":[],"source":["to_train = True\n","model_name = \"EleutherAI/gpt-neo-125m\"\n","tuning_type = \"last\"\n","\n","lr = 6e-5\n","epochs = 5\n","mini_batch_size = 32\n","\n","# For LORA\n","r = 16\n","alpha = 32"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.113926Z","iopub.status.busy":"2024-10-29T11:16:00.113638Z","iopub.status.idle":"2024-10-29T11:16:00.122594Z","shell.execute_reply":"2024-10-29T11:16:00.121693Z","shell.execute_reply.started":"2024-10-29T11:16:00.113895Z"},"trusted":true},"outputs":[],"source":["assert tuning_type in [\"none\", \"last\", \"lora\"], \"Invalid tuning type\"\n","if tuning_type == \"none\": to_train=False\n","os.makedirs(\"models\", exist_ok=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.123928Z","iopub.status.busy":"2024-10-29T11:16:00.123655Z","iopub.status.idle":"2024-10-29T11:16:00.166607Z","shell.execute_reply":"2024-10-29T11:16:00.165677Z","shell.execute_reply.started":"2024-10-29T11:16:00.123898Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Random Seed: 42\n"]}],"source":["random_seed = 42\n","\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","print(\"Using Random Seed:\", random_seed)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.168750Z","iopub.status.busy":"2024-10-29T11:16:00.167960Z","iopub.status.idle":"2024-10-29T11:16:00.173666Z","shell.execute_reply":"2024-10-29T11:16:00.172669Z","shell.execute_reply.started":"2024-10-29T11:16:00.168701Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Utils"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.175298Z","iopub.status.busy":"2024-10-29T11:16:00.174948Z","iopub.status.idle":"2024-10-29T11:16:00.185026Z","shell.execute_reply":"2024-10-29T11:16:00.184159Z","shell.execute_reply.started":"2024-10-29T11:16:00.175258Z"},"trusted":true},"outputs":[],"source":["dm_single_close_quote = \"\\u2019\"  # unicode\n","dm_double_close_quote = \"\\u201d\"\n","\n","# acceptable ways to end a sentence\n","END_TOKENS = [\n","    \".\",\n","    \"!\",\n","    \"?\",\n","    \"'\",\n","    \"`\",\n","    '\"',\n","    dm_single_close_quote,\n","    dm_double_close_quote,\n","    \")\",\n","]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.186792Z","iopub.status.busy":"2024-10-29T11:16:00.186366Z","iopub.status.idle":"2024-10-29T11:16:00.197205Z","shell.execute_reply":"2024-10-29T11:16:00.196397Z","shell.execute_reply.started":"2024-10-29T11:16:00.186749Z"},"trusted":true},"outputs":[],"source":["def remove_period(line):\n","    if line[-1] in END_TOKENS:\n","        return line[:-1]\n","    return line\n","\n","\n","def remove_punctuations(line):\n","    return re.sub(r\"[^\\w\\s]\", \" \", line)\n","\n","\n","def clean_data(data):\n","    for i in range(len(data)):\n","        data[i][\"article\"] = remove_punctuations(data[i][\"article\"])\n","        data[i][\"highlights\"] = remove_punctuations(data[i][\"highlights\"])\n","\n","        data[i][\"article\"] = re.sub(r\"\\s+\", \" \", data[i][\"article\"]).strip()\n","        data[i][\"highlights\"] = re.sub(r\"\\s+\", \" \", data[i][\"highlights\"]).strip()\n","\n","    return data"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.199082Z","iopub.status.busy":"2024-10-29T11:16:00.198395Z","iopub.status.idle":"2024-10-29T11:16:00.207611Z","shell.execute_reply":"2024-10-29T11:16:00.206755Z","shell.execute_reply.started":"2024-10-29T11:16:00.198998Z"},"trusted":true},"outputs":[],"source":["def read_data(filepath, max_length=None):\n","    with open(filepath, \"r\") as f:\n","        reader = csv.DictReader(f)\n","        if max_length is not None:\n","            rows = islice(reader, max_length)\n","        else:\n","            rows = reader\n","        data = list(rows)\n","    \n","    return clean_data(data)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.211471Z","iopub.status.busy":"2024-10-29T11:16:00.211106Z","iopub.status.idle":"2024-10-29T11:16:00.217677Z","shell.execute_reply":"2024-10-29T11:16:00.216750Z","shell.execute_reply.started":"2024-10-29T11:16:00.211440Z"},"trusted":true},"outputs":[],"source":["def freeze_last_layer(model):\n","    assert tuning_type == \"last\", \"Only last layer fine-tuning is supported\"\n","\n","    for param in model.parameters():\n","        param.requires_grad = False\n","    \n","    for param in model.lm_head.parameters():\n","        param.requires_grad = True\n","\n","def lora(model):\n","    assert tuning_type == \"lora\"\n","\n","    config = LoraConfig(\n","        task_type=TaskType.CAUSAL_LM,\n","        inference_mode=False,\n","        r=r,\n","        lora_alpha=alpha,\n","        bias=\"none\"\n","    )\n","\n","    model = get_peft_model(model, config)\n","\n","    return model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.219075Z","iopub.status.busy":"2024-10-29T11:16:00.218799Z","iopub.status.idle":"2024-10-29T11:16:00.227680Z","shell.execute_reply":"2024-10-29T11:16:00.226879Z","shell.execute_reply.started":"2024-10-29T11:16:00.219045Z"},"trusted":true},"outputs":[],"source":["def make_tokenizer(model_name):\n","    \"\"\"Returns GPT2 tokenizer after adding separator and padding tokens\"\"\"\n","    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","    special_tokens = {\"pad_token\": \"<pad>\", \"sep_token\": \"<sep>\"}\n","    tokenizer.add_special_tokens(special_tokens)\n","    return tokenizer\n","\n","\n","def make_model(model_name, len_tokenizer, tuning_type=\"last\"):\n","    model = GPTNeoForCausalLM.from_pretrained(model_name)\n","    model.resize_token_embeddings(len_tokenizer)\n","\n","    if tuning_type == \"last\":\n","        freeze_last_layer(model)\n","    elif tuning_type == \"lora\":\n","        model = lora(model)\n","\n","    model.to(device)\n","    return model"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.229138Z","iopub.status.busy":"2024-10-29T11:16:00.228856Z","iopub.status.idle":"2024-10-29T11:16:00.245231Z","shell.execute_reply":"2024-10-29T11:16:00.244566Z","shell.execute_reply.started":"2024-10-29T11:16:00.229107Z"},"trusted":true},"outputs":[],"source":["class SummarizationDataset(Dataset):\n","    def __init__(self, data, tokenizer, article_max_length=512, summary_max_length=128, type=\"train\"):\n","        assert type in [\"train\", \"val\", \"test\"], \"Invalid dataset type\"\n","\n","        self.type = type\n","        if type == \"test\":\n","            summary_max_length = 0\n","\n","        self.tokenizer = tokenizer\n","        self.article_max_length = article_max_length\n","        self.summary_max_length = summary_max_length\n","        self.instruction_tokens = self.tokenizer.encode(\"summarize: \")\n","        self.sep_token = self.tokenizer.encode(\" \" + self.tokenizer.sep_token + \" \")\n","        self.max_length = article_max_length + summary_max_length + len(self.instruction_tokens) + len(self.sep_token)\n","        \n","        self.processed_data = self._process_all_data(data, 4)\n","\n","    def _attention_mask(self, padding_length):\n","        return [1] * (self.max_length - padding_length) + [0] * padding_length\n","\n","    def _process_data(self, data):\n","        article_ids = self.tokenizer.encode(\n","            data[\"article\"], truncation=True, max_length=self.article_max_length\n","        )\n","        if self.type != \"test\":\n","            abstract_ids = self.tokenizer.encode(\n","                data[\"highlights\"], truncation=True, max_length=self.summary_max_length\n","            )\n","        else:\n","            abstract_ids = []\n","\n","        # Combine all components\n","        content = self.instruction_tokens + article_ids + self.sep_token + abstract_ids\n","\n","        if self.type != \"test\":\n","            padding_length = self.max_length - len(content)\n","            padded_content = content + [self.tokenizer.pad_token_id] * padding_length\n","        else:\n","            padding_length = self.max_length - len(content)\n","            padded_content = [self.tokenizer.pad_token_id] * padding_length + content\n","\n","        return {\n","            \"text\": padded_content,\n","            \"sep_idx\": len(article_ids),\n","            \"article_len\": len(article_ids),\n","            \"summary_len\": len(abstract_ids),\n","            \"attention_mask\": self._attention_mask(padding_length),\n","            \"highlights\": data[\"highlights\"],\n","        }\n","    \n","    def _process_all_data(self, data, num_workers):\n","        processed_data = []\n","\n","        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n","            # Submit tasks to the thread pool\n","            futures = [executor.submit(self._process_data, item) for item in data]\n","            \n","            # Use tqdm to track the progress\n","            for future in tqdm(as_completed(futures), total=len(data), desc=\"Processing Data\"):\n","                processed_data.append(future.result())\n","\n","        return processed_data\n","\n","    def __len__(self):\n","        return len(self.processed_data)\n","\n","    def __getitem__(self, idx):\n","        processed_item = self.processed_data[idx]\n","        return {\n","            \"article\": torch.tensor(processed_item[\"text\"]),\n","            \"sep_idx\": processed_item[\"sep_idx\"],\n","            \"article_len\": processed_item[\"article_len\"],\n","            \"summary_len\": processed_item[\"summary_len\"],\n","            \"attention_mask\": torch.tensor(processed_item[\"attention_mask\"]),\n","            \"highlights\": processed_item[\"highlights\"],\n","        }"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.247138Z","iopub.status.busy":"2024-10-29T11:16:00.246509Z","iopub.status.idle":"2024-10-29T11:16:00.259443Z","shell.execute_reply":"2024-10-29T11:16:00.258682Z","shell.execute_reply.started":"2024-10-29T11:16:00.247095Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, val_loader, loss_fn, summary_max_length=128):\n","    \"\"\"\n","    Evaluate the model on validation/test data\n","\n","    Args:\n","        model: The model to evaluate\n","        val_loader: DataLoader for validation data\n","        loss_fn: Loss function (typically CrossEntropyLoss with ignore_index set to pad_token_id)\n","\n","    Returns:\n","        float: Average loss per batch\n","    \"\"\"\n","    model.eval()\n","    total_loss = 0.0\n","    num_batches = 0\n","\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n","            inputs = batch[\"article\"].to(device)\n","            sep_idx = batch[\"sep_idx\"].squeeze()\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","\n","            outputs = model(inputs, attention_mask=attention_mask, labels=inputs)\n","            loss = outputs.loss\n","            # decoded_output = tokenizer.decode(outputs.logits[0].argmax(dim=-1))\n","            # decoded_input = tokenizer.decode(inputs[0])\n","            # print(decoded_input, decoded_output, sep=\"\\n\\n\")\n","\n","            # Get logits and labels for summary portion only\n","            shift_logits = outputs.logits[..., sep_idx:-1, :].contiguous()\n","            shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n","            shift_labels = inputs[..., sep_idx + 1 :].contiguous()\n","            shift_labels = shift_labels.view(-1)\n","\n","            shift_logits = shift_logits[:summary_max_length]\n","            shift_labels = shift_labels[:summary_max_length]\n","            \n","            # print()\n","            # print(tokenizer.decode(shift_logits.argmax(dim=-1)))\n","            # print(shift_labels)\n","\n","            loss = loss_fn(shift_logits, shift_labels)\n","            total_loss += loss.item()\n","            num_batches += 1\n","\n","    return total_loss / (num_batches if num_batches > 0 else 1)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.274649Z","iopub.status.busy":"2024-10-29T11:16:00.274258Z","iopub.status.idle":"2024-10-29T11:16:00.287642Z","shell.execute_reply":"2024-10-29T11:16:00.286821Z","shell.execute_reply.started":"2024-10-29T11:16:00.274599Z"},"trusted":true},"outputs":[],"source":["def train(\n","    model,\n","    optimiser,\n","    loss_fn,\n","    train_loader,\n","    val_loader,\n","    num_epochs,\n","    max_grad_norm=1.0,\n","    mini_batch_size=4,\n","    summary_max_length=128,\n","    save_path=\"models/model.pt\",\n","    print_every=5,\n","):\n","    global_step = 0\n","    best_val_loss = float(\"inf\")\n","    tr_loss = 0.0\n","    last_tr_loss, logging_loss = 0.0, 0.0\n","\n","    model.zero_grad()\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        epoch_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n","\n","        for step, batch in enumerate(epoch_iterator):\n","            inputs = batch[\"article\"].to(device)\n","            sep_idx = batch[\"sep_idx\"].squeeze()\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","\n","            outputs = model(inputs, labels=inputs, attention_mask=attention_mask)\n","\n","            shift_logits = outputs.logits[..., sep_idx:-1, :].contiguous()\n","            shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n","            shift_labels = inputs[..., sep_idx + 1 :].contiguous()\n","            shift_labels = shift_labels.view(-1)\n","\n","            shift_logits = shift_logits[:summary_max_length]\n","            shift_labels = shift_labels[:summary_max_length]\n","\n","            loss = loss_fn(shift_logits, shift_labels)\n","            loss /= mini_batch_size\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","\n","            tr_loss += loss.item()\n","\n","            if (step + 1) % mini_batch_size == 0:\n","                optimiser.step()\n","                model.zero_grad()\n","                global_step += 1\n","\n","                if global_step % print_every == 0:\n","                    log_loss = (tr_loss - logging_loss) / mini_batch_size\n","                    logging_loss = tr_loss\n","\n","                    print(f\"Step: {global_step}, Mini-Batch Loss: {log_loss:.4f}\")\n","\n","        print(\n","            f\"Epoch: {epoch+1}, Avg Training Loss: {(tr_loss - last_tr_loss) / len(train_loader):.4f}/sample\",\n","            end=\", \",\n","        )\n","        last_tr_loss = tr_loss\n","\n","        val_loss = evaluate(model, val_loader, loss_fn)\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), save_path)\n","\n","        print(f\"Validation Loss: {val_loss:.4f}\")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.288957Z","iopub.status.busy":"2024-10-29T11:16:00.288676Z","iopub.status.idle":"2024-10-29T11:16:00.302755Z","shell.execute_reply":"2024-10-29T11:16:00.301902Z","shell.execute_reply.started":"2024-10-29T11:16:00.288927Z"},"trusted":true},"outputs":[],"source":["def predict(\n","    model,\n","    tokenizer,\n","    text,\n","    article_max_length=512,\n","    max_length=128,\n","    preprocess=True,\n","    sep_idx=None,\n","):\n","    model.eval()\n","    if preprocess:\n","        text_ids = (\n","            tokenizer.encode(\"summarize: \")\n","            + tokenizer.encode(text)[:article_max_length]\n","            + tokenizer.encode(tokenizer.sep_token)\n","        )\n","        sep_idx = len(text_ids) - 1\n","        inputs = torch.tensor(text_ids).unsqueeze(0).to(device)\n","    else:\n","        assert sep_idx is not None, \"sep_idx must be provided if preprocess is False\"\n","        assert isinstance(sep_idx, torch.Tensor), \"sep_idx must be a list\"\n","        inputs = text.to(device)\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            inputs,\n","            max_new_tokens=max_length,\n","            pad_token_id=tokenizer.pad_token_id,\n","            eos_token_id=tokenizer.eos_token_id,\n","            do_sample=True,\n","            top_k=50,\n","            top_p=0.95,\n","            temperature=0.7,\n","            num_return_sequences=1,\n","            no_repeat_ngram_size=3,\n","        )\n","\n","    if preprocess:\n","        generated_summary = tokenizer.decode(\n","            outputs[0][sep_idx + 1 :], skip_special_tokens=True\n","        )\n","        return generated_summary\n","    else:\n","        generated_summaries = []\n","        for i in range(len(sep_idx)):\n","            sep_idx_i = sep_idx[i].item()\n","            generated_summary = tokenizer.decode(outputs[i][sep_idx_i + 1 :], skip_special_tokens=True)\n","            generated_summaries.append(generated_summary)\n","\n","        return generated_summaries"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.304249Z","iopub.status.busy":"2024-10-29T11:16:00.303898Z","iopub.status.idle":"2024-10-29T11:16:00.317192Z","shell.execute_reply":"2024-10-29T11:16:00.316433Z","shell.execute_reply.started":"2024-10-29T11:16:00.304204Z"},"trusted":true},"outputs":[],"source":["def test_score(model, tokenizer, test_loader, article_max_length=512, max_length=128, print_every=False):\n","    rouge_scorer_obj = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"])\n","    rouge_scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n","\n","    for i in tqdm(test_loader):\n","        text = i[\"article\"]\n","        summary = i[\"highlights\"]\n","\n","        generated_summary = predict(\n","            model,\n","            tokenizer,\n","            text,\n","            article_max_length,\n","            max_length,\n","            preprocess=False,\n","            sep_idx=i[\"sep_idx\"],\n","        )\n","\n","        for j in range(len(summary)):\n","            scores = rouge_scorer_obj.score(summary[j], generated_summary[j])\n","            for key in rouge_scores:\n","                rouge_scores[key].append(scores[key].fmeasure)\n","            \n","            if print_every:\n","                print(scores)\n","\n","    for key in rouge_scores:\n","        rouge_scores[key] = np.mean(rouge_scores[key])\n","\n","    return rouge_scores"]},{"cell_type":"markdown","metadata":{},"source":["## Main"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:00.332041Z","iopub.status.busy":"2024-10-29T11:16:00.331750Z","iopub.status.idle":"2024-10-29T11:16:04.340726Z","shell.execute_reply":"2024-10-29T11:16:04.339720Z","shell.execute_reply.started":"2024-10-29T11:16:00.332011Z"},"trusted":true},"outputs":[],"source":["train_data = read_data(train_filepath, max_train_samples)\n","val_data = read_data(val_filepath, max_val_samples)\n","test_data = read_data(test_filepath, max_test_samples)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tokenizer = make_tokenizer(model_name)\n","len_tokenizer = len(tokenizer)\n","\n","model = make_model(model_name, len_tokenizer, tuning_type)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:15.249735Z","iopub.status.busy":"2024-10-29T11:16:15.249304Z","iopub.status.idle":"2024-10-29T11:16:15.281691Z","shell.execute_reply":"2024-10-29T11:16:15.280775Z","shell.execute_reply.started":"2024-10-29T11:16:15.249689Z"},"trusted":true},"outputs":[{"data":{"text/plain":["================================================================================\n","Layer (type:depth-idx)                                  Param #\n","================================================================================\n","GPTNeoForCausalLM                                       --\n","├─GPTNeoModel: 1-1                                      --\n","│    └─Embedding: 2-1                                   38,598,912\n","│    └─Embedding: 2-2                                   (1,572,864)\n","│    └─Dropout: 2-3                                     --\n","│    └─ModuleList: 2-4                                  --\n","│    │    └─GPTNeoBlock: 3-1                            (7,085,568)\n","│    │    └─GPTNeoBlock: 3-2                            (7,085,568)\n","│    │    └─GPTNeoBlock: 3-3                            (7,085,568)\n","│    │    └─GPTNeoBlock: 3-4                            (7,085,568)\n","│    │    └─GPTNeoBlock: 3-5                            (7,085,568)\n","│    │    └─GPTNeoBlock: 3-6                            (7,085,568)\n","│    │    └─GPTNeoBlock: 3-7                            (7,085,568)\n","│    │    └─GPTNeoBlock: 3-8                            (7,085,568)\n","│    │    └─GPTNeoBlock: 3-9                            (7,085,568)\n","│    │    └─GPTNeoBlock: 3-10                           (7,085,568)\n","│    │    └─GPTNeoBlock: 3-11                           (7,085,568)\n","│    │    └─GPTNeoBlock: 3-12                           (7,085,568)\n","│    └─LayerNorm: 2-5                                   (1,536)\n","├─Linear: 1-2                                           38,598,912\n","================================================================================\n","Total params: 163,799,040\n","Trainable params: 77,197,824\n","Non-trainable params: 86,601,216\n","================================================================================"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["modelinfo(model)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:16:15.283247Z","iopub.status.busy":"2024-10-29T11:16:15.282824Z","iopub.status.idle":"2024-10-29T11:18:20.895278Z","shell.execute_reply":"2024-10-29T11:18:20.894324Z","shell.execute_reply.started":"2024-10-29T11:16:15.283203Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing Data: 100%|██████████| 5000/5000 [01:31<00:00, 54.66it/s]\n","Processing Data: 100%|██████████| 1000/1000 [00:17<00:00, 56.62it/s]\n","Processing Data: 100%|██████████| 1000/1000 [00:16<00:00, 62.32it/s]\n"]}],"source":["if to_train:\n","    train_dataset = SummarizationDataset(train_data, tokenizer, type=\"train\")\n","    val_dataset = SummarizationDataset(val_data, tokenizer, type=\"val\")\n","test_dataset = SummarizationDataset(test_data, tokenizer, type=\"test\")\n","\n","if to_train:\n","    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:18:20.896969Z","iopub.status.busy":"2024-10-29T11:18:20.896648Z","iopub.status.idle":"2024-10-29T11:18:21.563295Z","shell.execute_reply":"2024-10-29T11:18:21.562556Z","shell.execute_reply.started":"2024-10-29T11:18:20.896936Z"},"trusted":true},"outputs":[],"source":["optimiser = optim.AdamW(model.parameters(), lr=lr)\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T11:18:21.564787Z","iopub.status.busy":"2024-10-29T11:18:21.564366Z","iopub.status.idle":"2024-10-29T12:03:32.920659Z","shell.execute_reply":"2024-10-29T12:03:32.919555Z","shell.execute_reply.started":"2024-10-29T11:18:21.564754Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1:  26%|██▌       | 1282/5000 [02:08<06:09, 10.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 40, Mini-Batch Loss: 23.5291\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1:  51%|█████     | 2562/5000 [04:15<04:02, 10.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 80, Mini-Batch Loss: 22.2773\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1:  77%|███████▋  | 3842/5000 [06:22<01:55, 10.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 120, Mini-Batch Loss: 21.6129\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1: 100%|██████████| 5000/5000 [08:17<00:00, 10.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1, Avg Training Loss: 0.5541/sample, "]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 1000/1000 [00:43<00:00, 22.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 17.2898\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2:   3%|▎         | 130/5000 [00:12<08:06, 10.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 160, Mini-Batch Loss: 21.2895\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2:  28%|██▊       | 1410/5000 [02:20<05:57, 10.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 200, Mini-Batch Loss: 20.8317\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2:  54%|█████▍    | 2690/5000 [04:27<03:50, 10.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 240, Mini-Batch Loss: 20.3651\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2:  79%|███████▉  | 3969/5000 [06:34<01:44,  9.91it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 280, Mini-Batch Loss: 20.2127\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2: 100%|██████████| 5000/5000 [08:17<00:00, 10.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2, Avg Training Loss: 0.5099/sample, "]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 1000/1000 [00:43<00:00, 22.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 16.2494\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3:   5%|▌         | 258/5000 [00:25<07:53, 10.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 320, Mini-Batch Loss: 20.0472\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3:  31%|███       | 1538/5000 [02:33<05:45, 10.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 360, Mini-Batch Loss: 19.9306\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3:  56%|█████▋    | 2818/5000 [04:40<03:37, 10.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 400, Mini-Batch Loss: 19.5970\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3:  82%|████████▏ | 4098/5000 [06:47<01:30, 10.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 440, Mini-Batch Loss: 19.5742\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3: 100%|██████████| 5000/5000 [08:17<00:00, 10.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3, Avg Training Loss: 0.4930/sample, "]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 1000/1000 [00:43<00:00, 22.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 16.3394\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4:   8%|▊         | 386/5000 [00:38<07:40, 10.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 480, Mini-Batch Loss: 19.9925\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4:  33%|███▎      | 1665/5000 [02:45<05:32, 10.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 520, Mini-Batch Loss: 19.7062\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4:  59%|█████▉    | 2946/5000 [04:52<03:25, 10.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 560, Mini-Batch Loss: 19.8407\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4:  85%|████████▍ | 4226/5000 [07:00<01:17, 10.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 600, Mini-Batch Loss: 19.5675\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4: 100%|██████████| 5000/5000 [08:17<00:00, 10.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4, Avg Training Loss: 0.4921/sample, "]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 1000/1000 [00:43<00:00, 22.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 15.6558\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5:  10%|█         | 514/5000 [00:51<07:27, 10.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 640, Mini-Batch Loss: 19.5028\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5:  36%|███▌      | 1794/5000 [02:58<05:19, 10.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 680, Mini-Batch Loss: 19.0562\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5:  61%|██████▏   | 3074/5000 [05:05<03:11, 10.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 720, Mini-Batch Loss: 18.5341\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5:  87%|████████▋ | 4354/5000 [07:13<01:04, 10.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Step: 760, Mini-Batch Loss: 19.3672\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5: 100%|██████████| 5000/5000 [08:17<00:00, 10.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5, Avg Training Loss: 0.4758/sample, "]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 1000/1000 [00:43<00:00, 22.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 15.6085\n","Total Training Time: 45.18 minutes\n","\n","Model loaded successfully\n"]}],"source":["if to_train:\n","    start_time = time.time()\n","    train(\n","        model,\n","        optimiser,\n","        loss_fn,\n","        train_loader,\n","        val_loader,\n","        num_epochs=epochs,\n","        mini_batch_size=mini_batch_size,\n","        save_path=f\"models/model_{tuning_type}.pt\",\n","        print_every=40,\n","    )\n","    end_time = time.time()\n","    total_training_time = end_time - start_time\n","    print(f\"Total Training Time: {total_training_time / 60:.2f} minutes\\n\")\n","\n","if os.path.exists(f\"models/model_{tuning_type}.pt\"):\n","    model.load_state_dict(torch.load(f\"models/model_{tuning_type}.pt\", map_location=device, weights_only=True))\n","    print(\"Model loaded successfully\")\n","else:\n","    print(\"No model checkpoint found\")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:03:32.922485Z","iopub.status.busy":"2024-10-29T12:03:32.922116Z","iopub.status.idle":"2024-10-29T12:03:32.928230Z","shell.execute_reply":"2024-10-29T12:03:32.927477Z","shell.execute_reply.started":"2024-10-29T12:03:32.922443Z"},"trusted":true},"outputs":[],"source":["# # Predict first 5 examples from test data\n","\n","# for i in range(5):\n","#     text = test_data[i][\"article\"]\n","#     summary = test_data[i][\"highlights\"]\n","#     generated_summary = predict(model, tokenizer, text)\n","\n","#     print(f\"Example {i+1}\")\n","#     print(\"Text:\", text)\n","#     print(\"Actual Summary:\", summary)\n","#     print(\"Generated Summary:\", generated_summary)\n","#     print(\"\\n\")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:03:32.929645Z","iopub.status.busy":"2024-10-29T12:03:32.929277Z","iopub.status.idle":"2024-10-29T12:09:45.842555Z","shell.execute_reply":"2024-10-29T12:09:45.840664Z","shell.execute_reply.started":"2024-10-29T12:03:32.929597Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [06:12<00:00,  5.92s/it]"]},{"name":"stdout","output_type":"stream","text":["Test Scores: {'rouge1': 0.19136570004823917, 'rouge2': 0.10484339052743428, 'rougeL': 0.15257491328665496}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["print(\"Test Scores:\", test_score(model, tokenizer, test_loader, print_every=False))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-10-29T12:09:45.844266Z","iopub.status.busy":"2024-10-29T12:09:45.843952Z","iopub.status.idle":"2024-10-29T12:09:45.850716Z","shell.execute_reply":"2024-10-29T12:09:45.849820Z","shell.execute_reply.started":"2024-10-29T12:09:45.844233Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Allocated Memory: 0.9669 GB\n","Max Allocated Memory: 4.6935 GB\n","Reserved Memory: 6.3906 GB\n","Max Reserved Memory: 6.3906 GB\n"]}],"source":["print(f\"Allocated Memory: {torch.cuda.memory_allocated() / (1024 ** 3):.4f} GB\")\n","print(f\"Max Allocated Memory: {torch.cuda.max_memory_allocated() / (1024 ** 3):.4f} GB\")\n","print(f\"Reserved Memory: {torch.cuda.memory_reserved() / (1024 ** 3):.4f} GB\")\n","print(f\"Max Reserved Memory: {torch.cuda.max_memory_reserved() / (1024 ** 3):.4f} GB\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1654566,"sourceId":2734496,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
