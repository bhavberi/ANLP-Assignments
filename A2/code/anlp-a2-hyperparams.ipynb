{"cells":[{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:13.640860Z","iopub.status.busy":"2024-10-02T12:48:13.640131Z","iopub.status.idle":"2024-10-02T12:48:25.217223Z","shell.execute_reply":"2024-10-02T12:48:25.215947Z","shell.execute_reply.started":"2024-10-02T12:48:13.640819Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n"]}],"source":["!pip install rouge_score"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.220217Z","iopub.status.busy":"2024-10-02T12:48:25.219843Z","iopub.status.idle":"2024-10-02T12:48:25.227357Z","shell.execute_reply":"2024-10-02T12:48:25.226368Z","shell.execute_reply.started":"2024-10-02T12:48:25.220180Z"},"trusted":true},"outputs":[],"source":["import os\n","import re\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","from torchinfo import summary\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","from rouge_score import rouge_scorer\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.228796Z","iopub.status.busy":"2024-10-02T12:48:25.228447Z","iopub.status.idle":"2024-10-02T12:48:25.241501Z","shell.execute_reply":"2024-10-02T12:48:25.240610Z","shell.execute_reply.started":"2024-10-02T12:48:25.228754Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}],"source":["import nltk\n","\n","nltk.download(\"punkt\")\n","nltk.download(\"punkt_tab\")\n","\n","from nltk.tokenize import word_tokenize\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"]},{"cell_type":"markdown","metadata":{},"source":["## Config"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.242901Z","iopub.status.busy":"2024-10-02T12:48:25.242619Z","iopub.status.idle":"2024-10-02T12:48:25.250739Z","shell.execute_reply":"2024-10-02T12:48:25.249854Z","shell.execute_reply.started":"2024-10-02T12:48:25.242870Z"},"trusted":true},"outputs":[],"source":["en_train = '/kaggle/input/ted-talks-corpus/train.en'\n","fr_train = '/kaggle/input/ted-talks-corpus/train.fr'\n","en_val = '/kaggle/input/ted-talks-corpus/dev.en'\n","fr_val = '/kaggle/input/ted-talks-corpus/dev.fr'\n","en_test = '/kaggle/input/ted-talks-corpus/test.en'\n","fr_test = '/kaggle/input/ted-talks-corpus/test.fr'"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.254218Z","iopub.status.busy":"2024-10-02T12:48:25.253870Z","iopub.status.idle":"2024-10-02T12:48:25.260644Z","shell.execute_reply":"2024-10-02T12:48:25.259756Z","shell.execute_reply.started":"2024-10-02T12:48:25.254186Z"},"trusted":true},"outputs":[],"source":["train = True\n","padding_before = False\n","plot_losses = False"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.262403Z","iopub.status.busy":"2024-10-02T12:48:25.261840Z","iopub.status.idle":"2024-10-02T12:48:25.270506Z","shell.execute_reply":"2024-10-02T12:48:25.269646Z","shell.execute_reply.started":"2024-10-02T12:48:25.262359Z"},"trusted":true},"outputs":[],"source":["embedding_dim = 300\n","max_length = 64\n","lr=1e-4\n","\n","heads = 6\n","layers = 6\n","\n","epochs = 10\n","batch_size = 32"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.271915Z","iopub.status.busy":"2024-10-02T12:48:25.271593Z","iopub.status.idle":"2024-10-02T12:48:25.281644Z","shell.execute_reply":"2024-10-02T12:48:25.280765Z","shell.execute_reply.started":"2024-10-02T12:48:25.271884Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving model to ./models/transformer_heads6_layers6.pth\n"]}],"source":["os.makedirs(\"models\", exist_ok=True)\n","\n","save_path=\"./models/transformer\"\n","\n","save_path = save_path + f\"_heads{heads}_layers{layers}\"\n","\n","save_path = save_path + \".pth\"\n","\n","print(f\"Saving model to {save_path}\")"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.283963Z","iopub.status.busy":"2024-10-02T12:48:25.283020Z","iopub.status.idle":"2024-10-02T12:48:25.293714Z","shell.execute_reply":"2024-10-02T12:48:25.292821Z","shell.execute_reply.started":"2024-10-02T12:48:25.283902Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Random Seed: 42\n"]}],"source":["random_seed = 42\n","\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","print(\"Using Random Seed:\", random_seed)"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.295405Z","iopub.status.busy":"2024-10-02T12:48:25.294892Z","iopub.status.idle":"2024-10-02T12:48:25.303206Z","shell.execute_reply":"2024-10-02T12:48:25.302363Z","shell.execute_reply.started":"2024-10-02T12:48:25.295350Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Utils"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.305114Z","iopub.status.busy":"2024-10-02T12:48:25.304345Z","iopub.status.idle":"2024-10-02T12:48:25.313536Z","shell.execute_reply":"2024-10-02T12:48:25.312610Z","shell.execute_reply.started":"2024-10-02T12:48:25.305069Z"},"trusted":true},"outputs":[],"source":["def clean_text(text):\n","    text = str(text).lower().strip()\n","    text = text.rstrip('\\n')\n","    # text = re.sub(r\"<[^>]+>\", \"\", text)\n","    text = re.sub(r\"[^a-zA-ZÀ-ÿ0-9\\s.,;!?':()\\[\\]{}-]\", \" \", text)  # Keep selected punctuation marks, symbols and apostrophes\n","    text = re.sub(r\"\\s+\", \" \", text)\n","\n","    text = text.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")  # Corrected encoding\n","\n","    return text\n","\n","def clean_sentences(sentences):\n","    sentences = [clean_text(sentence) for sentence in sentences]\n","    sentences = [s for s in sentences if s and s != \"\"]  # remove empty strings\n","    return sentences"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.314855Z","iopub.status.busy":"2024-10-02T12:48:25.314601Z","iopub.status.idle":"2024-10-02T12:48:25.326533Z","shell.execute_reply":"2024-10-02T12:48:25.325596Z","shell.execute_reply.started":"2024-10-02T12:48:25.314826Z"},"trusted":true},"outputs":[],"source":["def read_data(en_path, fr_path):\n","    with open(en_path, \"r\") as f:\n","        en_data = f.readlines()\n","    with open(fr_path, \"r\") as f:\n","        fr_data = f.readlines()\n","\n","    assert len(en_data) == len(fr_data), \"Data mismatch\"\n","\n","    en_data = clean_sentences(en_data)\n","    fr_data = clean_sentences(fr_data)\n","\n","    assert len(en_data) == len(fr_data), \"Data mismatch in cleaned data\"\n","\n","    return en_data, fr_data\n","\n","def word_tokenizer(sentence):\n","    words = word_tokenize(sentence)\n","    return words"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.328117Z","iopub.status.busy":"2024-10-02T12:48:25.327769Z","iopub.status.idle":"2024-10-02T12:48:25.336650Z","shell.execute_reply":"2024-10-02T12:48:25.335875Z","shell.execute_reply.started":"2024-10-02T12:48:25.328083Z"},"trusted":true},"outputs":[],"source":["def flatten_concatenation(list_of_lists, unique=False):\n","    # flat_list = []\n","    # for sublist in list_of_lists:\n","    #     flat_list += sublist\n","\n","    # flat_list = list(set(flat_list))\n","    # return flat_list\n","    flat_array = np.concatenate(list_of_lists)\n","    if unique:\n","        flat_list = np.unique(flat_array).tolist()\n","    else:\n","        flat_list = flat_array.tolist()\n","    return flat_list"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.338233Z","iopub.status.busy":"2024-10-02T12:48:25.337623Z","iopub.status.idle":"2024-10-02T12:48:25.346261Z","shell.execute_reply":"2024-10-02T12:48:25.345424Z","shell.execute_reply.started":"2024-10-02T12:48:25.338187Z"},"trusted":true},"outputs":[],"source":["def reverse_vocab(vocab):\n","    return {v: k for k, v in vocab.items()}"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.351538Z","iopub.status.busy":"2024-10-02T12:48:25.351250Z","iopub.status.idle":"2024-10-02T12:48:25.356483Z","shell.execute_reply":"2024-10-02T12:48:25.355611Z","shell.execute_reply.started":"2024-10-02T12:48:25.351507Z"},"trusted":true},"outputs":[],"source":["def return_words_till_EOS(lst, eos=2):\n","    if eos not in lst:\n","        return lst\n","    return lst[:lst.index(eos)]"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.357899Z","iopub.status.busy":"2024-10-02T12:48:25.357559Z","iopub.status.idle":"2024-10-02T12:48:25.366037Z","shell.execute_reply":"2024-10-02T12:48:25.365190Z","shell.execute_reply.started":"2024-10-02T12:48:25.357850Z"},"trusted":true},"outputs":[],"source":["def pad_sequence(sequence, max_len, before=True, pad_token=0):\n","    if len(sequence) > max_len:\n","        return sequence[:max_len]\n","    elif before:\n","        return [pad_token] * (max_len - len(sequence)) + sequence\n","    else:\n","        return sequence + [pad_token] * (max_len - len(sequence))"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.367471Z","iopub.status.busy":"2024-10-02T12:48:25.367148Z","iopub.status.idle":"2024-10-02T12:48:25.382282Z","shell.execute_reply":"2024-10-02T12:48:25.381402Z","shell.execute_reply.started":"2024-10-02T12:48:25.367437Z"},"trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(\n","        self,\n","        en_data,\n","        fr_data,\n","        en_vocab,\n","        fr_vocab,\n","        pad_before=False,\n","    ):\n","        self.en_data = []\n","        self.fr_data = []\n","        self.labels = []\n","        self.en_vocab = en_vocab\n","        self.fr_vocab = fr_vocab\n","\n","        assert len(en_data) == len(fr_data)\n","        self.length = len(en_data)\n","\n","        en_pad = self.en_vocab[\"<pad>\"]\n","        en_unk = self.en_vocab[\"<unk>\"]\n","        en_sos = self.en_vocab[\"<sos>\"]\n","        en_eos = self.en_vocab[\"<eos>\"]\n","        fr_pad = self.fr_vocab[\"<pad>\"]\n","        fr_unk = self.fr_vocab[\"<unk>\"]\n","        fr_sos = self.fr_vocab[\"<sos>\"]\n","        fr_eos = self.fr_vocab[\"<eos>\"]\n","\n","        tqdm_obj = tqdm(\n","            total=self.length, desc=\"Creating dataset\"\n","        )\n","        for index, (en_sentence, fr_sentence) in enumerate(zip(en_data, fr_data)):\n","            en_indices = [int(self.en_vocab.get(w, en_unk)) for w in en_sentence]\n","            en_indices = [en_sos] + en_indices[: max_length - 2] + [en_eos]\n","            en_indices = pad_sequence(\n","                en_indices, max_length, before=pad_before, pad_token=en_pad\n","            )\n","            self.en_data.append(\n","                torch.tensor(en_indices, dtype=torch.int, device=device)\n","            )\n","\n","            fr_indices1 = [int(self.fr_vocab.get(w, fr_unk)) for w in fr_sentence]\n","            fr_indices = [fr_sos] + fr_indices1\n","            fr_indices = pad_sequence(\n","                fr_indices, max_length, before=pad_before, pad_token=fr_pad\n","            )\n","            self.fr_data.append(\n","                torch.tensor(fr_indices, dtype=torch.int, device=device)\n","            )\n","\n","            fr_indices = fr_indices1 + [fr_eos]\n","            fr_indices = pad_sequence(\n","                fr_indices, max_length, before=pad_before, pad_token=fr_pad\n","            )\n","            self.labels.append(torch.tensor(fr_indices, device=device))\n","\n","            if index % 10 == 0:\n","                tqdm_obj.update(10)\n","\n","        tqdm_obj.close()\n","\n","        print(f\"Dataset created with {self.length} samples\")\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, idx):\n","        return self.en_data[idx], self.fr_data[idx], self.labels[idx]"]},{"cell_type":"markdown","metadata":{},"source":["### Model"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.383616Z","iopub.status.busy":"2024-10-02T12:48:25.383312Z","iopub.status.idle":"2024-10-02T12:48:25.394663Z","shell.execute_reply":"2024-10-02T12:48:25.393866Z","shell.execute_reply.started":"2024-10-02T12:48:25.383579Z"},"trusted":true},"outputs":[],"source":["def create_positional_encoding(max_length, embedding_dim):\n","    pe = torch.zeros(max_length, embedding_dim)\n","    position = torch.arange(0, max_length).unsqueeze(1)\n","    div_term = torch.exp(\n","        torch.arange(0, embedding_dim, 2) * -(np.log(10000.0) / embedding_dim)\n","    )\n","    pe[:, 0::2] = torch.sin(position.float() * div_term)\n","    pe[:, 1::2] = torch.cos(position.float() * div_term)\n","    return pe.to(device)\n","\n","\n","def make_src_mask(src):\n","    src1 = src\n","    if len(src.shape) == 3:\n","        src1 = torch.sum(src, dim=-1)\n","\n","    src_mask = (src1 != 0).unsqueeze(1).unsqueeze(2)\n","    return src_mask.to(device)\n","\n","\n","def make_trg_mask(trg):\n","    trg1 = trg\n","    if len(trg.shape) == 3:\n","        trg1 = torch.sum(trg, dim=-1)\n","    \n","    n, trg_len = trg1.size()\n","    trg_mask = torch.tril(torch.ones(trg_len, trg_len)).expand(n, 1, trg_len, trg_len)\n","    return trg_mask.to(device)"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.395950Z","iopub.status.busy":"2024-10-02T12:48:25.395678Z","iopub.status.idle":"2024-10-02T12:48:25.407755Z","shell.execute_reply":"2024-10-02T12:48:25.406659Z","shell.execute_reply.started":"2024-10-02T12:48:25.395901Z"},"trusted":true},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, embedding_dim: int = 512, num_heads: int = 8):\n","        super(MultiHeadAttention, self).__init__()\n","        self.embedding_dim = embedding_dim\n","        self.num_heads = num_heads\n","        self.head_dim = embedding_dim // num_heads\n","\n","        assert (\n","            self.head_dim * num_heads == embedding_dim\n","        ), \"Embedding dimension must be divisible by number of heads\"\n","\n","        self.q = nn.Linear(self.head_dim, self.head_dim)\n","        self.k = nn.Linear(self.head_dim, self.head_dim)\n","        self.v = nn.Linear(self.head_dim, self.head_dim)\n","        self.fc = nn.Linear(self.embedding_dim, self.embedding_dim)\n","\n","    def forward(self, value, key, query, mask):\n","        n = query.size(0)\n","        query_len, key_len, value_len = query.size(1), key.size(1), value.size(1)\n","\n","        value = self.v(value.reshape(n, value_len, self.num_heads, self.head_dim))\n","        query = self.q(query.reshape(n, query_len, self.num_heads, self.head_dim))\n","        key = self.k(key.reshape(n, key_len, self.num_heads, self.head_dim))\n","\n","        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [query, key])\n","        if mask is not None:\n","            energy = energy.masked_fill(mask == 0, -float(\"inf\"))\n","        attention = F.softmax(energy / np.sqrt(self.head_dim), dim=3)\n","\n","        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, value]).reshape(\n","            n, query_len, self.embedding_dim\n","        )\n","        out = self.fc(out)\n","\n","        return out"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.409226Z","iopub.status.busy":"2024-10-02T12:48:25.408880Z","iopub.status.idle":"2024-10-02T12:48:25.420324Z","shell.execute_reply":"2024-10-02T12:48:25.419480Z","shell.execute_reply.started":"2024-10-02T12:48:25.409193Z"},"trusted":true},"outputs":[],"source":["class TransformerBlock(nn.Module):\n","    def __init__(\n","        self,\n","        embed_size: int,\n","        heads: int,\n","        forward_expansion: int,\n","        dropout: float,\n","    ):\n","        super(TransformerBlock, self).__init__()\n","        self.attention = MultiHeadAttention(embed_size, heads)\n","\n","        self.feed_forward = nn.Sequential(\n","            nn.Linear(embed_size, forward_expansion * embed_size),\n","            nn.ReLU(),\n","            nn.Linear(forward_expansion * embed_size, embed_size),\n","        )\n","\n","        self.layer_norm1 = nn.Sequential(\n","            nn.LayerNorm(embed_size),\n","            nn.Dropout(dropout),\n","        )\n","        self.layer_norm2 = nn.Sequential(\n","            nn.LayerNorm(embed_size),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, value, key, query, mask):\n","        attention = self.attention(value, key, query, mask)\n","        x = self.layer_norm1(attention + query)\n","        forward = self.feed_forward(x)\n","        out = self.layer_norm2(forward + x)\n","        return out"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.421683Z","iopub.status.busy":"2024-10-02T12:48:25.421395Z","iopub.status.idle":"2024-10-02T12:48:25.434156Z","shell.execute_reply":"2024-10-02T12:48:25.433351Z","shell.execute_reply.started":"2024-10-02T12:48:25.421652Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(\n","        self,\n","        src_vocab_size: int,\n","        embed_size: int,\n","        num_layers: int,\n","        heads: int,\n","        forward_expansion: int,\n","        dropout: float,\n","        max_len: int,\n","    ):\n","        super(Encoder, self).__init__()\n","        self.embed_size = embed_size\n","        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)\n","        self.position_embedding = nn.Embedding(max_len, embed_size)\n","        self.layers = nn.ModuleList(\n","            [\n","                TransformerBlock(embed_size, heads, forward_expansion, dropout)\n","                for _ in range(num_layers)\n","            ]\n","        )\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask):\n","        n, seq_len = x.size()\n","        positions = torch.arange(0, seq_len).expand(n, seq_len).to(device)\n","        out = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n","        for layer in self.layers:\n","            out = layer(out, out, out, mask)\n","\n","        return out"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.435522Z","iopub.status.busy":"2024-10-02T12:48:25.435208Z","iopub.status.idle":"2024-10-02T12:48:25.446148Z","shell.execute_reply":"2024-10-02T12:48:25.445282Z","shell.execute_reply.started":"2024-10-02T12:48:25.435490Z"},"trusted":true},"outputs":[],"source":["class DecoderBlock(nn.Module):\n","    def __init__(\n","        self, embed_size: int, heads: int, forward_expansion: int, dropout: float\n","    ):\n","        super(DecoderBlock, self).__init__()\n","        self.attention = MultiHeadAttention(embed_size, heads)\n","        self.transformer_block = TransformerBlock(\n","            embed_size, heads, forward_expansion, dropout\n","        )\n","        self.layer_norm = nn.Sequential(\n","            nn.LayerNorm(embed_size),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x, value, key, src_mask, trg_mask):\n","        attention = self.attention(x, x, x, trg_mask)\n","        query = self.layer_norm(attention + x)\n","        out = self.transformer_block(value, key, query, src_mask)\n","        return out"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.447409Z","iopub.status.busy":"2024-10-02T12:48:25.447113Z","iopub.status.idle":"2024-10-02T12:48:25.459838Z","shell.execute_reply":"2024-10-02T12:48:25.458951Z","shell.execute_reply.started":"2024-10-02T12:48:25.447377Z"},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(\n","        self,\n","        trg_vocab_size: int,\n","        embed_size: int,\n","        num_layers: int,\n","        heads: int,\n","        forward_expansion: int,\n","        dropout: float,\n","        max_len: int,\n","    ):\n","        super(Decoder, self).__init__()\n","        self.device = device\n","        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n","        self.position_embedding = nn.Embedding(max_len, embed_size)\n","        self.layers = nn.ModuleList(\n","            [\n","                DecoderBlock(embed_size, heads, forward_expansion, dropout)\n","                for _ in range(num_layers)\n","            ]\n","        )\n","        self.fc = nn.Linear(embed_size, trg_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_out, src_mask, trg_mask):\n","        n, seq_len = x.size()\n","        positions = torch.arange(0, seq_len).expand(n, seq_len).to(device)\n","        x = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n","        for layer in self.layers:\n","            x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n","        out = self.fc(x)\n","        return out"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.461694Z","iopub.status.busy":"2024-10-02T12:48:25.461342Z","iopub.status.idle":"2024-10-02T12:48:25.498068Z","shell.execute_reply":"2024-10-02T12:48:25.497151Z","shell.execute_reply.started":"2024-10-02T12:48:25.461652Z"},"trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(\n","        self,\n","        src_vocab_size: int,\n","        trg_vocab_size: int,\n","        embed_size: int = 512,\n","        num_layers: int = 6,\n","        forward_expansion: int = 4,\n","        heads: int = 8,\n","        dropout: float = 0.2,\n","        max_len: int = 50,\n","        save_path=None,\n","    ):\n","        super(Transformer, self).__init__()\n","        self.encoder = Encoder(\n","            src_vocab_size,\n","            embed_size,\n","            num_layers,\n","            heads,\n","            forward_expansion,\n","            dropout,\n","            max_len,\n","        )\n","        self.decoder = Decoder(\n","            trg_vocab_size,\n","            embed_size,\n","            num_layers,\n","            heads,\n","            forward_expansion,\n","            dropout,\n","            max_len,\n","        )\n","        self.best_val_loss = float(\"inf\")\n","        self.save_path = save_path\n","\n","    def forward(self, src, trg):\n","        src_mask = make_src_mask(src)\n","        trg_mask = make_trg_mask(trg)\n","        enc_src = self.encoder(src, src_mask)\n","        out = self.decoder(trg, enc_src, src_mask, trg_mask)\n","        return out\n","\n","    def fit(self, train_loader, val_loader, criterion, optimizer, num_epochs: int = 10):\n","        train_losses = []\n","        val_losses = []\n","\n","        for epoch in range(num_epochs):\n","            self.train()\n","            train_loss = 0\n","            for src, trg, label in tqdm(train_loader, total=len(train_loader)):\n","                optimizer.zero_grad()\n","                output = self(src, trg)\n","                output = output.reshape(-1, output.size(-1))\n","                label = label.reshape(-1)\n","\n","                loss = criterion(output, label)\n","                loss.backward()\n","                optimizer.step()\n","                train_loss += loss.item()\n","\n","            train_loss /= len(train_loader)\n","            train_losses.append(train_loss)\n","            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss}\")\n","\n","            if device == \"cuda\":\n","                torch.cuda.empty_cache()\n","\n","            val_loss = self.evaluate(val_loader, criterion, True)\n","            val_losses.append(val_loss)\n","            print(f\"Validation Loss: {val_loss}\")\n","\n","            if self.save_path and val_loss < self.best_val_loss:\n","                self.best_val_loss = val_loss\n","                torch.save(self.state_dict(), self.save_path)\n","\n","        return train_losses, val_losses\n","\n","    def evaluate(self, val_loader, criterion, tqdm_disabled: bool = False):\n","        self.eval()\n","        val_loss = 0\n","        with torch.no_grad():\n","            for src, trg_input, trg_target in tqdm(\n","                val_loader, total=len(val_loader), disable=tqdm_disabled\n","            ):\n","                output = self(src, trg_input)\n","                output_dim = output.shape[-1]\n","                output = output.view(-1, output_dim)\n","                trg_target = trg_target.view(-1)\n","                loss = criterion(output, trg_target)\n","                val_loss += loss.item()\n","        val_loss /= len(val_loader)\n","        return val_loss\n","\n","    def load(self, path=None):\n","        if path:\n","            self.load_state_dict(torch.load(path))\n","        elif self.save_path:\n","            self.load_state_dict(torch.load(self.save_path))\n","        else:\n","            raise ValueError(\"No model path provided\")\n","\n","    def predict(\n","        self,\n","        src,\n","        src_preprocessed=False,\n","        max_len=64,\n","        return_sentence=False,\n","        fr_vocab=None,\n","        en_vocab=None,\n","        start_token_idx=1,\n","        end_token_idx=2,\n","    ):\n","        self.eval()  # Set the model to evaluation mode\n","\n","        if not src_preprocessed:\n","            assert en_vocab is not None\n","            src = word_tokenizer(src)\n","            src = [en_vocab.get(w, en_vocab[\"<unk>\"]) for w in src]\n","            src = [start_token_idx] + src[: max_len - 2] + [end_token_idx]\n","            src = pad_sequence(src, max_len, before=padding_before, pad_token=0)\n","            src = torch.tensor([src], dtype=torch.int, device=device)\n","\n","        trg = torch.tensor([[start_token_idx]], dtype=torch.int, device=device)\n","\n","        src_mask = make_src_mask(src)\n","        with torch.no_grad():\n","            enc_src = self.encoder(src, src_mask)\n","\n","        for _ in range(max_len):\n","            trg_mask = make_trg_mask(trg)\n","\n","            with torch.no_grad():\n","                output = self.decoder(trg, enc_src, src_mask, trg_mask)\n","                output = output[:, -1]\n","\n","            next_token = output.argmax(-1).unsqueeze(0)\n","            trg = torch.cat((trg, next_token), dim=1)\n","\n","            if next_token.item() == end_token_idx:\n","                break\n","\n","        generated_sequence = trg.squeeze(0).tolist()[1:]\n","        if generated_sequence[-1] == 2:\n","            generated_sequence = generated_sequence[:-1]\n","\n","        if return_sentence:\n","            assert fr_vocab is not None\n","            fr_vocab_rev = reverse_vocab(fr_vocab)\n","            generated_sequence = [fr_vocab_rev[idx] for idx in generated_sequence]\n","\n","        return generated_sequence\n","\n","    def test(self, test_loader, en_vocab, fr_vocab):\n","        self.eval()\n","        bleu_scores = []\n","        rouge_scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n","\n","        reverse_fr_vocab = reverse_vocab(fr_vocab)\n","        scorer = rouge_scorer.RougeScorer(\n","            [\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True\n","        )\n","\n","        with torch.no_grad():\n","            for src, _, label in tqdm(test_loader, total=len(test_loader)):\n","                for i in range(src.size(0)):\n","                    src_i = src[i].unsqueeze(0)\n","                    trg_target_i = label[i].unsqueeze(0)\n","\n","                    candidate = self.predict(\n","                        src_i,\n","                        src_preprocessed=True,\n","                        max_len=max_length,\n","                        fr_vocab=fr_vocab,\n","                        start_token_idx=en_vocab[\"<sos>\"],\n","                        end_token_idx=en_vocab[\"<eos>\"],\n","                    )\n","                    candidate = [reverse_fr_vocab[idx] for idx in candidate]\n","\n","                    reference = return_words_till_EOS(\n","                        trg_target_i.squeeze(0).tolist(), eos=fr_vocab[\"<eos>\"]\n","                    )\n","                    reference = [reverse_fr_vocab[idx] for idx in reference]\n","\n","                    bleu_score = sentence_bleu(\n","                        [reference],\n","                        candidate,\n","                        smoothing_function=SmoothingFunction().method1,\n","                    )\n","                    bleu_scores.append(bleu_score)\n","\n","                    # Convert lists to strings for ROUGE calculation\n","                    candidate_str = \" \".join(candidate)\n","                    reference_str = \" \".join(reference)\n","\n","                    # ROUGE Score calculation\n","                    rouge_score = scorer.score(reference_str, candidate_str)\n","                    rouge_scores[\"rouge1\"].append(rouge_score[\"rouge1\"].fmeasure)\n","                    rouge_scores[\"rouge2\"].append(rouge_score[\"rouge2\"].fmeasure)\n","                    rouge_scores[\"rougeL\"].append(rouge_score[\"rougeL\"].fmeasure)\n","\n","        if device == \"cuda\":\n","            torch.cuda.empty_cache()\n","        \n","        print(f\"Test BLEU Score: {np.mean(bleu_scores)}\")\n","        print(f\"Test ROUGE-1 Score: {np.mean(rouge_scores['rouge1'])}\")\n","        print(f\"Test ROUGE-2 Score: {np.mean(rouge_scores['rouge2'])}\")\n","        print(f\"Test ROUGE-L Score: {np.mean(rouge_scores['rougeL'])}\")\n","\n","        return (\n","            np.mean(bleu_scores),\n","            np.mean(rouge_scores[\"rouge1\"]),\n","            np.mean(rouge_scores[\"rouge2\"]),\n","            np.mean(rouge_scores[\"rougeL\"]),\n","        )"]},{"cell_type":"markdown","metadata":{},"source":["## Main"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:25.500217Z","iopub.status.busy":"2024-10-02T12:48:25.499139Z","iopub.status.idle":"2024-10-02T12:48:26.569392Z","shell.execute_reply":"2024-10-02T12:48:26.568590Z","shell.execute_reply.started":"2024-10-02T12:48:25.500171Z"},"trusted":true},"outputs":[],"source":["train_en, train_fr = read_data(en_train, fr_train)\n","val_en, val_fr = read_data(en_val, fr_val)\n","test_en, test_fr = read_data(en_test, fr_test)"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:26.570994Z","iopub.status.busy":"2024-10-02T12:48:26.570606Z","iopub.status.idle":"2024-10-02T12:48:44.396362Z","shell.execute_reply":"2024-10-02T12:48:44.395440Z","shell.execute_reply.started":"2024-10-02T12:48:26.570952Z"},"trusted":true},"outputs":[],"source":["train_en_words = [word_tokenizer(s) for s in train_en]\n","train_fr_words = [word_tokenizer(s) for s in train_fr]\n","val_en_words = [word_tokenizer(s) for s in val_en]\n","val_fr_words = [word_tokenizer(s) for s in val_fr]\n","test_en_words = [word_tokenizer(s) for s in test_en]\n","test_fr_words = [word_tokenizer(s) for s in test_fr]\n","\n","all_en_words = flatten_concatenation(train_en_words + val_en_words + test_en_words)\n","all_fr_words = flatten_concatenation(train_fr_words + val_fr_words + test_fr_words)"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:44.401859Z","iopub.status.busy":"2024-10-02T12:48:44.401513Z","iopub.status.idle":"2024-10-02T12:48:44.593726Z","shell.execute_reply":"2024-10-02T12:48:44.592921Z","shell.execute_reply.started":"2024-10-02T12:48:44.401826Z"},"trusted":true},"outputs":[],"source":["en_word_counts = Counter(all_en_words)\n","assert en_word_counts.total() == len(all_en_words)\n","fr_word_counts = Counter(all_fr_words)\n","assert fr_word_counts.total() == len(all_fr_words)\n","\n","en_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n","fr_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n","\n","for word, count in en_word_counts.items():\n","    # if count > 1:\n","        en_vocab[word] = len(en_vocab.keys())\n","\n","for word, count in fr_word_counts.items():\n","    # if count > 1:\n","        fr_vocab[word] = len(fr_vocab.keys())"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:44.595198Z","iopub.status.busy":"2024-10-02T12:48:44.594843Z","iopub.status.idle":"2024-10-02T12:48:49.417594Z","shell.execute_reply":"2024-10-02T12:48:49.416537Z","shell.execute_reply.started":"2024-10-02T12:48:44.595165Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Creating dataset: 100%|██████████| 30000/30000 [00:04<00:00, 6680.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Dataset created with 30000 samples\n"]},{"name":"stderr","output_type":"stream","text":["Creating dataset: 890it [00:00, 6989.21it/s]                         \n"]},{"name":"stdout","output_type":"stream","text":["Dataset created with 887 samples\n"]},{"name":"stderr","output_type":"stream","text":["Creating dataset: 1310it [00:00, 6880.07it/s]                         "]},{"name":"stdout","output_type":"stream","text":["Dataset created with 1305 samples\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["if train:\n","    train_dataset = MyDataset(\n","        train_en_words,\n","        train_fr_words,\n","        en_vocab,\n","        fr_vocab,\n","        padding_before,\n","    )\n","    val_dataset = MyDataset(\n","        val_en_words,\n","        val_fr_words,\n","        en_vocab,\n","        fr_vocab,\n","        padding_before,\n","    )\n","test_dataset = MyDataset(\n","    test_en_words,\n","    test_fr_words,\n","    en_vocab,\n","    fr_vocab,\n","    padding_before,\n",")"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:49.419325Z","iopub.status.busy":"2024-10-02T12:48:49.418968Z","iopub.status.idle":"2024-10-02T12:48:49.654890Z","shell.execute_reply":"2024-10-02T12:48:49.653974Z","shell.execute_reply.started":"2024-10-02T12:48:49.419279Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of train_loader: 938\n","Length of val_loader: 28\n","Length of test_loader: 1305\n"]}],"source":["if train:\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","    )\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","    )\n","    print(\"Length of train_loader:\", len(train_loader))\n","    print(\"Length of val_loader:\", len(val_loader))\n","\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","print(\"Length of test_loader:\", len(test_loader))"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:49.656359Z","iopub.status.busy":"2024-10-02T12:48:49.656038Z","iopub.status.idle":"2024-10-02T12:48:49.663575Z","shell.execute_reply":"2024-10-02T12:48:49.662679Z","shell.execute_reply.started":"2024-10-02T12:48:49.656324Z"},"trusted":true},"outputs":[],"source":["hyper_params1 = [\n","    {\"embedding_dim\": 300, \"dropout\": 0.2, \"layers\": 6},\n","    {\"embedding_dim\": 300, \"dropout\": 0.4, \"layers\": 6},\n","]\n","train_losses1, val_losses1 = [], []\n","scores1 = []\n","losses1 = []\n","\n","hyper_params2 = [\n","    {\"embedding_dim\": 300, \"dropout\": 0.2, \"layers\": 6},\n","    {\"embedding_dim\": 600, \"dropout\": 0.2, \"layers\": 6},\n","]\n","train_losses2, val_losses2 = [], []\n","scores2 = []\n","losses2 = []\n","\n","hyper_params3 = [\n","    {\"embedding_dim\": 300, \"dropout\": 0.2, \"layers\": 4},\n","    {\"embedding_dim\": 300, \"dropout\": 0.2, \"layers\": 6},\n","]\n","train_losses3, val_losses3 = [], []\n","scores3 = []\n","losses3 = []"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:49.665756Z","iopub.status.busy":"2024-10-02T12:48:49.664720Z","iopub.status.idle":"2024-10-02T12:48:49.677247Z","shell.execute_reply":"2024-10-02T12:48:49.676259Z","shell.execute_reply.started":"2024-10-02T12:48:49.665710Z"},"trusted":true},"outputs":[],"source":["def run_full_model(hyper_params):\n","    print(\"Running model with hyperparameters:\", hyper_params)\n","    embedding_dim = hyper_params[\"embedding_dim\"]\n","    dropout = hyper_params[\"dropout\"]\n","    layers = hyper_params[\"layers\"]\n","    save_path = f\"./models/transformer_layers{layers}_embedding{embedding_dim}_dropout{dropout}.pth\"\n","\n","    model = Transformer(\n","        len(en_vocab),\n","        len(fr_vocab),\n","        embed_size=hyper_params[\"embedding_dim\"],\n","        num_layers=hyper_params[\"layers\"],\n","        heads=heads,\n","        forward_expansion=4,\n","        dropout=hyper_params[\"dropout\"],\n","        max_len=max_length,\n","        save_path=save_path,\n","    ).to(device)\n","\n","    criterion = nn.CrossEntropyLoss(ignore_index=0)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","    train_losses = val_losses = [0]*epochs\n","\n","    # train_losses, val_losses = model.fit(\n","    #     train_loader, val_loader, criterion, optimizer, epochs\n","    # )\n","\n","    # model.load(save_path)\n","    test_loss = model.evaluate(test_loader, criterion)\n","    scores = model.test(test_loader, en_vocab, fr_vocab)\n","\n","    return train_losses, val_losses, test_loss, scores"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T12:48:49.678737Z","iopub.status.busy":"2024-10-02T12:48:49.678432Z","iopub.status.idle":"2024-10-02T12:48:49.695743Z","shell.execute_reply":"2024-10-02T12:48:49.694777Z","shell.execute_reply.started":"2024-10-02T12:48:49.678705Z"},"trusted":true},"outputs":[],"source":["def plot_scores(blue_scores, rouge1_scores, rouge2_scores, rougeL_scores, labels):\n","    # Number of indices\n","    indices = np.arange(len(blue_scores))\n","    \n","    # Define bar width and spacing\n","    bar_width = 0.2\n","    spacing = 0.05  # Space between groups of bars\n","    \n","    # Offset for each set of bars\n","    offset_blue = 0\n","    offset_rouge1 = bar_width + spacing\n","    offset_rouge2 = (bar_width + spacing) * 2\n","    offset_rougeL = (bar_width + spacing) * 3\n","\n","    # Adjusting x positions for side-by-side bars\n","    x_blue = indices + offset_blue\n","    x_rouge1 = indices + offset_rouge1\n","    x_rouge2 = indices + offset_rouge2\n","    x_rougeL = indices + offset_rougeL\n","\n","    plt.figure(figsize=(10, 6))\n","    \n","    # Plot each set of bars side-by-side for each index\n","    plt.bar(x_blue, blue_scores, width=bar_width, label='BLEU', color='b')\n","    plt.bar(x_rouge1, rouge1_scores, width=bar_width, label='ROUGE-1', color='g')\n","    plt.bar(x_rouge2, rouge2_scores, width=bar_width, label='ROUGE-2', color='r')\n","    plt.bar(x_rougeL, rougeL_scores, width=bar_width, label='ROUGE-L', color='orange')\n","\n","    # Set labels and titles\n","    plt.xlabel('Index')\n","    plt.ylabel('Scores')\n","    plt.title('BLEU and ROUGE Scores')\n","    \n","    # Adjust x-axis ticks to the middle of each group\n","    plt.xticks(indices + (offset_rougeL + offset_blue) / 2, labels)\n","    \n","    plt.legend()\n","    plt.grid(True)\n","    \n","    # Show plot\n","    plt.show()\n","\n","\n","def plot(train_losses, val_losses, test_loss, scores, labels=[]):\n","    assert (\n","        len(train_losses)\n","        == len(val_losses)\n","        == len(scores)\n","        == len(test_loss)\n","        == len(labels)\n","    )\n","\n","    plt.figure(figsize=(10, 5))\n","\n","    # Plot train losses\n","    for i, losses in enumerate(train_losses):\n","        plt.plot(losses, label=f'Train Loss {labels[i]}')\n","    \n","    # Plot validation losses\n","    for i, losses in enumerate(val_losses):\n","        plt.plot(losses, label=f'Val Loss {labels[i]}', linestyle='--')\n","\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Loss\")\n","    plt.title(\"Train and Validation Loss\")\n","    plt.legend()\n","    plt.show()\n","\n","    plt.figure(figsize=(7, 5))\n","    plt.bar(labels, test_loss, color='orange')\n","    plt.xlabel(\"Hyperparameter\")\n","    plt.ylabel('Loss')\n","    plt.title('Test Losses')\n","    \n","    # Show plot for test losses\n","    plt.show()\n","\n","    blue_scores = [score[0] for score in scores]\n","    rouge1_scores = [score[1] for score in scores]\n","    rouge2_scores = [score[2] for score in scores]\n","    rougeL_scores = [score[3] for score in scores]\n","\n","    plot_scores(blue_scores, rouge1_scores, rouge2_scores, rougeL_scores, labels)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for hyper_params in hyper_params1:\n","    train_losses, val_losses, test_loss, scores = run_full_model(hyper_params)\n","    train_losses1.append(train_losses)\n","    val_losses1.append(val_losses)\n","    scores1.append(scores)\n","    losses1.append(test_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-10-02T12:50:47.144861Z","iopub.status.idle":"2024-10-02T12:50:47.145369Z","shell.execute_reply":"2024-10-02T12:50:47.145134Z","shell.execute_reply.started":"2024-10-02T12:50:47.145108Z"},"trusted":true},"outputs":[],"source":["plot(train_losses1, val_losses1, losses1, scores1, [\"300-0.2-6\", \"300-0.4-6\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-10-02T12:50:47.146637Z","iopub.status.idle":"2024-10-02T12:50:47.147131Z","shell.execute_reply":"2024-10-02T12:50:47.146887Z","shell.execute_reply.started":"2024-10-02T12:50:47.146861Z"},"trusted":true},"outputs":[],"source":["for hyper_params in hyper_params2:\n","    train_losses, val_losses, test_loss, scores = run_full_model(hyper_params)\n","    train_losses2.append(train_losses)\n","    val_losses2.append(val_losses)\n","    scores2.append(scores)\n","    losses2.append(test_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-10-02T12:50:47.148752Z","iopub.status.idle":"2024-10-02T12:50:47.149251Z","shell.execute_reply":"2024-10-02T12:50:47.149020Z","shell.execute_reply.started":"2024-10-02T12:50:47.148992Z"},"trusted":true},"outputs":[],"source":["plot(train_losses2, val_losses2, losses2, scores2, [\"300-0.2-6\", \"600-0.2-6\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-10-02T12:50:47.150849Z","iopub.status.idle":"2024-10-02T12:50:47.151232Z","shell.execute_reply":"2024-10-02T12:50:47.151066Z","shell.execute_reply.started":"2024-10-02T12:50:47.151047Z"},"trusted":true},"outputs":[],"source":["for hyper_params in hyper_params3:\n","    train_losses, val_losses, test_loss, scores = run_full_model(hyper_params)\n","    train_losses3.append(train_losses)\n","    val_losses3.append(val_losses)\n","    scores3.append(scores)\n","    losses3.append(test_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-10-02T12:50:47.152425Z","iopub.status.idle":"2024-10-02T12:50:47.152753Z","shell.execute_reply":"2024-10-02T12:50:47.152603Z","shell.execute_reply.started":"2024-10-02T12:50:47.152585Z"},"trusted":true},"outputs":[],"source":["plot(train_losses3, val_losses3, losses3, scores3, [\"300-0.2-4\", \"300-0.2-6\"])"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5799894,"sourceId":9524849,"sourceType":"datasetVersion"},{"datasetId":5800233,"sourceId":9525328,"sourceType":"datasetVersion"}],"dockerImageVersionId":30776,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
