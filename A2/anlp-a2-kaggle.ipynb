{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:28.878858Z","iopub.status.busy":"2024-10-02T14:45:28.878560Z","iopub.status.idle":"2024-10-02T14:45:43.753628Z","shell.execute_reply":"2024-10-02T14:45:43.752523Z","shell.execute_reply.started":"2024-10-02T14:45:28.878825Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=d46c80b02a1561d41c173e51381125ac896a419d24691e675a89eb029eba9d50\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}],"source":["!pip install rouge_score"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:43.756035Z","iopub.status.busy":"2024-10-02T14:45:43.755701Z","iopub.status.idle":"2024-10-02T14:45:47.987433Z","shell.execute_reply":"2024-10-02T14:45:47.986647Z","shell.execute_reply.started":"2024-10-02T14:45:43.756000Z"},"trusted":true},"outputs":[],"source":["import os\n","import re\n","import json\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","from torchinfo import summary\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","from rouge_score import rouge_scorer\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:47.988897Z","iopub.status.busy":"2024-10-02T14:45:47.988506Z","iopub.status.idle":"2024-10-02T14:45:48.993409Z","shell.execute_reply":"2024-10-02T14:45:48.992460Z","shell.execute_reply.started":"2024-10-02T14:45:47.988864Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]}],"source":["import nltk\n","\n","nltk.download(\"punkt\")\n","nltk.download(\"punkt_tab\")\n","\n","from nltk.tokenize import word_tokenize\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction, corpus_bleu"]},{"cell_type":"markdown","metadata":{},"source":["## Config"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:48.996059Z","iopub.status.busy":"2024-10-02T14:45:48.995721Z","iopub.status.idle":"2024-10-02T14:45:49.000720Z","shell.execute_reply":"2024-10-02T14:45:48.999674Z","shell.execute_reply.started":"2024-10-02T14:45:48.996025Z"},"trusted":true},"outputs":[],"source":["en_train = '/kaggle/input/ted-talks-corpus/train.en'\n","fr_train = '/kaggle/input/ted-talks-corpus/train.fr'\n","en_val = '/kaggle/input/ted-talks-corpus/dev.en'\n","fr_val = '/kaggle/input/ted-talks-corpus/dev.fr'\n","en_test = '/kaggle/input/ted-talks-corpus/test.en'\n","fr_test = '/kaggle/input/ted-talks-corpus/test.fr'"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.002836Z","iopub.status.busy":"2024-10-02T14:45:49.002148Z","iopub.status.idle":"2024-10-02T14:45:49.045502Z","shell.execute_reply":"2024-10-02T14:45:49.044634Z","shell.execute_reply.started":"2024-10-02T14:45:49.002793Z"},"trusted":true},"outputs":[],"source":["train = False\n","padding_before = False\n","plot_losses = False"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.047864Z","iopub.status.busy":"2024-10-02T14:45:49.047584Z","iopub.status.idle":"2024-10-02T14:45:49.055306Z","shell.execute_reply":"2024-10-02T14:45:49.054505Z","shell.execute_reply.started":"2024-10-02T14:45:49.047834Z"},"trusted":true},"outputs":[],"source":["embedding_dim = 300\n","max_length = 64\n","lr=1e-4\n","\n","heads = 6\n","layers = 6\n","\n","epochs = 15\n","batch_size = 32"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.056780Z","iopub.status.busy":"2024-10-02T14:45:49.056434Z","iopub.status.idle":"2024-10-02T14:45:49.066790Z","shell.execute_reply":"2024-10-02T14:45:49.065933Z","shell.execute_reply.started":"2024-10-02T14:45:49.056737Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving model to ./models/transformer_heads6_layers6.pth\n"]}],"source":["os.makedirs(\"models\", exist_ok=True)\n","\n","save_path=\"./models/transformer\"\n","\n","save_path = save_path + f\"_heads{heads}_layers{layers}\"\n","\n","save_path = save_path + \".pth\"\n","\n","print(f\"Saving model to {save_path}\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.068785Z","iopub.status.busy":"2024-10-02T14:45:49.068076Z","iopub.status.idle":"2024-10-02T14:45:49.079350Z","shell.execute_reply":"2024-10-02T14:45:49.078360Z","shell.execute_reply.started":"2024-10-02T14:45:49.068752Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Random Seed: 42\n"]}],"source":["random_seed = 42\n","\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","print(\"Using Random Seed:\", random_seed)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.080550Z","iopub.status.busy":"2024-10-02T14:45:49.080298Z","iopub.status.idle":"2024-10-02T14:45:49.117861Z","shell.execute_reply":"2024-10-02T14:45:49.117004Z","shell.execute_reply.started":"2024-10-02T14:45:49.080522Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Utils"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.123365Z","iopub.status.busy":"2024-10-02T14:45:49.122640Z","iopub.status.idle":"2024-10-02T14:45:49.129798Z","shell.execute_reply":"2024-10-02T14:45:49.128992Z","shell.execute_reply.started":"2024-10-02T14:45:49.123331Z"},"trusted":true},"outputs":[],"source":["def clean_text(text):\n","    text = str(text).lower().strip()\n","    text = text.rstrip('\\n')\n","#     text = re.sub(r\"<[^>]+>\", \"\", text)\n","    text = re.sub(r\"[^a-zA-ZÀ-ÿ0-9\\s.,;!?':()\\[\\]{}-]\", \" \", text)  # Keep selected punctuation marks, symbols and apostrophes\n","    text = re.sub(r\"\\s+\", \" \", text)\n","\n","    text = text.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")  # Corrected encoding\n","\n","    return text\n","\n","def clean_sentences(sentences):\n","    sentences = [clean_text(sentence) for sentence in sentences]\n","    sentences = [s for s in sentences if s and s != \"\"]  # remove empty strings\n","    return sentences"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.131005Z","iopub.status.busy":"2024-10-02T14:45:49.130652Z","iopub.status.idle":"2024-10-02T14:45:49.142454Z","shell.execute_reply":"2024-10-02T14:45:49.141690Z","shell.execute_reply.started":"2024-10-02T14:45:49.130945Z"},"trusted":true},"outputs":[],"source":["def read_data(en_path, fr_path):\n","    with open(en_path, \"r\") as f:\n","        en_data = f.readlines()\n","    with open(fr_path, \"r\") as f:\n","        fr_data = f.readlines()\n","\n","    assert len(en_data) == len(fr_data), \"Data mismatch\"\n","\n","    en_data = clean_sentences(en_data)\n","    fr_data = clean_sentences(fr_data)\n","\n","    assert len(en_data) == len(fr_data), \"Data mismatch in cleaned data\"\n","\n","    return en_data, fr_data\n","\n","def word_tokenizer(sentence):\n","    words = word_tokenize(sentence)\n","    return words"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.143711Z","iopub.status.busy":"2024-10-02T14:45:49.143426Z","iopub.status.idle":"2024-10-02T14:45:49.151131Z","shell.execute_reply":"2024-10-02T14:45:49.150353Z","shell.execute_reply.started":"2024-10-02T14:45:49.143676Z"},"trusted":true},"outputs":[],"source":["def flatten_concatenation(list_of_lists, unique=False):\n","    # flat_list = []\n","    # for sublist in list_of_lists:\n","    #     flat_list += sublist\n","\n","    # flat_list = list(set(flat_list))\n","    # return flat_list\n","    flat_array = np.concatenate(list_of_lists)\n","    if unique:\n","        flat_list = np.unique(flat_array).tolist()\n","    else:\n","        flat_list = flat_array.tolist()\n","    return flat_list"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.152377Z","iopub.status.busy":"2024-10-02T14:45:49.152119Z","iopub.status.idle":"2024-10-02T14:45:49.160572Z","shell.execute_reply":"2024-10-02T14:45:49.159730Z","shell.execute_reply.started":"2024-10-02T14:45:49.152348Z"},"trusted":true},"outputs":[],"source":["def reverse_vocab(vocab):\n","    return {v: k for k, v in vocab.items()}"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.161830Z","iopub.status.busy":"2024-10-02T14:45:49.161566Z","iopub.status.idle":"2024-10-02T14:45:49.169917Z","shell.execute_reply":"2024-10-02T14:45:49.169019Z","shell.execute_reply.started":"2024-10-02T14:45:49.161801Z"},"trusted":true},"outputs":[],"source":["def return_words_till_EOS(lst, eos=2):\n","    if eos not in lst:\n","        return lst\n","    return lst[:lst.index(eos)]"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.171511Z","iopub.status.busy":"2024-10-02T14:45:49.171079Z","iopub.status.idle":"2024-10-02T14:45:49.179085Z","shell.execute_reply":"2024-10-02T14:45:49.178255Z","shell.execute_reply.started":"2024-10-02T14:45:49.171480Z"},"trusted":true},"outputs":[],"source":["def pad_sequence(sequence, max_len, before=True, pad_token=0):\n","    if len(sequence) > max_len:\n","        return sequence[:max_len]\n","    elif before:\n","        return [pad_token] * (max_len - len(sequence)) + sequence\n","    else:\n","        return sequence + [pad_token] * (max_len - len(sequence))"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.180517Z","iopub.status.busy":"2024-10-02T14:45:49.180220Z","iopub.status.idle":"2024-10-02T14:45:49.194051Z","shell.execute_reply":"2024-10-02T14:45:49.193219Z","shell.execute_reply.started":"2024-10-02T14:45:49.180487Z"},"trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(\n","        self,\n","        en_data,\n","        fr_data,\n","        en_vocab,\n","        fr_vocab,\n","        pad_before=False,\n","    ):\n","        self.en_data = []\n","        self.fr_data = []\n","        self.labels = []\n","        self.en_vocab = en_vocab\n","        self.fr_vocab = fr_vocab\n","\n","        assert len(en_data) == len(fr_data)\n","        self.length = len(en_data)\n","\n","        en_pad = self.en_vocab[\"<pad>\"]\n","        en_unk = self.en_vocab[\"<unk>\"]\n","        en_sos = self.en_vocab[\"<sos>\"]\n","        en_eos = self.en_vocab[\"<eos>\"]\n","        fr_pad = self.fr_vocab[\"<pad>\"]\n","        fr_unk = self.fr_vocab[\"<unk>\"]\n","        fr_sos = self.fr_vocab[\"<sos>\"]\n","        fr_eos = self.fr_vocab[\"<eos>\"]\n","\n","        tqdm_obj = tqdm(\n","            total=self.length, desc=\"Creating dataset\"\n","        )\n","        for index, (en_sentence, fr_sentence) in enumerate(zip(en_data, fr_data)):\n","            en_indices = [int(self.en_vocab.get(w, en_unk)) for w in en_sentence]\n","            en_indices = [en_sos] + en_indices[: max_length - 2] + [en_eos]\n","            en_indices = pad_sequence(\n","                en_indices, max_length, before=pad_before, pad_token=en_pad\n","            )\n","            self.en_data.append(\n","                torch.tensor(en_indices, dtype=torch.int, device=device)\n","            )\n","\n","            fr_indices1 = [int(self.fr_vocab.get(w, fr_unk)) for w in fr_sentence]\n","            fr_indices = [fr_sos] + fr_indices1\n","            fr_indices = pad_sequence(\n","                fr_indices, max_length, before=pad_before, pad_token=fr_pad\n","            )\n","            self.fr_data.append(\n","                torch.tensor(fr_indices, dtype=torch.int, device=device)\n","            )\n","\n","            fr_indices = fr_indices1 + [fr_eos]\n","            fr_indices = pad_sequence(\n","                fr_indices, max_length, before=pad_before, pad_token=fr_pad\n","            )\n","            self.labels.append(torch.tensor(fr_indices, device=device))\n","\n","            if index % 10 == 0:\n","                tqdm_obj.update(10)\n","\n","        tqdm_obj.close()\n","\n","        print(f\"Dataset created with {self.length} samples\")\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, idx):\n","        return self.en_data[idx], self.fr_data[idx], self.labels[idx]"]},{"cell_type":"markdown","metadata":{},"source":["### Model"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.195446Z","iopub.status.busy":"2024-10-02T14:45:49.195141Z","iopub.status.idle":"2024-10-02T14:45:49.207000Z","shell.execute_reply":"2024-10-02T14:45:49.206152Z","shell.execute_reply.started":"2024-10-02T14:45:49.195410Z"},"trusted":true},"outputs":[],"source":["def create_positional_encoding(max_length, embedding_dim):\n","    pe = torch.zeros(max_length, embedding_dim)\n","    position = torch.arange(0, max_length).unsqueeze(1)\n","    div_term = torch.exp(\n","        torch.arange(0, embedding_dim, 2) * -(np.log(10000.0) / embedding_dim)\n","    )\n","    pe[:, 0::2] = torch.sin(position.float() * div_term)\n","    pe[:, 1::2] = torch.cos(position.float() * div_term)\n","    return pe.to(device)\n","\n","\n","def make_src_mask(src):\n","    src1 = src\n","    if len(src.shape) == 3:\n","        src1 = torch.sum(src, dim=-1)\n","\n","    src_mask = (src1 != 0).unsqueeze(1).unsqueeze(2)\n","    return src_mask.to(device)\n","\n","\n","def make_trg_mask(trg):\n","    trg1 = trg\n","    if len(trg.shape) == 3:\n","        trg1 = torch.sum(trg, dim=-1)\n","    \n","    n, trg_len = trg1.size()\n","    trg_mask = torch.tril(torch.ones(trg_len, trg_len)).expand(n, 1, trg_len, trg_len)\n","    return trg_mask.to(device)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.208464Z","iopub.status.busy":"2024-10-02T14:45:49.208172Z","iopub.status.idle":"2024-10-02T14:45:49.219180Z","shell.execute_reply":"2024-10-02T14:45:49.218400Z","shell.execute_reply.started":"2024-10-02T14:45:49.208433Z"},"trusted":true},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, embedding_dim: int = 512, num_heads: int = 8):\n","        super(MultiHeadAttention, self).__init__()\n","        self.embedding_dim = embedding_dim\n","        self.num_heads = num_heads\n","        self.head_dim = embedding_dim // num_heads\n","\n","        assert (\n","            self.head_dim * num_heads == embedding_dim\n","        ), \"Embedding dimension must be divisible by number of heads\"\n","\n","        self.q = nn.Linear(self.head_dim, self.head_dim)\n","        self.k = nn.Linear(self.head_dim, self.head_dim)\n","        self.v = nn.Linear(self.head_dim, self.head_dim)\n","        self.fc = nn.Linear(self.embedding_dim, self.embedding_dim)\n","\n","    def forward(self, value, key, query, mask):\n","        n = query.size(0)\n","        query_len, key_len, value_len = query.size(1), key.size(1), value.size(1)\n","\n","        value = self.v(value.reshape(n, value_len, self.num_heads, self.head_dim))\n","        query = self.q(query.reshape(n, query_len, self.num_heads, self.head_dim))\n","        key = self.k(key.reshape(n, key_len, self.num_heads, self.head_dim))\n","\n","        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [query, key])\n","        if mask is not None:\n","            energy = energy.masked_fill(mask == 0, -float(\"inf\"))\n","        attention = F.softmax(energy / np.sqrt(self.head_dim), dim=3)\n","\n","        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, value]).reshape(\n","            n, query_len, self.embedding_dim\n","        )\n","        out = self.fc(out)\n","\n","        return out"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.220526Z","iopub.status.busy":"2024-10-02T14:45:49.220223Z","iopub.status.idle":"2024-10-02T14:45:49.231545Z","shell.execute_reply":"2024-10-02T14:45:49.230735Z","shell.execute_reply.started":"2024-10-02T14:45:49.220496Z"},"trusted":true},"outputs":[],"source":["class TransformerBlock(nn.Module):\n","    def __init__(\n","        self,\n","        embed_size: int,\n","        heads: int,\n","        forward_expansion: int,\n","        dropout: float,\n","    ):\n","        super(TransformerBlock, self).__init__()\n","        self.attention = MultiHeadAttention(embed_size, heads)\n","\n","        self.feed_forward = nn.Sequential(\n","            nn.Linear(embed_size, forward_expansion * embed_size),\n","            nn.ReLU(),\n","            nn.Linear(forward_expansion * embed_size, embed_size),\n","        )\n","\n","        self.layer_norm1 = nn.Sequential(\n","            nn.LayerNorm(embed_size),\n","            nn.Dropout(dropout),\n","        )\n","        self.layer_norm2 = nn.Sequential(\n","            nn.LayerNorm(embed_size),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, value, key, query, mask):\n","        attention = self.attention(value, key, query, mask)\n","        x = self.layer_norm1(attention + query)\n","        forward = self.feed_forward(x)\n","        out = self.layer_norm2(forward + x)\n","        return out"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.232820Z","iopub.status.busy":"2024-10-02T14:45:49.232531Z","iopub.status.idle":"2024-10-02T14:45:49.244881Z","shell.execute_reply":"2024-10-02T14:45:49.244125Z","shell.execute_reply.started":"2024-10-02T14:45:49.232789Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(\n","        self,\n","        src_vocab_size: int,\n","        embed_size: int,\n","        num_layers: int,\n","        heads: int,\n","        forward_expansion: int,\n","        dropout: float,\n","        max_len: int,\n","    ):\n","        super(Encoder, self).__init__()\n","        self.embed_size = embed_size\n","        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)\n","        self.position_embedding = nn.Embedding(max_len, embed_size)\n","        self.layers = nn.ModuleList(\n","            [\n","                TransformerBlock(embed_size, heads, forward_expansion, dropout)\n","                for _ in range(num_layers)\n","            ]\n","        )\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask):\n","        n, seq_len = x.size()\n","        positions = torch.arange(0, seq_len).expand(n, seq_len).to(device)\n","        out = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n","        for layer in self.layers:\n","            out = layer(out, out, out, mask)\n","\n","        return out"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.246180Z","iopub.status.busy":"2024-10-02T14:45:49.245879Z","iopub.status.idle":"2024-10-02T14:45:49.256448Z","shell.execute_reply":"2024-10-02T14:45:49.255667Z","shell.execute_reply.started":"2024-10-02T14:45:49.246142Z"},"trusted":true},"outputs":[],"source":["class DecoderBlock(nn.Module):\n","    def __init__(\n","        self, embed_size: int, heads: int, forward_expansion: int, dropout: float\n","    ):\n","        super(DecoderBlock, self).__init__()\n","        self.attention = MultiHeadAttention(embed_size, heads)\n","        self.transformer_block = TransformerBlock(\n","            embed_size, heads, forward_expansion, dropout\n","        )\n","        self.layer_norm = nn.Sequential(\n","            nn.LayerNorm(embed_size),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x, value, key, src_mask, trg_mask):\n","        attention = self.attention(x, x, x, trg_mask)\n","        query = self.layer_norm(attention + x)\n","        out = self.transformer_block(value, key, query, src_mask)\n","        return out"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.257859Z","iopub.status.busy":"2024-10-02T14:45:49.257475Z","iopub.status.idle":"2024-10-02T14:45:49.269594Z","shell.execute_reply":"2024-10-02T14:45:49.268838Z","shell.execute_reply.started":"2024-10-02T14:45:49.257816Z"},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(\n","        self,\n","        trg_vocab_size: int,\n","        embed_size: int,\n","        num_layers: int,\n","        heads: int,\n","        forward_expansion: int,\n","        dropout: float,\n","        max_len: int,\n","    ):\n","        super(Decoder, self).__init__()\n","        self.device = device\n","        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n","        self.position_embedding = nn.Embedding(max_len, embed_size)\n","        self.layers = nn.ModuleList(\n","            [\n","                DecoderBlock(embed_size, heads, forward_expansion, dropout)\n","                for _ in range(num_layers)\n","            ]\n","        )\n","        self.fc = nn.Linear(embed_size, trg_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_out, src_mask, trg_mask):\n","        n, seq_len = x.size()\n","        positions = torch.arange(0, seq_len).expand(n, seq_len).to(device)\n","        x = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n","        for layer in self.layers:\n","            x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n","        out = self.fc(x)\n","        return out"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:52:19.834400Z","iopub.status.busy":"2024-10-02T14:52:19.834006Z","iopub.status.idle":"2024-10-02T14:52:19.874134Z","shell.execute_reply":"2024-10-02T14:52:19.873182Z","shell.execute_reply.started":"2024-10-02T14:52:19.834363Z"},"trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(\n","        self,\n","        src_vocab_size: int,\n","        trg_vocab_size: int,\n","        embed_size: int = 512,\n","        num_layers: int = 6,\n","        forward_expansion: int = 4,\n","        heads: int = 8,\n","        dropout: float = 0.2,\n","        max_len: int = 50,\n","        save_path=None,\n","    ):\n","        super(Transformer, self).__init__()\n","        self.encoder = Encoder(\n","            src_vocab_size,\n","            embed_size,\n","            num_layers,\n","            heads,\n","            forward_expansion,\n","            dropout,\n","            max_len,\n","        )\n","        self.decoder = Decoder(\n","            trg_vocab_size,\n","            embed_size,\n","            num_layers,\n","            heads,\n","            forward_expansion,\n","            dropout,\n","            max_len,\n","        )\n","        self.best_val_loss = float(\"inf\")\n","        self.save_path = save_path\n","\n","    def forward(self, src, trg):\n","        src_mask = make_src_mask(src)\n","        trg_mask = make_trg_mask(trg)\n","        enc_src = self.encoder(src, src_mask)\n","        out = self.decoder(trg, enc_src, src_mask, trg_mask)\n","        return out\n","\n","    def fit(self, train_loader, val_loader, criterion, optimizer, num_epochs: int = 10):\n","        train_losses = []\n","        val_losses = []\n","\n","        for epoch in range(num_epochs):\n","            self.train()\n","            train_loss = 0\n","            for src, trg, label in tqdm(train_loader, total=len(train_loader)):\n","                optimizer.zero_grad()\n","                output = self(src, trg)\n","                output = output.reshape(-1, output.size(-1))\n","                label = label.reshape(-1)\n","\n","                loss = criterion(output, label)\n","                loss.backward()\n","                optimizer.step()\n","                train_loss += loss.item()\n","\n","            train_loss /= len(train_loader)\n","            train_losses.append(train_loss)\n","            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss}\")\n","\n","            if device == \"cuda\":\n","                torch.cuda.empty_cache()\n","\n","            val_loss = self.evaluate(val_loader, criterion, True)\n","            val_losses.append(val_loss)\n","            print(f\"Validation Loss: {val_loss}\")\n","\n","            if self.save_path and val_loss < self.best_val_loss:\n","                self.best_val_loss = val_loss\n","                torch.save(self.state_dict(), self.save_path)\n","\n","        return train_losses, val_losses\n","\n","    def evaluate(self, val_loader, criterion, tqdm_disabled: bool = False):\n","        self.eval()\n","        val_loss = 0\n","        with torch.no_grad():\n","            for src, trg_input, trg_target in tqdm(\n","                val_loader, total=len(val_loader), disable=tqdm_disabled\n","            ):\n","                output = self(src, trg_input)\n","                output_dim = output.shape[-1]\n","                output = output.view(-1, output_dim)\n","                trg_target = trg_target.view(-1)\n","                loss = criterion(output, trg_target)\n","                val_loss += loss.item()\n","        val_loss /= len(val_loader)\n","        return val_loss\n","\n","    def load(self, path=None):\n","        if path:\n","            self.load_state_dict(torch.load(path))\n","        elif self.save_path:\n","            self.load_state_dict(torch.load(self.save_path))\n","        else:\n","            raise ValueError(\"No model path provided\")\n","\n","    def predict(\n","        self,\n","        src,\n","        src_preprocessed=False,\n","        max_len=64,\n","        return_sentence=False,\n","        fr_vocab=None,\n","        en_vocab=None,\n","        start_token_idx=1,\n","        end_token_idx=2,\n","    ):\n","        self.eval()  # Set the model to evaluation mode\n","\n","        if not src_preprocessed:\n","            assert en_vocab is not None\n","            src = word_tokenizer(src)\n","            src = [en_vocab.get(w, en_vocab[\"<unk>\"]) for w in src]\n","            src = [start_token_idx] + src[: max_len - 2] + [end_token_idx]\n","            src = pad_sequence(src, max_len, before=padding_before, pad_token=0)\n","            src = torch.tensor([src], dtype=torch.int, device=device)\n","\n","        trg = torch.tensor([[start_token_idx]], dtype=torch.int, device=device)\n","\n","        src_mask = make_src_mask(src)\n","        with torch.no_grad():\n","            enc_src = self.encoder(src, src_mask)\n","\n","        for _ in range(max_len):\n","            trg_mask = make_trg_mask(trg)\n","\n","            with torch.no_grad():\n","                output = self.decoder(trg, enc_src, src_mask, trg_mask)\n","                output = output[:, -1]\n","\n","            next_token = output.argmax(-1).unsqueeze(0)\n","            trg = torch.cat((trg, next_token), dim=1)\n","\n","            if next_token.item() == end_token_idx:\n","                break\n","\n","        generated_sequence = trg.squeeze(0).tolist()[1:]\n","        if generated_sequence[-1] == 2:\n","            generated_sequence = generated_sequence[:-1]\n","\n","        if return_sentence:\n","            assert fr_vocab is not None\n","            fr_vocab_rev = reverse_vocab(fr_vocab)\n","            generated_sequence = [fr_vocab_rev[idx] for idx in generated_sequence]\n","\n","        return generated_sequence\n","\n","    def test(self, test_loader, en_vocab, fr_vocab):\n","        self.eval()\n","        bleu_scores = []\n","        rouge_scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n","        predicts = []\n","        references = []\n","        candidates = []\n","\n","        reverse_fr_vocab = reverse_vocab(fr_vocab)\n","        scorer = rouge_scorer.RougeScorer(\n","            [\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True\n","        )\n","\n","        with torch.no_grad():\n","            for src, _, label in tqdm(test_loader, total=len(test_loader)):\n","                for i in range(src.size(0)):\n","                    src_i = src[i].unsqueeze(0)\n","                    trg_target_i = label[i].unsqueeze(0)\n","\n","                    candidate = self.predict(\n","                        src_i,\n","                        src_preprocessed=True,\n","                        max_len=max_length,\n","                        fr_vocab=fr_vocab,\n","                        start_token_idx=en_vocab[\"<sos>\"],\n","                        end_token_idx=en_vocab[\"<eos>\"],\n","                    )\n","                    candidate = [reverse_fr_vocab[idx] for idx in candidate]\n","\n","                    reference = return_words_till_EOS(\n","                        trg_target_i.squeeze(0).tolist(), eos=fr_vocab[\"<eos>\"]\n","                    )\n","                    reference = [reverse_fr_vocab[idx] for idx in reference]\n","\n","                    bleu_score = sentence_bleu(\n","                        [reference],\n","                        candidate,\n","                        smoothing_function=SmoothingFunction().method1,\n","                    )\n","                    bleu_scores.append(bleu_score)\n","\n","                    candidate_str = \" \".join(candidate)\n","                    reference_str = \" \".join(reference)\n","\n","                    predicts.append(candidate_str)\n","                    candidates.append(candidate)\n","                    references.append([reference])\n","\n","                    rouge_score = scorer.score(reference_str, candidate_str)\n","                    rouge_scores[\"rouge1\"].append(rouge_score[\"rouge1\"].fmeasure)\n","                    rouge_scores[\"rouge2\"].append(rouge_score[\"rouge2\"].fmeasure)\n","                    rouge_scores[\"rougeL\"].append(rouge_score[\"rougeL\"].fmeasure)\n","\n","        os.makedirs(\"results\", exist_ok=True)\n","\n","        overall_results = []\n","        for i in range(len(test_loader)):\n","            overall_results.append(\n","                {\n","                    \"src\": test_en[i],\n","                    \"expected\": test_fr[i],\n","                    \"predicted\": predicts[i],\n","                    \"bleu\": bleu_scores[i],\n","                    \"rouge1\": rouge_scores['rouge1'][i],\n","                    \"rouge2\": rouge_scores['rouge2'][i],\n","                    \"rougeL\": rouge_scores['rougeL'][i],\n","                }\n","            )\n","        with open(\"./results/overall_results.json\", \"w\") as f:\n","            json.dump(overall_results, f, indent=4)\n","\n","        with open(\"./results/testbleu.txt\", \"w\") as f:\n","            for i in range(len(test_loader)):\n","                f.write(f\"{test_en[i]} {bleu_scores[i]}\\n\")\n","\n","        if device == \"cuda\":\n","            torch.cuda.empty_cache()\n","        \n","        print(f\"Test BLEU Score: {np.mean(bleu_scores)}\")\n","        print(f\"Corpus BLEU Score: {corpus_bleu(references, candidates)}\")\n","        print(f\"Test ROUGE-1 Score: {np.mean(rouge_scores['rouge1'])}\")\n","        print(f\"Test ROUGE-2 Score: {np.mean(rouge_scores['rouge2'])}\")\n","        print(f\"Test ROUGE-L Score: {np.mean(rouge_scores['rougeL'])}\")\n","\n","        return (\n","            np.mean(bleu_scores),\n","            np.mean(rouge_scores[\"rouge1\"]),\n","            np.mean(rouge_scores[\"rouge2\"]),\n","            np.mean(rouge_scores[\"rougeL\"]),\n","        )"]},{"cell_type":"markdown","metadata":{},"source":["## Main"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:49.310807Z","iopub.status.busy":"2024-10-02T14:45:49.310448Z","iopub.status.idle":"2024-10-02T14:45:50.507772Z","shell.execute_reply":"2024-10-02T14:45:50.507005Z","shell.execute_reply.started":"2024-10-02T14:45:49.310765Z"},"trusted":true},"outputs":[],"source":["train_en, train_fr = read_data(en_train, fr_train)\n","val_en, val_fr = read_data(en_val, fr_val)\n","test_en, test_fr = read_data(en_test, fr_test)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:45:50.509237Z","iopub.status.busy":"2024-10-02T14:45:50.508879Z","iopub.status.idle":"2024-10-02T14:46:06.947335Z","shell.execute_reply":"2024-10-02T14:46:06.946350Z","shell.execute_reply.started":"2024-10-02T14:45:50.509203Z"},"trusted":true},"outputs":[],"source":["train_en_words = [word_tokenizer(s) for s in train_en]\n","train_fr_words = [word_tokenizer(s) for s in train_fr]\n","val_en_words = [word_tokenizer(s) for s in val_en]\n","val_fr_words = [word_tokenizer(s) for s in val_fr]\n","test_en_words = [word_tokenizer(s) for s in test_en]\n","test_fr_words = [word_tokenizer(s) for s in test_fr]\n","\n","all_en_words = flatten_concatenation(train_en_words + val_en_words + test_en_words)\n","all_fr_words = flatten_concatenation(train_fr_words + val_fr_words + test_fr_words)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:46:06.949812Z","iopub.status.busy":"2024-10-02T14:46:06.949074Z","iopub.status.idle":"2024-10-02T14:46:07.163315Z","shell.execute_reply":"2024-10-02T14:46:07.162313Z","shell.execute_reply.started":"2024-10-02T14:46:06.949767Z"},"trusted":true},"outputs":[],"source":["en_word_counts = Counter(all_en_words)\n","assert en_word_counts.total() == len(all_en_words)\n","fr_word_counts = Counter(all_fr_words)\n","assert fr_word_counts.total() == len(all_fr_words)\n","\n","en_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n","fr_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n","\n","for word, count in en_word_counts.items():\n","    # if count > 1:\n","        en_vocab[word] = len(en_vocab.keys())\n","\n","for word, count in fr_word_counts.items():\n","    # if count > 1:\n","        fr_vocab[word] = len(fr_vocab.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pickle as pkl\n","\n","os.makedirs(\"vocab\")\n","\n","# Save vocab\n","with open(\"./vocab/en_vocab.pkl\", \"wb\") as f:\n","    pkl.dump(en_vocab, f)\n","\n","with open(\"./vocab/fr_vocab.pkl\", \"wb\") as f:\n","    pkl.dump(fr_vocab, f)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:46:07.165252Z","iopub.status.busy":"2024-10-02T14:46:07.164542Z","iopub.status.idle":"2024-10-02T14:46:07.521784Z","shell.execute_reply":"2024-10-02T14:46:07.520861Z","shell.execute_reply.started":"2024-10-02T14:46:07.165217Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Creating dataset: 1310it [00:00, 3783.33it/s]                         "]},{"name":"stdout","output_type":"stream","text":["Dataset created with 1305 samples\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["if train:\n","    train_dataset = MyDataset(\n","        train_en_words,\n","        train_fr_words,\n","        en_vocab,\n","        fr_vocab,\n","        padding_before,\n","    )\n","    val_dataset = MyDataset(\n","        val_en_words,\n","        val_fr_words,\n","        en_vocab,\n","        fr_vocab,\n","        padding_before,\n","    )\n","test_dataset = MyDataset(\n","    test_en_words,\n","    test_fr_words,\n","    en_vocab,\n","    fr_vocab,\n","    padding_before,\n",")"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:46:07.526740Z","iopub.status.busy":"2024-10-02T14:46:07.526416Z","iopub.status.idle":"2024-10-02T14:46:07.533579Z","shell.execute_reply":"2024-10-02T14:46:07.532683Z","shell.execute_reply.started":"2024-10-02T14:46:07.526705Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of test_loader: 1305\n"]}],"source":["if train:\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","    )\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","    )\n","    print(\"Length of train_loader:\", len(train_loader))\n","    print(\"Length of val_loader:\", len(val_loader))\n","\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","print(\"Length of test_loader:\", len(test_loader))"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:52:25.753273Z","iopub.status.busy":"2024-10-02T14:52:25.752562Z","iopub.status.idle":"2024-10-02T14:52:26.156030Z","shell.execute_reply":"2024-10-02T14:52:26.155009Z","shell.execute_reply.started":"2024-10-02T14:52:25.753232Z"},"trusted":true},"outputs":[],"source":["model = Transformer(\n","    len(en_vocab),\n","    len(fr_vocab),\n","    embed_size=embedding_dim,\n","    num_layers=layers,\n","    heads=heads,\n","    forward_expansion=4,\n","    dropout=0.2,\n","    max_len=max_length,\n","    save_path=save_path,\n",").to(device)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:46:08.005538Z","iopub.status.busy":"2024-10-02T14:46:08.005225Z","iopub.status.idle":"2024-10-02T14:46:08.009861Z","shell.execute_reply":"2024-10-02T14:46:08.008807Z","shell.execute_reply.started":"2024-10-02T14:46:08.005506Z"},"trusted":true},"outputs":[],"source":["# print(model)\n","# summary(model, input_data=[\n","#     torch.randint(low=0, high=len(en_vocab), size=(batch_size, max_length), device=device)\n","#     torch.randint(low=0, high=len(fr_vocab), size=(batch_size, max_length), device=device)\n","# ])"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:46:08.011355Z","iopub.status.busy":"2024-10-02T14:46:08.010998Z","iopub.status.idle":"2024-10-02T14:46:09.070840Z","shell.execute_reply":"2024-10-02T14:46:09.069821Z","shell.execute_reply.started":"2024-10-02T14:46:08.011303Z"},"trusted":true},"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=lr) # type: ignore\n","criterion = nn.CrossEntropyLoss(ignore_index=0)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:46:09.072620Z","iopub.status.busy":"2024-10-02T14:46:09.072153Z","iopub.status.idle":"2024-10-02T14:46:09.077921Z","shell.execute_reply":"2024-10-02T14:46:09.077022Z","shell.execute_reply.started":"2024-10-02T14:46:09.072585Z"},"trusted":true},"outputs":[],"source":["if train:\n","    train_losses, val_losses = model.fit(\n","        train_loader,\n","        val_loader,\n","        criterion,\n","        optimizer,\n","        num_epochs=epochs,\n","    )\n","\n","    if plot_losses:\n","        plt.plot(train_losses, label=\"Train Loss\")\n","        plt.plot(val_losses, label=\"Validation Loss\")\n","        plt.legend()\n","        plt.show()"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:52:30.645126Z","iopub.status.busy":"2024-10-02T14:52:30.644432Z","iopub.status.idle":"2024-10-02T14:52:30.811935Z","shell.execute_reply":"2024-10-02T14:52:30.810917Z","shell.execute_reply.started":"2024-10-02T14:52:30.645082Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/3166810607.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.load_state_dict(torch.load(self.save_path))\n"]}],"source":["model.load()"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:46:09.245555Z","iopub.status.busy":"2024-10-02T14:46:09.245127Z","iopub.status.idle":"2024-10-02T14:46:27.019282Z","shell.execute_reply":"2024-10-02T14:46:27.018244Z","shell.execute_reply.started":"2024-10-02T14:46:09.245511Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1305/1305 [00:17<00:00, 73.47it/s]\n"]},{"data":{"text/plain":["4.895798279407837"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["model.evaluate(test_loader, criterion)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:46:27.020920Z","iopub.status.busy":"2024-10-02T14:46:27.020522Z","iopub.status.idle":"2024-10-02T14:46:27.198873Z","shell.execute_reply":"2024-10-02T14:46:27.197921Z","shell.execute_reply.started":"2024-10-02T14:46:27.020875Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['les', 'gens', 'sont', 'un', 'peu', 'de', 'la', 'vie', '.']"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["model.predict(\n","    \"I am a student.\",\n","    en_vocab=en_vocab,\n","    fr_vocab=fr_vocab,\n","    return_sentence=True,\n",")"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-10-02T14:52:33.111356Z","iopub.status.busy":"2024-10-02T14:52:33.110939Z","iopub.status.idle":"2024-10-02T14:58:02.083415Z","shell.execute_reply":"2024-10-02T14:58:02.082521Z","shell.execute_reply.started":"2024-10-02T14:52:33.111315Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1305/1305 [05:28<00:00,  3.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test BLEU Score: 0.031163257459442834\n","Corpus BLEU Score: 0.014645905653256672\n","Test ROUGE-1 Score: 0.1758659844683691\n","Test ROUGE-2 Score: 0.04185880767342699\n","Test ROUGE-L Score: 0.16228867247008116\n"]},{"data":{"text/plain":["(0.031163257459442834,\n"," 0.1758659844683691,\n"," 0.04185880767342699,\n"," 0.16228867247008116)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["model.test(test_loader, en_vocab, fr_vocab)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5800233,"sourceId":9525328,"sourceType":"datasetVersion"}],"dockerImageVersionId":30776,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
